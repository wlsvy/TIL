# AtDevcat_2024

## 24.02.27

[c - Is it Safe to use ReaderWriterLockSlim in an async method - Stack Overflow](https://stackoverflow.com/questions/15882710/is-it-safe-to-use-readerwriterlockslim-in-an-async-method)

```cs
System.Threading.ReaderWriterLockSlim readerwriterlock = new System.Threading.ReaderWriterLockSlim();
private async Task Test()
{
    readerwriterlock.EnterWriteLock();
    await Task.Yield(); //do work that could yield the task
    readerwriterlock.ExitWriteLock(); //potentailly exit the lock on a different thread
}
```

ÏúÑÏùò ÏΩîÎìúÎäî ÏïàÏ†ÑÌïòÏßÄ Î™ªÌïòÎã§.

`await Task.Yield();` ÎùºÏù∏ Ï†ÑÌõÑÎ°ú Ïã§Ìñâ Ïä§Î†àÎìúÍ∞Ä Îã§Î•º Ïàò ÏûàÍ∏∞ ÎïåÎ¨∏Ïù¥Îã§!!!

ÎùΩÏùÑ Í±∞Îäî Ïä§Î†àÎìúÏôÄ Ìï¥Ï†úÌïòÎäî Ïä§Î†àÎìúÍ∞Ä Îã§Î•¥Î©¥ Ïä§Î†àÎìú ÏïàÏ†ÑÏÑ±Ïù¥ ÏúÑÎ∞òÎêúÎã§. Ï†ïÎßê Ï†ïÎßê ÌÅ∞Ïùº ÎÇ† Ïàò ÏûàÎã§!!!

**ChatGPT ÎãµÎ≥Ä**

`ReaderWriterLockSlim`ÏùÑ ÎπÑÎèôÍ∏∞ ÏΩîÎìú ÎÇ¥ÏóêÏÑú ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏùÄ Ï£ºÏùòÎ•º ÏöîÌï©ÎãàÎã§. ÏúÑÏùò ÏΩîÎìú ÏòàÏ†úÏóêÏÑúÎäî ÎπÑÎèôÍ∏∞ Î©îÏÑúÎìú(Loop1 Î∞è Loop2) ÎÇ¥ÏóêÏÑú ReaderWriterLockSlimÏùò EnterWriteLockÍ≥º ExitWriteLockÏùÑ ÏÇ¨Ïö©ÌïòÍ≥† ÏûàÏäµÎãàÎã§. Ïù¥Îü¨Ìïú Î∞©ÏãùÏúºÎ°ú ReaderWriterLockSlimÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏùÄ ÏùºÎ∞òÏ†ÅÏúºÎ°ú ÏïàÏ†ÑÌï¥ Î≥¥Ïù¥ÏßÄÎßå, ÎπÑÎèôÍ∏∞ ÌîÑÎ°úÍ∑∏ÎûòÎ∞çÏùò Îß•ÎùΩÏóêÏÑú Î™á Í∞ÄÏßÄ Ï£ºÏùòÌï¥Ïïº Ìï† Ï†êÏù¥ ÏûàÏäµÎãàÎã§:

ÎπÑÎèôÍ∏∞ÏôÄ Î∏îÎ°úÌÇπ Ìò∏Ï∂úÏùò ÌòºÌï© ÏÇ¨Ïö©: ReaderWriterLockSlimÏùò EnterWriteLock Î©îÏÑúÎìúÎäî Ìò∏Ï∂ú Ïä§Î†àÎìúÎ•º Î∏îÎ°úÌÇπÌï©ÎãàÎã§. Ïù¥Îäî await Task.Delay(1000);ÏôÄ Í∞ôÏùÄ ÎπÑÎèôÍ∏∞ Ìò∏Ï∂ú ÌõÑÏóê Ïù¥Î£®Ïñ¥Ïßà Í≤ΩÏö∞, ÎπÑÎèôÍ∏∞ ÏûëÏóÖÏù¥ ÏôÑÎ£åÎêú ÌõÑ ÎèôÍ∏∞ Î∏îÎ°úÌÇπ Ìò∏Ï∂úÏù¥ Ïù¥Î£®Ïñ¥ÏßÄÎäî Í≤ÉÏûÖÎãàÎã§. Ïù¥Îü¨Ìïú Ìå®ÌÑ¥ÏùÄ ÏùºÎ∞òÏ†ÅÏúºÎ°ú Í∂åÏû•ÎêòÏßÄ ÏïäÏúºÎ©∞, ÌäπÌûà UI Ïä§Î†àÎìúÏôÄ Í∞ôÏù¥ Î∏îÎ°úÌÇπÎêòÏñ¥ÏÑúÎäî Ïïà ÎêòÎäî Ïä§Î†àÎìúÏóêÏÑúÎäî ÏÇ¨Ïö©ÏùÑ ÌîºÌï¥Ïïº Ìï©ÎãàÎã§.

Îç∞ÎìúÎùΩ ÏúÑÌóò: ÏúÑÏùò ÏòàÏãú ÏΩîÎìú ÏûêÏ≤¥ÏóêÏÑú ÏßÅÏ†ëÏ†ÅÏù∏ Îç∞ÎìúÎùΩÏùÑ Ïú†Î∞úÌï† Î™ÖÌôïÌïú ÏöîÏÜåÎäî ÏóÜÏäµÎãàÎã§. Í∑∏Îü¨ÎÇò, ReaderWriterLockSlimÏùÑ ÏÇ¨Ïö©ÌïòÎäî Î≥µÏû°Ìïú ÎπÑÎèôÍ∏∞ ÌùêÎ¶ÑÏóêÏÑúÎäî Îç∞ÎìúÎùΩ ÏúÑÌóòÏù¥ ÏûàÏäµÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥, ÌïòÎÇòÏùò ÌÉúÏä§ÌÅ¨Í∞Ä Ïì∞Í∏∞ ÎùΩÏùÑ ÌöçÎìùÌïú ÏÉÅÌÉúÏóêÏÑú Îã§Î•∏ ÌÉúÏä§ÌÅ¨Í∞Ä Í∞ôÏùÄ ÎùΩÏùÑ Í∏∞Îã§Î¶¨Îäî ÎèôÏïà, Ï≤´ Î≤àÏß∏ ÌÉúÏä§ÌÅ¨Í∞Ä ÌõÑÏûêÏùò ÏôÑÎ£åÎ•º Í∏∞Îã§Î¶¨Í≤å ÎêòÎ©¥ Îç∞ÎìúÎùΩÏù¥ Î∞úÏÉùÌï† Ïàò ÏûàÏäµÎãàÎã§.

ÎπÑÎèôÍ∏∞ ÏΩîÎìúÏóêÏÑúÏùò ÎùΩ Í¥ÄÎ¶¨: ReaderWriterLockSlimÏùÄ Î≥∏ÏßàÏ†ÅÏúºÎ°ú ÎèôÍ∏∞Ï†Å ÎùΩ Î©îÏª§ÎãàÏ¶òÏûÖÎãàÎã§. ÎπÑÎèôÍ∏∞ ÏΩîÎìúÏóêÏÑúÎäî SemaphoreSlimÏùò WaitAsync Î©îÏÑúÎìúÏôÄ Í∞ôÏù¥, ÎπÑÎèôÍ∏∞Ï†ÅÏúºÎ°ú ÎåÄÍ∏∞Ìï† Ïàò ÏûàÎäî ÎùΩ Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏù¥ Îçî Ï†ÅÌï©Ìï† Ïàò ÏûàÏäµÎãàÎã§. Ïù¥Îü¨Ìïú Î©îÏª§ÎãàÏ¶òÏùÄ ÎπÑÎèôÍ∏∞ ÏûëÏóÖÏù¥ ÎùΩÏùÑ Í∏∞Îã§Î¶¨Îäî ÎèôÏïà Ïä§Î†àÎìúÎ•º Î∏îÎ°úÌÇπÌïòÏßÄ ÏïäÍ≥† ÎåÄÍ∏∞ÌïòÎèÑÎ°ù Ìï¥Ï§çÎãàÎã§.

ÏöîÏïΩÌïòÏûêÎ©¥, ReaderWriterLockSlimÏùÄ Ï£ºÎ°ú ÎèôÍ∏∞ ÏΩîÎìúÏóêÏÑú ÏÇ¨Ïö©Îê† Îïå ÏïàÏ†ÑÌïòÎ©∞, ÎπÑÎèôÍ∏∞ ÏΩîÎìúÏóêÏÑú ÏÇ¨Ïö©Ìï† ÎïåÎäî Ï£ºÏùòÍ∞Ä ÌïÑÏöîÌï©ÎãàÎã§. ÌäπÌûà, ÎπÑÎèôÍ∏∞ ÏûëÏóÖ ÎÇ¥ÏóêÏÑú Î∏îÎ°úÌÇπ ÎùΩ Ìò∏Ï∂úÏùÑ ÌîºÌïòÍ≥†, Í∞ÄÎä•ÌïòÎã§Î©¥ ÎπÑÎèôÍ∏∞ ÏûëÏóÖÏóê Ï†ÅÌï©Ìïú ÎùΩ Î©îÏª§ÎãàÏ¶òÏùÑ ÏÇ¨Ïö©ÌïòÎäî Í≤ÉÏù¥ Ï¢ãÏäµÎãàÎã§. ÎπÑÎèôÍ∏∞ ÏΩîÎìúÏóêÏÑú ReaderWriterLockSlim Í∞ôÏùÄ ÎèôÍ∏∞ ÎùΩÏùÑ ÏÇ¨Ïö©Ìï† ÎïåÎäî Îç∞ÎìúÎùΩÏù¥ÎÇò ÏÑ±Îä• Ï†ÄÌïòÏùò ÏúÑÌóòÏùÑ Ï∂©Î∂ÑÌûà Í≥†Î†§Ìï¥Ïïº Ìï©ÎãàÎã§.

## 24.02.28

[White House - PRESS RELEASE: Future Software Should Be Memory Safe](https://www.whitehouse.gov/oncd/briefing-room/2024/02/26/press-release-technical-report/)

> ONCD makes the case that technology manufacturers can prevent entire classes of vulnerabilities from entering the digital ecosystem by adopting memory safe programming languages. ONCD is also encouraging the research community to address the problem of software measurability to enable the development of better diagnostics that measure cybersecurity quality.

Î∞±ÏïÖÍ¥ÄÏóêÏÑú ÎîîÏßÄÌÑ∏ ÌôòÍ≤ΩÏóêÏÑú ÏÇ¨Ïù¥Î≤Ñ Í≥µÍ≤©ÏùÑ Î∞©ÏßÄÌïòÍ∏∞ ÏúÑÌï¥, Î©îÎ™®Î¶¨ ÏÑ∏Ïù¥ÌîÑÌïú ÏÜåÌîÑÌä∏Ïõ®Ïñ¥Ïùò ÌïÑÏöîÏÑ±ÏùÑ Í∞ïÏ°∞Ìï®.

**Í≤åÏûÑ Í∏∞Îèô ÏÜçÎèÑ ÎÜíÏù¥Í∏∞**

- ÌòÑÎåÄÏù∏ÏùÄ Ïù∏ÎÇ¥Ïã¨Ïù¥ Îß§Ïö∞ Î∂ÄÏ°±ÌïòÍ≥† ÏßßÏùÄ ÏãúÍ∞ÑÏóêÎèÑ ÏßëÏ§ëÎ†•ÏùÑ ÏûÉÎäîÎã§.
  - Í≤åÏûÑ Ï¥àÍ∏∞ Í∏∞Îèô ÏãúÍ∞ÑÏù¥ Í∏∏Î©¥ Ïú†Ï†Ä Ïù¥ÌÉàÎ°ú Ïù¥Ïñ¥Ïßê
- Í∏∞Îèô ÏÜçÎèÑÎ•º Ï§ÑÏù¥Í±∞ÎÇò, ÎåÄÍ∏∞ Ï§ëÏóê Ï£ºÏùòÎ•º ÌôòÍ∏∞ÏãúÌÇ¨ÎßåÌïú Îã§Î•∏ ÏöîÏÜåÎ•º ÏßëÏñ¥ÎÑ£Ïñ¥Ïïº ÌïúÎã§. (ÎèôÏòÅÏÉÅÏùÑ ÌäºÎã§Í±∞ÎÇò)

[Jake Seo on X ÏÑ∏Í≥Ñ ÏµúÍ≥†Ïùò Í∞úÎ∞úÏûê Ï§ë ÌïúÎ™ÖÏù∏ Ï°¥ Ïπ¥Îß•Ïù¥ ÏãúÍ∞ÑÏùÑ Í¥ÄÎ¶¨ÌïòÎäî Î∞©Ïãù Ïù∏ÌÑ∞Î∑∞Ìïú Í≤ÉÏùÑ ÎÇòÎ¶ÑÎåÄÎ°ú Ï†ïÎ¶¨Ìï¥Î¥Ñ Ïù∏ÌÑ∞Î∑∞ ÏòÅÏÉÅÏù¥ ÎßàÏπò Ïª§ÌîºÏ±óÌïòÎäî Í≤É Í∞ôÏïÑ Ïû¨Î∞åÏóàÎã§ - Î™áÏã≠ÎÖÑÍ∞Ñ Ï£º 60ÏãúÍ∞Ñ Ïù¥ÏÉÅ ÏùºÌï¥Ïò¥ - Îß§Ïùº 10ÏãúÍ∞Ñ Ï†ïÎèÑ - Ï†äÏóàÏùÑ ÎïåÎäî ÍµâÏû•Ìûà Î∂àÍ∑úÏπôÏ†ÅÏúºÎ°ú ÏÇ¥ÏïòÏùå - Î∞§ÏùÑ ÏÉàÍ±∞ÎÇò Îä¶Ïû†ÏùÑ ÏûêÍ∏∞ÎèÑ Ìï® - ÎÇòÏù¥Í∞Ä Îì§Ïñ¥ÏÑú‚Ä¶  X](https://twitter.com/JakeSeo8/status/1733483508549693512?s=20)

ÏÑ∏Í≥Ñ ÏµúÍ≥†Ïùò Í∞úÎ∞úÏûê Ï§ë ÌïúÎ™ÖÏù∏ Ï°¥ Ïπ¥Îß•Ïù¥ ÏãúÍ∞ÑÏùÑ Í¥ÄÎ¶¨ÌïòÎäî Î∞©Ïãù Ïù∏ÌÑ∞Î∑∞Ìïú Í≤ÉÏùÑ ÎÇòÎ¶ÑÎåÄÎ°ú Ï†ïÎ¶¨Ìï¥Î¥Ñ

Ïù∏ÌÑ∞Î∑∞ ÏòÅÏÉÅÏù¥ ÎßàÏπò Ïª§ÌîºÏ±óÌïòÎäî Í≤É Í∞ôÏïÑ Ïû¨Î∞åÏóàÎã§

- Î™áÏã≠ÎÖÑÍ∞Ñ Ï£º 60ÏãúÍ∞Ñ Ïù¥ÏÉÅ ÏùºÌï¥Ïò¥
- Îß§Ïùº 10ÏãúÍ∞Ñ Ï†ïÎèÑ
- Ï†äÏóàÏùÑ ÎïåÎäî ÍµâÏû•Ìûà Î∂àÍ∑úÏπôÏ†ÅÏúºÎ°ú ÏÇ¥ÏïòÏùå
- Î∞§ÏùÑ ÏÉàÍ±∞ÎÇò Îä¶Ïû†ÏùÑ ÏûêÍ∏∞ÎèÑ Ìï®
- ÎÇòÏù¥Í∞Ä Îì§Ïñ¥ÏÑú ÏïÑÏù¥Î•º ÎÇ≥Í≥† ÎÇòÏÑúÎäî ÏùºÎ∞ò ÏßÅÏû•Ïù∏Í≥º ÎπÑÏä∑Ìïú Ìå®ÌÑ¥ÏúºÎ°ú ÏÇ∂
- ÏµúÍ∑º Î™áÎã¨Í∞Ñ 4ÎßàÏùº (ÏïΩ 6km) Ï†ïÎèÑÎ•º Í±∑Í±∞ÎÇò Îõ∞ÎäîÎç∞ Ìö®Í≥ºÍ∞Ä ÏûàÎäî Í≤É Í∞ôÎã§
- Ïö¥ÎèôÌïú Îã§Ïùå ÏÉ§Ïõå ÌõÑÏùò Î™áÏãúÍ∞ÑÏù¥ ÏûêÏã†ÏóêÍ≤å ÏµúÍ≥†Ïùò ÏãúÍ∞ÑÏù¥ÏóàÎã§
- ÎÇú 12ÏãúÍ∞ÑÎßå ÏùºÌïòÎ©¥ ÎáåÍ∞Ä ÏßÄÏπòÎäîÎç∞ 20ÏãúÍ∞ÑÏî© ÏùºÌïòÎäî ÌîÑÎ°úÍ∑∏ÎûòÎ®∏Í∞Ä Î∂ÄÎüΩÎã§
- 4ÏãúÍ∞ÑÎßå ÏûêÍ≥† ÏùºÌïòÎäî ÎèÖÏ¢ÖÏùÑ Ïù¥Í∏∞Í∏¥ Ïñ¥Î†µÎã§
- ÏÇ¨ÎûåÎì§ÏóêÍ≤åÎäî 8ÏãúÍ∞ÑÏùÄ Íº≠ ÏûêÎùºÍ≥† Ï°∞Ïñ∏ÌïúÎã§
- Ïä§Ïä§Î°úÎ•º ÏïïÎ∞ïÌïòÏßÄ ÎßêÍ≥† ÏñµÏßÄÎ°ú ÏùºÏ∞ç ÏùºÏñ¥ÎÇòÏßÄ ÎßêÎùºÍ≥†
- Ìïú Í≤åÏûÑ Í∞úÎ∞úÏûêÏùò ÎßêÏùÑ ÎπåÎ¶¨Î©¥ "ÏßÄÎÇòÏπòÍ≤å ÎßéÏùÄ ÏùºÏùÄ Î∞òÎìúÏãú ÌÅ∞ Î¨∏Ï†úÎ•º Í∞ÄÏ†∏Ïò®Îã§" ÎùºÍ≥† Ìï®
- Î™áÎ™á ÏÇ¨ÎûåÎì§ÏùÄ ÏÉùÏÇ∞ÏÑ±Ïóê ÎåÄÌïú ÏßÄÏãùÏùÑ ÏûòÎ™ª Ïù∏Ïö©ÌïòÎ©∞ Ï£º 40ÏãúÍ∞Ñ ÏùºÌïòÎäî Í≤ÉÏùÄ Îß§Ïö∞ ÎπÑÌö®Ïú®Ï†ÅÏù¥ÎùºÍ≥† ÎßêÌïúÎã§
- ÎÑàÎ¨¥ Ïò§Îûò ÏùºÌïòÎ©¥ ÏÉùÏÇ∞ÏÑ±Ïù¥ Í∞êÏÜåÌïòÍ∏¥ ÌïòÏßÄÎßå Î™áÏãúÍ∞Ñ Îçî ÏùºÌïúÎã§Í≥† ÏÑ±Í≥ºÍ∞Ä ÎÇòÎπ†ÏßÄÏßÑ ÏïäÏùå
- ÎãπÏû• ÏßÄÍµ¨Ïóê ÏÜåÌñâÏÑ±Ïù¥ Îñ®Ïñ¥ÏßÑÎã§Î©¥, Ïó¨Îü¨Î∂ÑÏùÄ ÏùºÎ°†Î®∏Ïä§ÌÅ¨Í∞Ä Ïù¥Î•º ÎßâÍ∏∞ ÏúÑÌï¥ ÏùºÌïòÎ©¥ÏÑú Ïò§ÌõÑ 5ÏãúÏóê ÏπºÌá¥ÌïòÎäî Í≤ÉÏùÑ ÎëêÍ≥†Î≥º Í≤ÉÏù∏Í∞Ä?
- ÎÇòÎ•º Ïû¨Ïàò ÏóÜÎäî ÎÜà (Asshole) ÏúºÎ°ú Î≥¥Îäî ÏãúÏÑ†ÎèÑ ÏûàÍ≤†ÏßÄÎßå, ÏßÑÏã§ÏùÄ Îçî Ïò§Îûò ÏùºÌï†ÏàòÎ°ù Îçî ÎßéÏùÄ ÏÑ±Í≥ºÎ•º ÏñªÎäîÎã§
- Î™®ÎëêÍ∞Ä Ïó¥Ïã¨Ìûà Ïùº Ìï† ÌïÑÏöîÎäî ÏóÜÏßÄÎßå Î¨¥Ïñ∏Í∞ÄÎ•º Ïù¥Î£®Î†§Î©¥ ÏùºÏóê Îß§ÏßÑÌï¥Ïïº ÌïúÎã§
- ÎÇú ÏùºÎ∞òÏ†ÅÏù∏ ÏßÅÏû•Ïù∏Í≥º Îß§Ïö∞ Îã§Î•¥Îã§
- ÏùºÏù¥ ÎÇ¥ ÏÇ∂Ïóê ÎØ∏ÏπòÎäî ÏòÅÌñ•Ïóê ÎåÄÌïú Ïù∏ÏãùÎ∂ÄÌÑ∞ Îß§Ïö∞ Îã§Î•¥Îã§
- ÏùºÏùÑ ÌïòÎ©∞ Î≤àÏïÑÏõÉÏùÑ Í≤™ÏùÄ Ï†ÅÏù¥ ÌïúÎ≤àÎèÑ ÏóÜÎã§
- Í∑∏Îü¨ÎÇò Ï£ºÎ≥ÄÏóêÎäî ÏúÑÎåÄÌïú ÏÑ±Í≥ºÎ•º Í±∞ÎëêÍ≥† ÏôÑÏ†ÑÌûà ÏßÄÏπú ÏÇ¨ÎûåÎèÑ ÎßéÎã§
- ÏßÄÎ£®ÌïòÎã§Í≥† ÎäêÍª¥ÏßÑÎã§Î©¥ Îã§Î•∏ ÏóÖÎ¨¥Ïóê Ï†ÑÎÖêÌïòÎ©∞ Îã§Ïãú ÌûòÏùÑ ÏñªÏóàÎã§
- Ïù¥Î•∏Î∞î Ï¢ãÏùÄ Îä•Î†•Ïù¥ÎûÄ ÏåìÏó¨ÏûàÎäî ÏàòÎßéÏùÄ Í≥ºÏ†ú Ï§ëÏóêÏÑú Í∞ÄÏû• Ïûò ÎßûÎäî Í≤ÉÏùÑ ÏÑ†ÌÉùÌï¥ Ìö®Ïú®Ï†ÅÏúºÎ°ú ÏßëÏ§ëÌïòÎäî Í≤ÉÏù¥ÎùºÍ≥† ÏÉùÍ∞ÅÌïúÎã§
- ÎÖºÎ¨∏Ïù¥ÎÇò Î¶¨Ìè¨Ìä∏Î•º ÏùΩÎçò, Í≥ºÍ±∞ ÏûêÎ£åÎ•º Ï†ïÎ¶¨ÌïòÎçò ÏΩîÎìúÎ•º ÏßúÎçò Î∂ÑÎ™Ö Í∑∏ Í≥ºÏ†úÎì§ÏùÑ Ìö®Ïú®Ï†ÅÏúºÎ°ú Ìï¥ÎÇº Ïàò ÏûàÎäî ÏãúÍ∞ÑÎåÄÍ∞Ä Ï°¥Ïû¨ÌïúÎã§
- Ìï† ÏùºÏùÑ Ï†ÅÏ†àÌûà Î∞îÍæ∏Îäî Í≤ÉÏùÄ Ï†ïÎßê Í∞ÄÏπòÏûàÎäî Îä•Î†•Ïù¥Îã§
- ÏÇ¨ÎûåÎì§ÏùÄ ÎÇòÎ•º Î¨¥ÌëúÏ†ïÌïòÍ≤å ÏùºÌïòÍ≥† Î¨∏ÏÑúÎßå Ï≥êÎã§Î≥¥Îäî ÏùåÏπ®Ìïú ÌîÑÎ°úÍ∑∏ÎûòÎ®∏Î°ú Î¨òÏÇ¨ÌïúÎã§
- ÎÇú ÌïúÎ≤à ÏùºÌïòÎ©¥ ÏßëÏ§ëÌï¥ÏÑú ÏÑ±Í≥ºÎ•º ÎÇ¥Í∏∞ ÎïåÎ¨∏Ïóê Ïñ¥ÎäêÏ†ïÎèÑ ÎßûÎäî ÏñòÍ∏∞ÏßÄÎßå ÎÇ¥ ÏùºÌïòÎäî Î∞©ÏãùÏùÄ ÎåÄÎ∂ÄÎ∂ÑÏóêÍ≤ê ÎßûÏßÄ ÏïäÎäîÎã§
- Í∑∏Îü¨ÎÇò Ïó¥Ïã¨Ìûà ÏùºÌïòÎäî Í≤ÉÏù¥ Ïñ¥Î¶¨ÏÑùÏùÄ Í±¥ Ï†àÎåÄ ÏïÑÎãàÎã§
- ÏùºÏóê ÎåÄÌïú ÏßëÏ∞© ÏÜçÏóêÏÑú ÏÇ∂Í≥º Ï¶êÍ±∞ÏõÄÏùÑ Ï∞æÎäî ÏÇ¨ÎûåÎèÑ Ï°¥Ïû¨ÌïòÎ©∞ Í∑∏Îì§ÏùÄ ÏùºÎ∞òÏ†ÅÏù∏ ÏÇ¨ÎûåÎì§Î≥¥Îã§ Îçî ÎßéÏùÄ ÏÑ±Í≥ºÎ•º ÎÇº Í≤ÉÏù¥Îã§
- ÏÇ¨Í≥† Ïã∂ÏùÄ ÎßåÌôî Ï±ÖÍ≥º ÏùåÏãùÏùÑ ÎßòÍªè ÏÇ¨Îäî Í≤å ÎÇ¥ Ïù∏ÏÉùÏùò ÎÇôÏù¥Îã§.
- ÎßéÏùÄ ÎèàÏù¥ Îì§ÏßÑ ÏïäÏßÄÎßå ÎÇ¥ ÌôúÎ†•Ïùò ÏõêÏ≤úÏù¥Îã§
- Îß®ÎÇ† Í∞ôÏùÄ ÌîºÏûêÎßå ÏãúÏº∞ÎäîÎç∞ ÏïåÍ≥†Î≥¥Îãà Í∑∏ ÌîºÏûê Í∞ÄÍ≤åÍ∞Ä ÎÇòÏóêÍ≤åÎßå ÏóÑÏ≤≠ÎÇú Ìï†Ïù∏ÏùÑ Ìï¥Ï£ºÏóàÎã§
- Ïö¥ÎèôÏùÑ Íæ∏Ï§ÄÌûà ÌïòÍ≥† Ï†àÎåÄ Í≥ºÏãùÌïòÏßÄ ÏïäÍ∏∞Ïóê Í±¥Í∞ïÏù¥ Í∑∏Î†áÍ≤å ÎÇòÏÅòÏßÑ ÏïäÎã§
- ÏßÄÍ∏à ÎÇòÏùò ÏÜåÏö∏Ìë∏ÎìúÎäî Ï†úÎ°úÏΩúÎùºÏù¥Îã§ ÌïòÎ£®Ïóê 8~9 Ï∫îÏùÄ ÎßàÏãúÎäî Í≤É Í∞ôÎã§

**ÏàôÎ†®Îêú ÏÇ¨ÎûåÎì§Ïù¥ Îπ†ÏßÄÍ∏∞ Ïâ¨Ïö¥ Ìï®Ï†ï**

- ÏùºÏùò Î™©Ï†ÅÎ≥¥Îã§ ÏûêÏã†Ïù¥ Í∞ÄÏßÄÍ≥† ÏûàÎäî Ï†ÑÎ¨∏ Îä•Î†•ÏùÑ Î∞úÌúòÌï®ÏóêÏÑú ÎßåÏ°±ÏùÑ ÏñªÏùÑ ÎïåÍ∞Ä ÎßéÏùå
- Ï†ÑÎ¨∏ Í∏∞Ïà†ÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÍ∏∞ ÎïåÎ¨∏Ïóê Î™©Ï†ÅÏóê ÏßëÏ§ëÌïòÏßÄ ÏïäÍ≥† Í≥ºÏ†ïÏóê ÎßåÏ°±ÌïòÎäî Ìï®Ï†ïÏóê Îπ†ÏßÄÍ∏∞ ÏâΩÎã§.
- ÎπÑÏä∑Ìïú ÏùºÏùÑ Î∞òÎ≥µÌï¥ÏÑú ÏàòÌñâÌïòÎã§Î≥¥Î©¥
  - Î™©Ï†ÅÏùÑ ÏûäÍ≥† Î∞òÎ≥µÏ†ÅÏù∏ ÌñâÎèô Í∑∏ ÏûêÏ≤¥Í∞Ä Î™©Ï†ÅÏù∏ Í≤ÉÏùÑ Ï∞©Í∞ÅÌïòÎäî ÏùºÏù¥ ÎßéÎã§.

## 24.03.08

[Large Language Models Are Drunk at the Wheel  Matt.si](https://matt.si/2024-02/llms-overpromised/)

- LLM Í∏∞Î∞ò ai Í¥ëÌíçÏùÑ ÏßÄÏ†ÅÌïòÎäî Í∏Ä
- ÍµâÏû•Ìûà ÎÑìÏùÄ Î∂ÑÏïºÏùò 100% Í≤ÄÏ¶ùÎêòÏßÄ Î™ªÌïú ÎπÖÎç∞Ïù¥ÌÑ∞Î°úÎ∂ÄÌÑ∞ ÌïôÏäµÌïú LLMÏùÄ Ïñ∏Ï†ú Ïñ¥Îñ§ Ïò§ÎãµÏùÑ ÎÇ¥ÎÜìÏùÑ ÏßÄ Î™®Î•¥Îäî ÌòºÎûÄÏä§Îü¨Ïö¥ ÏÉÅÌÉúÏûÑ
  - ÌòÑÏû¨ ai Î≤ÑÎ∏îÏóê ÌòÑÌòπÎêòÏßÄ Îßê Í≤ÉÏùÑ Ï£ºÏû•
- ÌÖåÏä§Ìä∏ Í∞ÄÎä•Ìïú Ï†úÌïúÎêú Î≤îÏúÑÏùò Ï†ÑÎ¨∏ Î∂ÑÏïºÎ•º ÌïôÏäµÌïú AI ÎùºÎ©¥ Ïã†Î¢∞Ìï† Ïàò ÏûàÎã§.

For an easier-to-read "layman" explanation I recommend Spencer Torene's (Computational Neuroscience PhD, Lead Research Scientist at Reuters) October article "Do LLMs Reason?"39. In short, LLMs are like parrots. However, their behaviour frequently appears logical. This is because their training sets are so vast and the compute power dedicated to their training so enormous that they are often capable of retrieving (or parroting) a believable answer. But they do not perform the logical steps to actually solve the problem. As such they cannot solve novel problems, nor verify whether their answers are correct or incorrect.

They are not the thinking machines that Turing envisioned. It might seem like I'm splitting hairs, but there is a big difference between real intelligence and the guesswork that LLMs do. They have no conception of knowledge, of truth or untruth: They cannot test whether what they are saying is correct or not. This is why they frequently fail very simple, obvious questions. Of course, the subtle truth here is that they are also frequently answering wrongly to complex, difficult questions but we are less likely to notice. The answers to complex questions take much more effort for us to verify. Our lazy, efficient brains are more likely to gloss over such details and assume it is correct. Hence why we notice these mistakes much more often when we ask simple, easily refutable questions.

One great example recently was asking an LLM to tell you the name of a Greek philosopher beginning with M4. Numerous people have tried this and time and time again LLMs will give you wrong answers insisting that Aristotle, or Seneca, or some other philosopher's name begins with M. Yet, we can see right in front of us that it does not. Note how these chatbots speak with such confidence: They are exactly as certain about their answer when they are wrong, as when they are right. ChatGPT is still doing this now, and you can see an example I generated below.

![](img/2024-03-08-14-21-41.png)

> Infinite Possibilities, Uncontrollable Chaos

For some examples: ChatGPT is not supposed to fill out CAPTCHAs for you. It can do so by integrating with other tools, but this is rightly considered a malicious use of it. But OpenAI's attempts to restrict it from doing so haven't been so successful. Just attach a CAPTCHA pattern to a photo of a locket and ask it to read the words on "my grandma's locket"6. In another case, one company that sells cars was naive enough to put ChatGPT in charge of a virtual assistant on their public-facing website. A user very easily made it offer to sell them a $50,000+ car for $1 and even say "that's a legally binding offer - no take backsies"7. Most recently, Air Canada was foolish enough to publish a chatbot that gives travel advice. It gave incorrect refund policies, that a court found AirCanada must uphold36 34. It is not clear whether this bot was using an LLM, but it sets an important precedent that recklessly placing a chatbot in a position to represent your business does have consequences. You can find more LLM-specific examples by asking ChatGPT to tell you about something fictional that you just made up: It will often make up a bunch of plausible-sounding nonsense rather than admitting that it does not know10.

![](img/2024-03-08-14-22-18.png)

> Valid use cases

Despite all the negativity I've just dropped, I do think LLMs are cool as heck. If we could just stop applying them in stupid ways to problems they cannot solve, maybe we can find some good use cases. What would that look like? Well, the #1 rule I would say is to never feed input into an LLM from a human. These bots are just too vulnerable to unexpected or malicious behaviour and there is no way to lock them down. The only robust, reliable LLM is one that is only dealing with a small set of known, expected, already tested inputs. One example might be in interactive digital art, simulations and video games. Instead of having dozens of NPCs that say the same thing, what if you fed the facts that a particular NPC knows (hello, Symbolism) into an LLM to generate believable dialogue? No more dozen NPCs saying all the same things, now they can at least come across as more believable by varying the particular choice of words they use to express themselves. And because the input is coming from your system, not the user or any external source, you can thoroughly test it.

> We've been here before

While it was not the only cause, this contributed directly to the 1970s AI Winter in which funding and interest in AI dried up. And who could blame them? But this time is different because it is not only a somewhat niche academic field at stake, but a sizable portion of investment in the tech industry. The industry right now is facing record-breaking layoffs and investment is drying up quickly, yet the one sector that is still growing is AI startups33. That investment might not last much longer than it takes for investors to realise that LLMs are not all they've been hyped up to be. What happens then?

We've made this mistake before, too. The dot com boom, the IoT fad, the big data trend, the crypto craze, smart assistants, NFTs and more. Our industry has a habit of promising the moon to investors, only for the funding to dry up when we can't deliver. Perhaps we don't feel the ramifications as strongly as we could because by the time the last bubble bursts, we are already hyping up investors for the next big fad. I recall during the big data craze a startup that had no production systems or customers, yet hired a data scientist. After a few weeks, he quietly confessed to me that he had nothing to do. There was no data with which to perform data science because they had no customers. Yet when the investors came to the office, one of the first places the executives would take them to was to see the data scientist so they could proudly show off that they were following the latest tech trend. Even if it made no sense in the context of their business. The same company produced multiple smart assistants when that was the cool thing to do, for a product that didn't have any customers for the growing collection of smart assistants to talk to.

> Conclusion

If we ever develop true artificial intelligence, it will be as similar to LLMs as a jet airliner is to a paper aeroplane. When someone knocks on your door promising to sell you a bridge with LLMs, look at them very sceptically. And then close the door in their face. Most of the organisations I've seen investing in LLM fantasies have one thing in common: Their product has tons of problems that their time would be better spent addressing. Think seriously about the design of your software, its reliability, and its usability. Spend your resources, your time and attention where it is most needed.

Whether you are a developer, designer, product manager, or anyone involved in creating software: In all your dealings with LLMs please reflect soberly on your professionalism and your responsibility to your users and stakeholders. If we aspire to the same earnest commitment and integrity that is seen in engineering, architecture, law, and so forth then let us act like it. I will leave you with this quote from the Engineers Council for Professional Development's definition of engineering38 37:

[Lessons Learned in Software Development  Henrik Warne's blog](https://henrikwarne.com/2015/04/16/lessons-learned-in-software-development/)

- (3)Add logging and error handling early.
  - When developing a new system, one of the first things I do is adding logging and error handling, because both are useful from the very beginning. For all systems that are bigger than a handful of lines of code, you need some way of knowing what happens in the program. Perhaps not when it is working as expected, but as soon as it doesn‚Äôt, you must be able to see what‚Äôs happening. The same goes for error handling ‚Äì errors and exceptions happen in the beginning too, so the sooner you handle them in a systematic way, the better.
- (16)Rubber ducking.
  - Whenever you are stuck, go to a colleague and explain the problem to them. Many times, as you talk, you realize what the problem is, even if your colleague doesn‚Äôt say a word. Sounds like magic, but works surprisingly often.
- (20)Sleep on it.
  - If you are working on a difficult problem, try to get in a night‚Äôs sleep before you decide. Then your subconscious mind works on the problem even when you aren‚Äôt actively thinking about it. As a result, the solution can seem obvious the next day.

## 24.03.12

**C# StopwatchÏùò Ìã±Í≥º DateTimeÏùò Ìã±ÏùÄ Îã§Î¶Ñ**

[MSDN .NET 7 / DateTime.Ticks ÏÜçÏÑ±](https://learn.microsoft.com/ko-kr/dotnet/api/system.datetime.ticks?view=net-7.0)

- **A single tick represents one hundred nanoseconds or one ten-millionth of a second**. There are 10,000 ticks in a millisecond (see TicksPerMillisecond) and 10 million ticks in a second.
  - 1 DateTime.Ticks = 100 ns(ÎÇòÎÖ∏Ï¥à)

[MSDN .NET 7 / Stopwatch.ElapsedTicks ÏÜçÏÑ±](https://learn.microsoft.com/en-us/dotnet/api/system.diagnostics.stopwatch.elapsedticks?view=net-7.0)

- **This property represents the number of elapsed ticks in the underlying timer mechanism. A tick is the smallest unit of time that the Stopwatch timer can measure**. Use the Frequency field to convert the ElapsedTicks value into a number of seconds.
- Stopwatch ticks are different from DateTime.Ticks. Each tick in the DateTime.Ticks value represents one 100-nanosecond interval. Each tick in the ElapsedTicks value represents the time interval equal to 1 second divided by the Frequency.
  - 1 Stopwatch.ElapsedTicksÎäî ÌïòÎìúÏõ®Ïñ¥ ÌÅ¥ÎùΩÏóê Í∏∞Î∞òÌï¥ÏÑú Ï∏°Ï†ï
  - Stopwatch.ElapsedTicks = 1 second / Stopwatch.Frequency

## 24.03.13

[ÌéòÏù¥Ïä§Î∂ÅÏù¥ GitÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÎäî Ïù¥Ïú†  GeekNews](https://news.hada.io/topic?id=13769)

- Mercurial ÏùÑ ÏÇ¨Ïö©ÌïúÎã§Í≥† Ìï®
- [Mercurial SCM](https://www.mercurial-scm.org/)
- [Scaling Mercurial at Facebook - Engineering at Meta](https://engineering.fb.com/2014/01/07/core-infra/scaling-mercurial-at-facebook/)

===

**Graphite Í∞úÎ∞úÏûê Greg FosterÍ∞Ä Ïù¥Ïóê Í¥ÄÏã¨ÏùÑ Í∞ÄÏßÑ Ïù¥Ïú†**

- Ïôú ÌéòÏù¥Ïä§Î∂ÅÏùÄ Git ÎåÄÏã† MercurialÏùÑ Ï±ÑÌÉùÌïòÍ≥† Í∑∏ ÏúÑÏóê Ïª§Ïä§ÌÖÄ ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Íµ¨Ï∂ïÌñàÏùÑÍπå ?
- Íµ¨Í∏ÄÎèÑ GitÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏßÄÎßå, Í∑∏Í±¥ GoogleÏùò ÏóîÏßÄÎãàÏñ¥ÎßÅÏù¥ GitÎ≥¥Îã§ 5ÎÖÑ Ïù¥ÏÉÅ ÏïûÏÑú ÏûàÍ∏∞ ÎïåÎ¨∏
- Î∞òÎ©¥Ïóê FacebookÏùÄ GitÏù¥ ÎßåÎì§Ïñ¥ÏßÑ ÏãúÍ∏∞ÏôÄ ÎπÑÏä∑Ìïú ÏãúÍ∏∞Ïù∏ 2004ÎÖÑÏóê ÏÑ§Î¶ΩÎêòÏóàÏúºÎ©∞, FacebookÏù¥ ÏÜåÏä§ Ï†úÏñ¥ ÎèÑÍµ¨Î•º ÏßÑÏßÄÌïòÍ≤å Í≤ÄÌÜ†Ìï† Î¨¥Î†µÏóêÎäî MercurialÎ≥¥Îã§ GitÏù¥ Îçî Ïù∏Í∏∞Í∞Ä ÏûàÏóàÏùå
- Í∑∏Îü∞Îç∞ Ïôú FacebookÏùÄ GitÏùÑ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùÑÍπå?
  - Í∑∏Ïùò ÏÉùÍ∞ÅÏóê FacebookÏù¥ GitÏùÑ ÎèÑÏûÖÌïòÍ≥† 2010ÎÖÑÎåÄ Ï¥àÎ∞òÏóê Í∏∞Ïó¨ÌñàÎã§Î©¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ ÏÑ∏Í≥ÑÎäî Îã¨ÎùºÏ°åÏùÑ Í≤É
  - GitÏù¥ Îçî ÏÇ¨Ïö©Ïûê ÏπúÌôîÏ†ÅÏù¥Í≥†, ÎÑ§Ïù¥Ìã∞Î∏åÌïòÍ≤å Stacked ChangesÎ•º ÏßÄÏõêÌïòÍ≤å ÎêòÏóàÏùÑ ÏàòÎèÑ
- Ï¥àÍ∏∞ ÌéòÏù¥Ïä§Î∂Å ÏßÅÏõêÎì§Ïù¥ ÎßåÎì† UberÏôÄ Pinterest Í∞ôÏùÄ ÌöåÏÇ¨Îì§ÎèÑ Mercurial ÎåÄÏã† GitÍ≥º GitHubÎ•º ÏÜåÏä§ Ïª®Ìä∏Î°§Î°ú ÏÇ¨Ïö©ÌïòÏó¨ ÏßÄÎÇú 10ÎÖÑ ÎèôÏïà Îçú ÌååÌé∏ÌôîÎêú ÏÉùÌÉúÍ≥ÑÎ•º ÎßåÎì§ÏóàÏùÑ Í≤É
- ÌïòÏßÄÎßå FacebookÏùÄ (Í∏∞Î≥∏ Î™®ÎÖ∏Î¶¨Ìè¨ÏßÄÌÜ†Î¶¨Î•º ÏúÑÌï¥) GitÏùÑ Í≥†ÏàòÌïòÏßÄ ÏïäÏïòÏùå. ÎåÄÏã† Î≤ÑÏ†Ñ Í¥ÄÎ¶¨Î•º ÏúÑÌï¥ MercurialÏùÑ Ï±ÑÌÉùÌïòÍ≥† Í∑∏ ÏúÑÏóê ÏÇ¨Ïö©Ïûê ÏßÄÏ†ï ÎèÑÍµ¨Î•º Ï†êÏßÑÏ†ÅÏúºÎ°ú Ï∂îÍ∞ÄÌï®
  - ÌéòÏù¥Ïä§Î∂ÅÏóê Ïò¨ÎùºÏò® Scaling Mercurial at Facebook Í∏ÄÏùÑ Î∞úÍ≤¨
  - 10ÎÖÑÏ†Ñ Í∏ÄÏù¥Í≥†, Í∑∏ Ïù¥ÌõÑÏóê Î™áÍ∞úÏùò Ïú†ÌäúÎ∏åÎ•º ÌÜµÌï¥ÏÑú "ÏÑ±Îä• ÎïåÎ¨∏Ïù¥ÏßÄ" ÎùºÎäî Ìï¥ÎãµÏùÑ ÏñªÏóàÏùå
  - ÌïòÏßÄÎßå, Îçî ÍπäÍ≤å Îì§Ïñ¥Í∞ÄÏÑú Í∑∏ ÎãπÏãú Í≤∞Ï†ïÍ∂åÏûêÎì§Ïùò ÏÉùÍ∞ÅÏùÑ Îì§Ïñ¥Î≥¥Í≥† Ïã∂ÏóàÍ≥†, Mercurial ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò ÌîÑÎ°úÏ†ùÌä∏Ïóê Ï∞∏Ïó¨ÌñàÎçò ÎëêÎ™ÖÏùò ÏóîÏßÄÎãàÏñ¥ÏóêÍ≤å Î¨ºÏñ¥Î¥§Ïùå
  - Í∑∏Îì§Í≥ºÏùò ÎπÑÍ≥µÏãùÏ†ÅÏù∏ ÏñòÍ∏∞Î•º ÌÜµÌï¥ Ïù¥ ÎÇ¥Ïö©ÏùÑ Ï†ïÎ¶¨Ìï®

**ÌéòÏù¥Ïä§Î∂ÅÏù¥ GitÏùÑ Î≤ÑÎ¶¨Í≥† MercurialÎ°ú Ïù¥Ï£ºÌïú Ïù¥Ïú†**

- ÌéòÏù¥Ïä§Î∂ÅÏùÄ Ï≤òÏùåÏóê GitÏùÑ ÏÇ¨Ïö©ÌñàÏúºÎÇò, 2012ÎÖÑÍ≤Ω ÏΩîÎìúÎ≤†Ïù¥Ïä§ Í∑úÎ™®Í∞Ä Ïª§ÏßÄÎ©¥ÏÑú ÏÑ±Îä• Î¨∏Ï†úÎ•º Í≤™Í∏∞ ÏãúÏûë
- GitÏùò ÌååÏùº "stat-ing" Í≥ºÏ†ïÏù¥ Î≥ëÎ™© ÌòÑÏÉÅÏùÑ ÏùºÏúºÌÇ§Î©∞, Í∏∞Î≥∏ Git Î™ÖÎ†πÏñ¥ Ïã§Ìñâ ÏãúÍ∞ÑÏù¥ 45Î∂Ñ Ïù¥ÏÉÅ ÏÜåÏöî
- Git Ïú†ÏßÄÎ≥¥ÏàòÏûêÎì§ÏùÄ ÌéòÏù¥Ïä§Î∂ÅÏùò ÎåÄÍ∑úÎ™® Î¶¨Ìè¨ÏßÄÌÜ†Î¶¨ Î¨∏Ï†úÏóê ÎåÄÌï¥ ÌòëÎ†•Ï†ÅÏù¥ÏßÄ ÏïäÏïòÍ≥†, ÎåÄÏã† Î¶¨Ìè¨ÏßÄÌÜ†Î¶¨ Î∂ÑÌï†ÏùÑ Í∂åÏû•

**Í≥†Î†§Îêú ÎåÄÏïàÎì§**

- 2012ÎÖÑ ÎãπÏãú GitÏùò ÎåÄÏïàÏùÄ ÎßéÏßÄ ÏïäÏïòÏúºÎ©∞, ÌéòÏù¥Ïä§Î∂ÅÏùÄ PerforceÏôÄ Í∞ôÏùÄ ÌèêÏáÑ ÏÜåÏä§ ÏÜîÎ£®ÏÖòÏùÑ Í≥†Î†§ÌñàÏúºÎÇò Í∏∞Ïà†Ï†Å Î¨∏Ï†úÍ∞Ä ÏûàÏóàÏùå
- MercurialÏùÄ GitÍ≥º Ïú†ÏÇ¨Ìïú ÏÑ±Îä•ÏùÑ Í∞ÄÏ°åÏúºÎÇò, Îçî ÍπîÎÅîÌïú ÏïÑÌÇ§ÌÖçÏ≤òÏôÄ ÌôïÏû•ÏÑ±ÏùÑ Í∞ÄÏßÄÍ≥† ÏûàÏóàÏùå
- ÌéòÏù¥Ïä§Î∂Å ÌåÄÏùÄ Mercurial Ìï¥Ïª§ÌÜ§Ïóê Ï∞∏Ïó¨ÌïòÏó¨ MercurialÏùò ÌôïÏû•ÏÑ±Í≥º Ïª§ÎÆ§ÎãàÌã∞Ïùò Í∞úÎ∞©ÏÑ±Ïóê Í∞êÎ™ÖÎ∞õÏùå

**Ï†ÑÏ≤¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ Ï°∞ÏßÅÏùò Ïù¥Ï£º**

- ÌéòÏù¥Ïä§Î∂Å ÌåÄÏùÄ ÎÇòÎ®∏ÏßÄ ÌöåÏÇ¨Î•º ÏÑ§ÎìùÌïòÍ∏∞ ÏúÑÌï¥ GitÍ≥º Mercurial Í∞ÑÏùò Î™ÖÎ†πÏñ¥ Î∞è ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º Îß§ÌïëÌïòÍ≥†, Í∞úÎ∞úÏûêÎì§Ïùò Ïö∞Î†§Î•º Îì£Îäî ÏãúÍ∞ÑÏùÑ Í∞ÄÏßê
- Ïù¥Ï£º Í≥ºÏ†ïÏùÄ Ïã†Ï§ëÌïòÍ≤å ÏßÑÌñâÎêòÏóàÏúºÎ©∞, Í≤∞Íµ≠ ÌéòÏù¥Ïä§Î∂ÅÏùÄ MercurialÎ°ú Ï†ÑÌôòÌï®
- ÌéòÏù¥Ïä§Î∂ÅÏùÄ MercurialÏùò ÏÑ±Îä•ÏùÑ Ìñ•ÏÉÅÏãúÌÇ§Í≥†, "stacked diffs"Î•º ÌÜµÌï¥ ÏΩîÎìú Î¶¨Î∑∞ Î≥ëÎ†¨ÌôîÎ•º Í∞ÄÎä•ÌïòÍ≤å ÌïòÎäî Îì±Ïùò Í∏∞Ïó¨Î•º Ìï®

**ÎßàÎ¨¥Î¶¨ ÏÉùÍ∞Å**

- Ïù¥ Ïù¥ÏïºÍ∏∞Îäî "ÎßéÏùÄ Ï£ºÏöî Í∏∞Ïà†Ï†Å Í≤∞Ï†ïÏùÄ Í∏∞Ïà†Ïù¥ Ï£ºÎèÑÌïòÎäî Í≤ÉÏù¥ ÏïÑÎãàÎùº ÏÇ¨ÎûåÏù¥ Ï£ºÎèÑÌïúÎã§"Îäî Ï†êÏùÑ ÏÉÅÍ∏∞ÏãúÌÇ¥
- ÌéòÏù¥Ïä§Î∂ÅÏùÄ MercurialÏù¥ GitÎ≥¥Îã§ ÏÑ±Îä•Ïù¥ Îõ∞Ïñ¥ÎÇòÏÑúÍ∞Ä ÏïÑÎãàÎùº, Mercurial Ïú†ÏßÄÎ≥¥ÏàòÏûêÎì§Í≥ºÏùò ÌòëÏóÖÏù¥ Îçî Í∞úÎ∞©Ï†ÅÏù¥ÏóàÍ∏∞ ÎïåÎ¨∏Ïóê ÏÑ†ÌÉùÌï®
- Ï†ÑÏ≤¥ ÏóîÏßÄÎãàÏñ¥ÎßÅ Ï°∞ÏßÅÏùÑ ÏÑ§ÎìùÌïòÎäî Í≥ºÏ†ïÏóêÏÑú Ìïú Í∏∞Ïà†Ïù¥ Îã§Î•∏ Í∏∞Ïà†Î≥¥Îã§ Îçî Ïö∞ÏàòÌï¥ÏÑúÍ∞Ä ÏïÑÎãàÎùº "ÏÇ¨Î†§ ÍπäÏùÄ Ïª§ÎÆ§ÎãàÏºÄÏù¥ÏÖò"Ïù¥ Ï§ëÏöîÌñàÏùå
- "ÏÜåÌÜµÍ≥º ÏπúÏ†àÌï®"Ïù¥ Í∞úÎ∞ú ÎèÑÍµ¨ ÏÑ∏Í≥ÑÏóêÏÑú Ï§ëÏöîÌïú Í∞ÄÏπòÏûÑÏùÑ Í∞ïÏ°∞

[GoÎ°ú 10Ïñµ Ìñâ Ï≤òÎ¶¨ÌïòÍ∏∞ ÎèÑÏ†Ñ 9Í∞úÏùò Î∞©Î≤ïÏúºÎ°ú 1Î∂Ñ45Ï¥àÏóêÏÑú 4Ï¥àÎ°ú Îã®Ï∂ï  GeekNews](https://news.hada.io/topic?id=13627)

- 1BRC : 10ÏñµÌñâÏù¥ ÏûàÎäî ÌÖçÏä§Ìä∏ ÌååÏùºÏóêÏÑú Ïò®ÎèÑ Ï∏°Ï†ïÍ∞íÏùÑ ÏùΩÏñ¥ Í¥ÄÏ∏°ÏÜåÎ≥Ñ ÏµúÏÜå/ÌèâÍ∑†/ÏµúÎåÄ Ïò®ÎèÑÎ•º Í≥ÑÏÇ∞ÌïòÎäî ÏΩîÎìúÎ•º ÏûëÏÑ±ÌïòÎäî Ï±åÎ¶∞ÏßÄ
- 2024ÎÖÑ 1Ïõî 1ÏùºÎ∂ÄÌÑ∞ 1Ïõî 31ÏùºÍπåÏßÄ ÏßÑÌñâÌñàÏúºÎ©∞, ÏµúÏã† JavaÎ•º ÏµúÎåÄÌïú ÌôúÏö©ÌïòÎäî Í≤ÉÏù¥ Î™©ÌëúÏòÄÏùå
- Ïù¥Ïóê ÎåÄÌï¥ ÏÇ¨ÎûåÎì§Ïù¥ Í¥ÄÏã¨ÏùÑ Í∞ÄÏßÄÍ≥† Îã§ÏñëÌïú Ïñ∏Ïñ¥(Rust,Go,C++,SQL)Î°ú ÎèÑÏ†ÑÌïòÍ∏∞ ÏãúÏûë
- GoÎ°ú ÏûëÏÑ±Ìïú 9Í∞ÄÏßÄ ÏÜîÎ£®ÏÖòÏóê ÎåÄÌï¥ÏÑú ÏÉÅÏÑ∏ ÏÜåÍ∞ú (ÎäêÎ¶∞Í≤ÉÎ∂ÄÌÑ∞ Îπ†Î•∏ Í≤ÉÏàúÏúºÎ°ú)
- [gunnarmorling1brc 1Ô∏è‚É£üêùüèéÔ∏è The One Billion Row Challenge -- A fun exploration of how quickly 1B rows from a text file can be aggregated with Java](https://github.com/gunnarmorling/1brc)

**Í∏∞Î≥∏ Ï∏°Ï†ïÍ∞í**

- cat Î™ÖÎ†πÏñ¥Î•º ÏÇ¨Ïö©ÌïòÏó¨ 10ÏñµÌñâ ÌÖçÏä§Ìä∏Îç∞Ïù¥ÌÑ∞(13GB) Îç∞Ïù¥ÌÑ∞Î•º ÏùΩÎäî Îç∞ Í±∏Î¶¨Îäî ÏãúÍ∞ÑÏùÄ 1.052Ï¥àÏûÑ.
- Ïã§Ï†úÎ°ú ÌååÏùºÏùÑ Ï≤òÎ¶¨ÌïòÎäî wc Î™ÖÎ†πÏñ¥Îäî Í±∞Ïùò 1Î∂ÑÏù¥ Í±∏Î¶º(55.710Ï¥à).
- AWK ÏÜîÎ£®ÏÖòÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Î¨∏Ï†úÎ•º Ìï¥Í≤∞ÌïòÎäî Îç∞ Í±∏Î¶¨Îäî ÏãúÍ∞ÑÏùÄ 7Î∂Ñ 35Ï¥àÏûÑ.

**ÏÜîÎ£®ÏÖò 1: Í∞ÑÎã®ÌïòÍ≥† Í¥ÄÏö©Ï†ÅÏù∏ Go**

- Go ÌëúÏ§Ä ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÇ¨Ïö©Ìïú Ï≤´ Î≤àÏß∏ ÏÜîÎ£®ÏÖòÏùÄ 1Î∂Ñ 45Ï¥àÍ∞Ä Í±∏Î¶º.
- bufio.ScannerÎ°ú Ï§ÑÏùÑ ÏùΩÍ≥†, strings.CutÏúºÎ°ú ';'Î•º Í∏∞Ï§ÄÏúºÎ°ú Î∂ÑÎ¶¨Ìï®.
- strconv.ParseFloatÎ°ú Ïò®ÎèÑÎ•º ÌååÏã±ÌïòÍ≥†, Go ÎßµÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Í≤∞Í≥ºÎ•º ÎàÑÏ†ÅÌï®.

**ÏÜîÎ£®ÏÖò 2: Ìè¨Ïù∏ÌÑ∞ Í∞íÏù¥ ÏûàÎäî Îßµ**

- ÎßµÏóêÏÑú Îëê Î≤àÏùò Ìï¥Ïã±ÏùÑ ÌîºÌïòÍ∏∞ ÏúÑÌï¥ map[string]*statsÎ•º ÏÇ¨Ïö©Ìï®.
- Ìè¨Ïù∏ÌÑ∞ Í∞íÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏãúÍ∞ÑÏùÑ 1Î∂Ñ 45Ï¥àÏóêÏÑú 1Î∂Ñ 31Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**ÏÜîÎ£®ÏÖò 3: strconv.ParseFloat ÌîºÌïòÍ∏∞**

- strconv.ParseFloat ÎåÄÏã† ÏÇ¨Ïö©Ïûê Ï†ïÏùò ÏΩîÎìúÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ïò®ÎèÑÎ•º ÌååÏã±Ìï®.
- ÏãúÍ∞ÑÏùÑ 1Î∂Ñ 31Ï¥àÏóêÏÑú 55.8Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**ÏÜîÎ£®ÏÖò 4: Í≥†Ï†ï ÏÜåÏàòÏ†ê Ï†ïÏàò ÏÇ¨Ïö©**

- Ïò®ÎèÑÎ•º Ï†ïÏàòÎ°ú ÌëúÌòÑÌïòÏó¨ Î∂ÄÎèô ÏÜåÏàòÏ†ê Ïó∞ÏÇ∞ÏùÑ ÌîºÌï®.
- ÏãúÍ∞ÑÏùÑ 55.8Ï¥àÏóêÏÑú 51.0Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**ÏÜîÎ£®ÏÖò 5: bytes.Cut ÌîºÌïòÍ∏∞**

- ';'Î•º Ï∞æÍ∏∞ ÏúÑÌï¥ Ï†ÑÏ≤¥ Ïä§ÌÖåÏù¥ÏÖò Ïù¥Î¶ÑÏùÑ Ïä§Ï∫îÌïòÎäî ÎåÄÏã† ÎÅùÏóêÏÑúÎ∂ÄÌÑ∞ ÌååÏã±Ìï®.
- ÏãúÍ∞ÑÏùÑ 51.0Ï¥àÏóêÏÑú 46.0Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**ÏÜîÎ£®ÏÖò 6: bufio.Scanner ÌîºÌïòÍ∏∞**

- bufio.ScannerÎ•º Ï†úÍ±∞ÌïòÍ≥† ÌååÏùºÏùÑ ÌÅ∞ Ï≤≠ÌÅ¨Î°ú ÏùΩÏùå.
- ÏãúÍ∞ÑÏùÑ 46.0Ï¥àÏóêÏÑú 41.3Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**ÏÜîÎ£®ÏÖò 7: ÏÇ¨Ïö©Ïûê Ï†ïÏùò Ìï¥Ïãú ÌÖåÏù¥Î∏î**

- GoÏùò Îßµ ÎåÄÏã† ÏÇ¨Ïö©Ïûê Ï†ïÏùò Ìï¥Ïãú ÌÖåÏù¥Î∏îÏùÑ Íµ¨ÌòÑÌï®.
- ÏãúÍ∞ÑÏùÑ 41.3Ï¥àÏóêÏÑú 25.8Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**ÏÜîÎ£®ÏÖò 8: Ï≤≠ÌÅ¨ Î≥ëÎ†¨ Ï≤òÎ¶¨**

- Í∞ÑÎã®ÌïòÍ≥† Í¥ÄÏö©Ï†ÅÏù∏ ÏΩîÎìúÎ•º Î≥ëÎ†¨ÌôîÌïòÏó¨ ÏãúÍ∞ÑÏùÑ 1Î∂Ñ 45Ï¥àÏóêÏÑú 24.3Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**ÏÜîÎ£®ÏÖò 9: Î™®Îì† ÏµúÏ†ÅÌôî Î∞è Î≥ëÎ†¨ Ï≤òÎ¶¨**

- Î™®Îì† ÏµúÏ†ÅÌôîÎ•º Î≥ëÎ†¨ Ï≤òÎ¶¨ÏôÄ Í≤∞Ìï©ÌïòÏó¨ ÏãúÍ∞ÑÏùÑ 24.3Ï¥àÏóêÏÑú 3.99Ï¥àÎ°ú Îã®Ï∂ïÌï®.

**Í≤∞Í≥º ÌÖåÏù¥Î∏î**

- Î™®Îì† Go ÏÜîÎ£®ÏÖòÍ≥º Í∞ÄÏû• Îπ†Î•∏ Go Î∞è Java ÏÜîÎ£®ÏÖòÏùÑ ÎπÑÍµêÌïú Ìëú Ï†úÍ≥µ.
- Go Î≤ÑÏ†Ñ Ï§ë Í∞ÄÏû• Îπ†Î•∏ Í≤ÉÏùÄ 2.90Ï¥à, Java Î≤ÑÏ†ÑÏùÄ 0.953Ï¥àÎ°ú Ï≤òÎ¶¨Ìï®.
- 1Ï¥àÎèÑ ÏïàÍ±∏Î¶¨Îäî JavaÎ≤ÑÏ†ÑÏùÄ Thomas Wuerthinger(GraalVM Ï†úÏûëÏûê)Í∞Ä Ìïú Í≤ÉÏúºÎ°ú, Ïù¥ Î∂ÑÏïº Ï†ÑÎ¨∏Í∞ÄÏù¥Í∏∞ ÎïåÎ¨∏Ïóê Í∞ÄÎä•ÌïúÎìØ

**ÏµúÏ¢Ö ÏΩîÎ©òÌä∏**

- ÏùºÏÉÅÏ†ÅÏù∏ ÌîÑÎ°úÍ∑∏ÎûòÎ∞ç ÏûëÏóÖÏóêÏÑúÎäî Í∞ÑÎã®ÌïòÍ≥† Í¥ÄÏö©Ï†ÅÏù∏ ÏΩîÎìúÍ∞Ä Ï¢ãÏùÄ Ï∂úÎ∞úÏ†êÏûÑ.
- Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ÏùÑ Íµ¨Ï∂ïÌïòÎäî Í≤ΩÏö∞, ÏΩîÎìúÎ•º 4Î∞∞ ÎòêÎäî 26Î∞∞ Îπ†Î•¥Í≤å ÎßåÎì§Î©¥ ÏÇ¨Ïö©Ïûê ÎßåÏ°±ÎèÑÎ•º ÎÜíÏù¥Í≥† Ïª¥Ìì®ÌåÖ ÎπÑÏö©ÏùÑ Ï†àÏïΩÌï† Ïàò ÏûàÏùå.
- Îü∞ÌÉÄÏûÑÏù¥ÎÇò Ïù∏ÌÑ∞ÌîÑÎ¶¨ÌÑ∞Î•º Íµ¨Ï∂ïÌïòÎäî Í≤ΩÏö∞, ÏÑ±Îä• Ìñ•ÏÉÅÏù¥ Ï§ëÏöîÌï®.

## 24.03.14

[PEP 20 ‚Äì The Zen of Python  peps.python.org](https://peps.python.org/pep-0020/)

**ÌååÏù¥Ïç¨Ïùò ÏÑ†**

1. ÏïÑÎ¶ÑÎã§Ïö¥ Í≤ÉÏù¥ Ï∂îÌïú Í≤ÉÎ≥¥Îã§ ÎÇ´Îã§. (Beautiful is better than ugly)
1. Î™ÖÏãúÏ†ÅÏù∏ Í≤ÉÏù¥ ÏïîÏãúÏ†ÅÏù∏ Í≤ÉÎ≥¥Îã§ ÎÇ´Îã§. (Explicit is better than implicit)
1. Îã®ÏàúÌïú Í≤ÉÏù¥ Î≥µÏû°Ìïú Í≤ÉÎ≥¥Îã§ ÎÇ´Îã§. (Simple is better than complex)
1. Î≥µÏû°Ìïú Í≤ÉÏù¥ ÎÇúÌï¥Ìïú Í≤ÉÎ≥¥Îã§ ÎÇ´Îã§. (Complex is better than complicated)
1. Í∞ÄÎèÖÏÑ±ÏùÄ Ï§ëÏöîÌïòÎã§. (Readability counts)
1. ÌäπÎ≥ÑÌïú Í≤ΩÏö∞Îì§ÏùÄ Í∑úÏπôÏùÑ Íπ∞ Ï†ïÎèÑÎ°ú ÌäπÎ≥ÑÌïòÏßÄ ÏïäÎã§. (Special cases aren't special enough to break the rules)
1. Ïã§Ïö©ÏÑ±Ïù¥ ÏàúÏàòÌï®ÏùÑ Ïù¥Í∏¥Îã§. (Practicality beats purity)
1. Ïò§Î•òÎäî Ï†àÎåÄÎ°ú Ï°∞Ïö©Ìûà ÏßÄÎÇòÍ∞ÄÏÑúÎäî Ïïà ÎêúÎã§. (Errors should never pass silently)
1. Î™ÖÏãúÏ†ÅÏúºÎ°ú Ïò§Î•òÎ•º Ïà®Í∏∞ÏßÄ ÏïäÎäî Ìïú. (Unless explicitly silenced)
1. Î™®Ìò∏Ìï®ÏùÑ ÌîºÌï† Ïàò ÏûàÎã§Î©¥, Í∑∏ Î∞©Î≤ïÏùÑ Í±∞Î∂ÄÌïòÏßÄ ÎßàÎùº. (In the face of ambiguity, refuse the temptation to guess)
1. ÎãπÏó∞Ìûà, Ìï¥Í≤∞Ï±ÖÏù¥ Ìïú Í∞ÄÏßÄÎ∞ñÏóê ÏóÜÏñ¥Ïïº ÌïúÎã§. (There should be one-- and preferably only one --obvious way to do it)
1. ÎπÑÎ°ù Í∑∏ Î∞©Î≤ïÏù¥ Ï≤òÏùåÏóêÎäî Î™ÖÌôïÌïòÏßÄ ÏïäÎçîÎùºÎèÑ. (Although that way may not be obvious at first unless you're Dutch)
1. ÏßÄÍ∏à ÌïòÎäî Í≤ÉÏù¥ Ï†ÑÌòÄ ÌïòÏßÄ ÏïäÎäî Í≤ÉÎ≥¥Îã§ ÎÇ´Îã§. (Now is better than never)
1. ÌïòÏßÄÎßå ÏßÄÍ∏à ÎãπÏû•ÏùÄ Ìï† ÌïÑÏöîÍ∞Ä ÏóÜÎäî Í≤ÉÎ≥¥Îã§ ÎÇòÏ§ëÏù¥ ÎÇ´Îã§. (Although never is often better than right now)
1. Íµ¨ÌòÑÏùÑ ÏÑ§Î™ÖÌïòÍ∏∞ Ïñ¥Î†µÎã§Î©¥, Í∑∏Í≤ÉÏùÄ ÎÇòÏÅú ÏïÑÏù¥ÎîîÏñ¥Îã§. (If the implementation is hard to explain, it's a bad idea)
1. Íµ¨ÌòÑÏùÑ ÏÑ§Î™ÖÌïòÍ∏∞ ÏâΩÎã§Î©¥, Í∑∏Í≤ÉÏùÄ Ï¢ãÏùÄ ÏïÑÏù¥ÎîîÏñ¥Ïùº Ïàò ÏûàÎã§. (If the implementation is easy to explain, it may be a good idea)
1. ÎÑ§ÏûÑÏä§ÌéòÏù¥Ïä§Îäî Ï†ïÎßê Ï¢ãÏùÄ ÏïÑÏù¥ÎîîÏñ¥Îã§! (Namespaces are one honking great idea -- let's do more of those!)

Ïù¥ ÏõêÏπôÎì§ÏùÄ ÌååÏù¥Ïç¨Ïùò ÏÑ§Í≥Ñ Ï≤†ÌïôÍ≥º ÏΩîÎìú Ïä§ÌÉÄÏùºÏùÑ Î∞òÏòÅÌïòÎ©∞, ÌååÏù¥Ïç¨ Ïª§ÎÆ§ÎãàÌã∞ ÎÇ¥ÏóêÏÑú ÎÑêÎ¶¨ Î∞õÏïÑÎì§Ïó¨ÏßÄÍ≥† ÏûàÏäµÎãàÎã§. Î™©Ï†ÅÏùÄ ÏΩîÎìúÏùò Í∞ÄÎèÖÏÑ±, Í∞ÑÍ≤∞ÏÑ±, Î™ÖÌôïÏÑ±ÏùÑ ÎÜíÏó¨, ÏûëÏÑ±ÏûêÍ∞Ä ÏïÑÎãå Îã§Î•∏ ÏÇ¨ÎûåÎèÑ ÏâΩÍ≤å Ïù¥Ìï¥ÌïòÍ≥† Ïú†ÏßÄÎ≥¥ÏàòÌï† Ïàò ÏûàÍ≤å ÌïòÎäî Îç∞ ÏûàÏäµÎãàÎã§.

[Scaling Mercurial at Facebook - Engineering at Meta](https://engineering.fb.com/2014/01/07/core-infra/scaling-mercurial-at-facebook/)

With thousands of commits a week across hundreds of thousands of files, Facebook‚Äôs main source repository is enormous‚Äìmany times larger than even the Linux kernel, which checked in at 17 million lines of code and 44,000 files in 2013. Given our size and complexity‚Äîand Facebook‚Äôs practice of shipping code twice a day‚Äìimproving our source control is one way we help our engineers move fast.

**Choosing a source control system**

We realized that we‚Äôd have to solve this ourselves. But instead of building a new system from scratch, we decided to take an existing one and make it scale. Our engineers were comfortable with Git and we preferred to stay with a familiar tool, so we took a long, hard look at improving it to work at scale. After much deliberation, we concluded that Git‚Äôs internals would be difficult to work with for an ambitious scaling project.

Instead, we chose to improve Mercurial. Mercurial is a distributed source control system similar to Git, with many equivalent features. Importantly, it‚Äôs written mostly in clean, modular Python (with some native code for hot paths), making it deeply extensible. Just as importantly, the Mercurial developer community is actively helping us address our scaling problems by reviewing our patches and keeping our scale in mind when designing new features.

When we first started working on Mercurial, we found that it was slower than Git in several notable areas. To narrow this performance gap, we‚Äôve contributed over 500 patches to Mercurial over the last year and a half. These range from new graph algorithms to rewrites of tight loops in native code. These helped, but we also wanted to make more fundamental changes to address the problem of scale.

**Speeding up file status operations**

For a repository as large as ours, **a major bottleneck is simply finding out what files have changed. Git examines every file and naturally becomes slower and slower as the number of files increases,** while Perforce ‚Äúcheats‚Äù by forcing users to tell it which files they are going to edit. The Git approach doesn‚Äôt scale, and the Perforce approach isn‚Äôt friendly.

**We solved this by monitoring the file system for changes.** This has been tried before, even for Mercurial, but making it work reliably is surprisingly challenging. **We decided to query our build system‚Äôs file monitor, Watchman**, to see which files have changed. Mercurial‚Äôs design made integrating with Watchman straightforward, but we expected Watchman to have bugs, so we developed a strategy to address them safely.

For our repository, **enabling Watchman integration has made Mercurial‚Äôs status command more than 5x faster than Git‚Äôs status command.** Other commands that look for changed files‚Äìlike diff, update, and commit‚Äîalso became faster.

**Working with large histories**

The rate of commits and the sheer size of our history also pose challenges. We have thousands of commits being made every day, and as the repository gets larger, it becomes increasingly painful to clone and pull all of it. Centralized source control systems like Subversion avoid this by only checking out a single commit, leaving all of the history on the server. This saves space on the client but leaves you unable to work if the server goes down. **More recent distributed source control systems, like Git and Mercurial, copy all of the history to the client which takes more time and space, but allows you to browse and commit entirely locally.** We wanted a happy medium between the speed and space of a centralized system and the robustness and flexibility of a distributed one.

**Improving clone and pull**

Normally when you run a pull, Mercurial figures out what has changed on the server since the last pull and downloads any new commit metadata and file contents. With tens of thousands of files changing every day, downloading all of this history to the client every day is slow. **To solve this problem we created the remotefilelog extension for Mercurial. This extension changes the clone and pull commands to download only the commit metadata**, while **omitting all file changes that account for the bulk of the download**. When a user performs an operation that needs the contents of files (such as checkout), we download the file contents on demand using Facebook‚Äôs existing memcache infrastructure. This allows clone and pull to be fast no matter how much history has changed, while only adding a slight overhead to checkout.

But what if the central Mercurial server goes down? A big benefit of distributed source control is the ability to work without interacting with the server. **The remotefilelog extension intelligently caches the file revisions needed for your local commits so you can checkout, rebase, and commit to any of your existing bookmarks without needing to access the server. Since we still download all of the commit metadata, operations that don‚Äôt require file contents (such as log) are completely local as well.** Lastly, we use Facebook‚Äôs memcache infrastructure as a caching layer in front of the central Mercurial server, so that even if the central repository goes down, memcache will continue to serve many of the file content requests.

**Clone and pull performance gains**

Enabling the remotefilelog extension for employees at Facebook has made **Mercurial clones and pulls 10x faster**, bringing them down from minutes to seconds. In addition, because of the way remotefilelog stores its local data on disk, **large rebases are 2x faster.** When compared with our previous Git infrastructure, the numbers remain impressive. Achieving these types of performance gains through extensions is one of the big reasons we chose Mercurial.

- [FsMonitorExtension - Mercurial](https://wiki.mercurial-scm.org/FsMonitorExtension)
  - This extension was previously known as hgwatchman before being merged into Mercurial.

## 24.03.19

[Frozen collections in .NET 8](chrome-extension://hajanaajapkhaabfcofdjgjnlgkdkknm/)

- .NET8Ïùò Frozen Collection Ïùò ÏÑ±Îä•ÏùÄ ÏùºÎ∞ò Ïª¨Î†âÏÖò ÎèÑÍµ¨ÏôÄ Immutable Ïª¨Î†âÏÖò ÎèÑÍµ¨Î≥¥Îã§ Îπ†Î•¥Îã§.
- Immutable Ïª¨Î†âÏÖò ÎèÑÍµ¨Îì§Ïù¥ ÏÉùÍ∞ÅÎ≥¥Îã§ Î≤§ÏπòÎßàÌÅ¨ ÏÑ±Îä•Ïù¥ Ï¢ãÏßÄ ÏïäÏïòÎã§. Ïù¥Ïú†Îäî Ìè¨Ïä§Ìä∏Ïóê ÎÇòÏôÄÏûàÏßÄ ÏïäÏßÄÎßå, Ïù¥Í≤ÉÎèÑ .net 7Ïóê ÎπÑÌï¥ Í∞úÏÑ†Îêú Í≤ÉÏù¥ÎùºÍ≥†

[Don't Block on Async Code](https://blog.stephencleary.com/2012/07/dont-block-on-async-code.html)

> ASP.NET Example

```cs
// My "library" method.
public static async Task<JObject> GetJsonAsync(Uri uri)
{
  // (real-world code shouldn't use HttpClient in a using block; this is just example code)
  using (var client = new HttpClient())
  {
    var jsonString = await client.GetStringAsync(uri);
    return JObject.Parse(jsonString);
  }
}

// My "top-level" method.
public class MyController : ApiController
{
  public string Get()
  {
    var jsonTask = GetJsonAsync(...);
    return jsonTask.Result.ToString();
  }
}
```

So this is what happens, starting with the top-level method (Button1_Click for UI / MyController.Get for ASP.NET):

1. The top-level method calls GetJsonAsync (within the UI/ASP.NET context).
1. GetJsonAsync starts the REST request by calling HttpClient.GetStringAsync (still within the context).
1. GetStringAsync returns an uncompleted Task, indicating the REST request is not complete.
1. GetJsonAsync awaits the Task returned by GetStringAsync. The context is captured and will be used to continue running the GetJsonAsync method later. GetJsonAsync returns an uncompleted Task, indicating that the GetJsonAsync method is not complete.
1. The top-level method synchronously blocks on the Task returned by GetJsonAsync. This blocks the context thread.
1. ‚Ä¶ Eventually, the REST request will complete. This completes the Task that was returned by GetStringAsync.
1. The continuation for GetJsonAsync is now ready to run, and it waits for the context to be available so it can execute in the context.
1. Deadlock. The top-level method is blocking the context thread, waiting for GetJsonAsync to complete, and GetJsonAsync is waiting for the context to be free so it can complete.

**Preventing Deadlock**

There are two best practices (both covered in my intro post) that avoid this situation:

1. In your ‚Äúlibrary‚Äù async methods, use ConfigureAwait(false) wherever possible.
2. Don‚Äôt block on Tasks; use async all the way down.

```cs
public static async Task<JObject> GetJsonAsync(Uri uri)
{
  // (real-world code shouldn't use HttpClient in a using block; this is just example code)
  using (var client = new HttpClient())
  {
    var jsonString = await client.GetStringAsync(uri).ConfigureAwait(false);
    return JObject.Parse(jsonString);
  }
}
```

This changes the continuation behavior of GetJsonAsync so that it does not resume on the context. Instead, GetJsonAsync will resume on a thread pool thread. This enables GetJsonAsync to complete the Task it returned without having to re-enter the context. The top-level methods, meanwhile, do require the context, so they cannot use ConfigureAwait(false).

```cs
public async void Button1_Click(...)
{
  var json = await GetJsonAsync(...);
  textBox1.Text = json;
}

public class MyController : ApiController
{
  public async Task<string> Get()
  {
    var json = await GetJsonAsync(...);
    return json.ToString();
  }
}
```

- [.NET Framework 394. asyncawait ÏÇ¨Ïö© Ïãú hang Î¨∏Ï†úÍ∞Ä Î∞úÏÉùÌïòÎäî Í≤ΩÏö∞](https://www.sysnet.pe.kr/2/0/1541)
- [Îã∑ÎÑ∑ 2224. C - WPFÏùò Dispatcher QueueÎ°ú ÏïåÏïÑÎ≥¥Îäî await Ìò∏Ï∂úÏùò hang ÌòÑÏÉÅ](https://www.sysnet.pe.kr/2/0/13572#SetOnInvokeMres)

```cs
private void Window_Loaded(object sender, RoutedEventArgs e)
{
    Task<string> task = GetMyText();
    this.textBox1.Text = task.Result; // Î¨¥Ìïú ÎåÄÍ∏∞!!!
}

async Task<string> GetMyText()
{
    await Task.Delay(1);
    return "Hello World";
}
```