# 데이터 중심 애플리케이션 설계

#### Reference
- [ju-popov/Martin Kleppmann - Designing Data-Intensive Applications.md](https://gist.github.com/ju-popov/6c653d6fea82aa25868260654f06f2e8)


## 01장. 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션

<details>
<summary>fold/unfold</summary>

<img src="https://miro.medium.com/max/875/1*HdNA-aIwWx_5pI0ODo8nZA.png" width="40%" height="40%">

- 오늘날 많은 애플리케이션은 계산 중심(computer-intensive)과는 다르게 데이터 중심(data-intensive)적이다. 이러한 애플리케이션의 경우, CPU 성능은 애플리케이션을 제한하는 요소가 아니며, 더 큰 문제는 보통 데이터의 양, 데이터의 복잡도, 데이터의 변화 속도다.
- 일반적으로 데이터 중심 애플리케이션은 공통으로 필요로 하는 기능을 제공하는 표준 구성 요소(standard building block)로 만든다. 
  - 구동 애플리케이션이나 다른 애플리케이션에서 나중에 다시 데이터를 찾을 수 있게 데이터를 저장(데이터베이스)
  - 읽기 속도 향상을 위해 값비싼 수행 결과를 기억(캐시)
  - 사용자가 키워드로 데이터를 검색하거나 다양한 방법으로 필터링할 수 있게 제공(검색 색인(search index))
  - 비동기 처리를 위해 다른 프로세스로 메세지 보내기(스트림 처리(stream processing))
  - 주기적으로 대량의 누적된 데이터를 분석(일괄 처리(batch processing))

<br>

이 책에서는 대부분의 소프트웨어 시스템에서 중요하게 여기는 세 가지 관심사에 중점을 둔다.
- 신뢰성Reliability : 하드웨어나 소프트웨어 결함, 심지어 인적 오류(human error) 같은 역경에 직면하더라도 시스템은 지속적으로 올바르게 동작(원하는 성능 수준에서 정확한 기능을 수행)해야 한다.
- 확장성Scalability : 시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면서 이를 처리할 수 이쓴 적절한 방법이 있어야 한다.
- 유지보수성Maintainability : 시간이 지남에 따라 여러 다양한 사람들이 시스템 상에서 작업(현재 작업을 유지보수하고 새로운 사용 사례를 시스템에 적용하는 엔지니어링과 운영)할 것이기 때문에 모든 사용자가 시스템 상에서 생산적으로 작업할 수 있게 해야 한다.

<br>

### 신뢰성
- 소프트웨어의 경우 일반적인 기대치는 다음과 같다.
  - 애플리케이션은 사용자가 기대한 기능을 수행한다.
  - 시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다.
  - 시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다.
  - 시스템은 허가되지 않은 접근과 오남용을 방지한다.

<br>

- 잘못될 수 있는 일을 결함(fault)라 부른다. 그리고 결함을 예측하도 대처할 수 있는 시스템을 내결함성(fault-tolerant) 또는 탄력성(resilient)을 지녔다고 말한다.
- 결함은 장애(failure)와 동일하지 않다. 일반적으로 결함은 사양에서 벗어난 시스템의 한 구성 요소로 정의되지만, 장애는 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 경우다.
  - 하드웨어 결함
  - 소프트웨어 오류
  - 인적 오류

### 확장성
- 시스템이 현재 안정적으로 동작한다고 해서 미래에도 안정적으로 동작한다는 보장은 없다. 성능 저하를 유발하는 흔한 이유 중 하나는 부하 증가다. 어쩌면 시스템의 동시 사용자 수가 1만 명에서 10만 명 또는 100만 명에서, 1,000만 명으로 증가했을 수도 있다. 시스템은 전에 처리했던 양보다 더 많은 데이터를 처리하고 있을지도 모른다.
- 확장성은 증가한 부하에 대처하는 시스템 능력을 설명하는 데 사용하는 용어지만 시스템에 부여하는 일차원적인 표식이 아님을 주의하자. "X는 확장 가능하다" 또는 "Y는 확장성이 없다" 같은 말은 의미가 없다. 오히려 확장성을 논한다는 것은 "시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가?"와 "추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?" 같은 질문을 고려한다는 의미다.

<br>

부하 기술하기
- 시스템의 현재 부하를 간결하게 기술할 수 있어야 한다. 그래야 부하 성장 질문(부하가 두 배로 되면 어떻게 될까?)을 논의할 수 있다. 부하는 부하 매개변수(load parameter)라 부르는 몇 개의 숫자로 나타낼 수 있다. 가장 적합한 부하 매개변수 선택은 시스템 설계에 따라 달라진다. 부하 매개변수로 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자(active user), 캐시 적중률 등이 될 수 있다. 평균적인 경우가 중요할 수도 있고 소수의 극단적인 경우가 병목 현상의 원인일 수도 있다.
- ex) 트위터

<br>

성능 기술하기
- 일단 시스템 부하를 기술하면 부하가 증가할 때 어떤 일이 일어나는지 조사할 수 있다. 다음 두 가지 방법으로 살펴볼 수 있다.
  - 부하 매개변수를 증가시키고 시스템 자원(CPU, 메모리, 네트워크 대역폭 등)은 변경하지 않고 유지하면 시스템 성능은 어떻게 영향을 받을까?
  - 부하 매개변수를 증가시켰을 대 성능이 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할까?

<br>

- 하둡(Hadoop)과 같은 일괄 처리 시스테은 보통 처리량(throughput)(초당 처리할 수 있는 레코드 수나 일정 크기의 데이터 집합으로 작업을 수행할 때 걸리는 전체 시간)에 관심을 가진다. 온라인 시스템에서 더 중요한 사항은 서비스 응답 시간(response time), 즉 클라이언트가 요청을 보내고 응답을 받는 사이의 시간이다.
- 지연 시간(latency)과 응답 시간(response time) : 지연 시간과 응답 시간을 종종 같은 뜻으로 사용하지만 동일하지는 않다. 응답 시간은 클라이언트 관점에서 본 시간으로, 요청을 처리하는 실제 시간(서비스 시간) 외에도 네트워크 지연과 큐 지연도 포함한다. 지연 시간은 요청이 처리되길 기다리는 시간으로, 서비스를 기다리며 휴지(latent) 상태인 시간을 말한다.

<br>

실전 백분위
- 상위 백분위는 단일 최종 사용자 요청의 일부로서 여러 번 호출되는 백엔드 서비스에서 특히 중요하다. 병렬로 호출해도 최종 사용자 요청은 여전히 병렬 호출 중 가장 느린 호출이 완료되길 기다려야 한다. 작은 비율의 백엔드 호출만 느려도 최종 사용자 요청이 여러 번 백엔드를 호출하면 느린 호출이 발생할 가능성이 증가한다. 그래서 최종 사용자 요청 중 많은 비율의 응답 시간이 결국 느려진다. 이 효과를 꼬리 지연 증폭(tail latency amplification) 이라 한다.
- 서비스의 모니터링 대시보드에 응답 시간 백분위를 추가하려면 지속적으로 백분위를 효율적으로 계산할 필요가 있다. 예를 들어, 지난 10분간 요청의 응답 시간을 롤링 윈도(rolling window)로 유지하고 싶다면 1분마다 구간 내 중앙값과 다양한 백분위를 계산해 각 지표를 그래프에 그리면 된다.
- 단순한 구현으로 시간 구간 내 모든 요청의 응답 시간 목록을 유지하고 1분마다 목록을 정렬하는 방법이 있다. 이 구현이 너무 비효율적이라면 상황에 따라 포워드 디케이(forward decay), T 다이제스트(t-digest), Hdr히스토그램(HdrHistogram) 같은 CPU와 메모리 비용을 최소로 하면서 좋은 백분위 근사치를 계산할 수 있는 알고리즘이 있다. 백분위 평균(예를 들어, 시간 해상도를 줄이거나 여러 장비의 데이터를 결합하기)은 수학적으로 의미가 없으니 주의하자. 응답 시간 데이털르 집계하는 올바른 방법은 히스토그램을 추가하는 것이다.


<br>

부하 대응 접근 방식
- 사람들은 확장성과 관련해 용량 확장(scaling up)(수직 확장(vertical scaling), 좀 더 강력한 장비로 이동)과 규모 확장(scaling out)(수평 확장(horizontal scaling), 다수의 낮은 사양 장비에 부하를 분산)으로 구분해서 말하곤한다. 다수의 장비에 부하를 분산하는 아키텍처를 비공유(shared-nothing) 아키텍처라 부른다.
- 대개 대규모로 동작하는 시스템의 아키텍처는 해당 시스템을 사용하는 애플리케이션에 특화돼 있다. 범용적이고 모든 상황에 맞는(one-size-fits-all) 확장 아키텍처(비공식적으로 마법의 확장 소스(magic scaling source)라 부른다)는 없다. 아키텍처를 결정하는 요소는 읽기의 양, 쓰기의 양, 저장할 데이터의 양, 데이터의 복잡도, 응답 시간 요구사항, 접근 패턴 등이 있다. 혹은 (대개) 이 요소 중 일부 조합에 더 많은 문제가 추가된 경우도 있다.
- 예를 들어 각 크기가 1KB 인 chekd 100,000 건의 요청을 처리하도록 설계한 시스템과 각 크기가 2GB인 분당 3건의 요청을 처리하기 위해 설계한 시스템은 서로 같은 데이터 처리량이라 해도 매우 다르다.

<br>

유지보수성
- 소프트웨어 비용의 대부분은 초기 개발이 아니라 지속해서 이어지는 유지보수에 들어간다는 사실은 잘 알려져 있다.
- 이런 유지보수에는 버그 수정, 시스템 운영 유지, 장애 조사, 새로운 플랫폼 적응, 새 사용 사례를 위한 변경, 기술 채무(technical debt) 상환, 새로운 기능 추가 등이 있다.

<br>

- 레거시 시스템 유지보수를 피하기 위한 소프트웨어 설계 원칙은 다음 세 가지가 있다.
  - 운용성(operability) : 운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만들어라.
  - 단순성(simplicity) : 시스템에서 복잡도를 최대한 제거해 새로운 엔지니어가 시스템을 이해하기 쉽게 만들어라(사용자 인터페이스의 단순성과는 다르다는 점에 유의하라)
  - 발전성(evolvability) : 엔지니어가 이후에 시스템을 쉽게 변경할 수 있게 하라. 그래야 요구사항 변경 같은 예기치 않은 사용 사례를 적용하기가 쉽다. 이 속성은 유연성(extensibility), 수정 가능성(modifiability), 적응성(plasticity)으로 알려져 있다.

<br>

운용성 : 운영의 편리함 만들기
- 시스템이 지속해서 원활하게 작동하려면 운영팀이 필수다. 좋은 운영팀은 일반적으로 다음과 같은 작업 등을 책임진다.
  - 시스템 상태를 모니터링하고 상태가 좋지 않다면 빠르게 서비스를 복원
  - 시스템 장애, 성능 저하 등의 문제의 원인을 추적
  - 보안 패치를 포함해 소프트웨어와 플랫폼을 최신 상태로 유지
  - 다른 시스템이 서로 어떻게 영향을 주는지 확인해 문제가 생길 수 있는 변경 사항을 손상을 입히기 전에 차단
  - 미래에 발생 가능한 문제를 예측해 문제가 발생하기 전에 해결(예를 들어 용량 계획)
  - 배포, 설정 관리 등을 위한 모범 사례와 도구를 마련
  - 애플리케이션을 특정 플랫폼에서 다른 플랫폼으로 이동하는 등 복잡한 유지보수 태스클르 수행
  - 설정 변경으로 생기는 시스템 보안 유지보수
  - 예측 가능한 운영과 안정적인 서비스 환경을 유지하기 위한 절차 정의
  - 개인 인사 이동에도 시스템에 대한 조직의 지식을 보존함
- 좋은 운영성이란 동일하게 반복된느 태스크를 쉽게 수행하게끔 만들어 운영팀이 고부가가치 활동에 노력을 집중한다는 의미다. 데이터 시스템은 동일 반복 태스크를 쉽게 하기 위해 아래 항목 등을 포함해 다양한 일을 할 수 있다.
  - 좋은 모니터링으로 런타임(runtime) 동작과 시스템의 내부에 대한 가시성 제공
  - 표준 도구를 이요해 자동화와 통합을 위한 우수한 자원을 제공
  - 개별 장비 의존성을 회피, 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고, 계속해서 운영 가능해야 함
  - 좋은 문서와 이해하기 쉬운 운영 모델(예를 들어 "X를 하면 Y가 발생한다") 제공
  - 만족할 만한 기본 동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여
  - 적절하게 자기 회복(self-healing)이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함
  - 예측 가능하게 동작하고 예기치 않은 상황을 최소화함

<br>

단순성 : 복잡도 관리
- 복잡도는 같은 시스템에서 작업해야 하는 모든 사람의 진행을 느리게 하고 나아가 유지보수 비용이 증가한다. 복잡도는 다양한 증상으로 나타난다. 상태 공간의 급증, 모듈 간 강한 커플링(tight coupling), 복잡한 의존성, 일관성 없는 명명(naming)과 용어, 성능 문제 해결을 목표로 한 해킹, 임시방편으로 문제를 해결한 특수 사례(special-casing) 등이 이런 증상이다.
- 우발적 복잡도를 제거하기 위한 최상의 도구는 추상화다. 좋은 추상화는 깔끔하고 직관적인 외관 아래로 많은 세부 구현을 숨길 수 있다. 예를 들어, 고수준 프로그래밍 언어는 기계 언어, CPU 레지스터, 시스템 호출을 숨긴 추상화다. 

<br>

발전성 : 변화를 쉽게 만들기
- 조직 프로세스 측면에서 애자일(agile) 작업 패턴은 변화에 적응하기 위한 프레임워크를 제공한다. 또하 애자일 커뮤니티는 테스트 주도 개발(test-driven development(TDD)) 과 리팩토링(refactoring) 같이 자주 변화하는 환경에서 소프트웨어를 개발할 때 도움이 되는 기술 도구와 패턴을 개발하고 있다.

</details>

## 02장. 데이터 모델과 질의 언어

<details>
<summary>fold/unfold</summary>

대부분의 애플리케이션은 하나의 데이터 모델을 다른 데이터 모델 위의 계층을 둬서 만든다. 각 계층의 핵심적인 문제는 다음 하위 계층 관점에서 데이터 모델을 표현하는 방법이다.
- 애플리케이션 개발자는 현실(사람, 조직, 상품, 행동, 자금 흐름, 센서 등)을 보고 객체나 데이터 구조, 그리고 이러한 데이터 구조를 다루는 API를 모델링한다. 이런 구조는 보통 애플리케이션에 특화돼 있다.
- 데이터 구조를 저장할 때는 JSON 이나 XML 문서, 관계형 데이터베이스 테이블이나 그래프 모델 같은 범용 데이터 모델로 표현한다.
- 데이터베이스 소프트웨어를 개발하는 엔지니어는 JSON/XML/관계형/그래프 데이터를 메모리나 디스크 또는 네트워크 상의 바이트 단위로 표현하는 방법을 결정한다. 이 표현은 다양한 방법으로 데이터의 질의, 탐색, 조작, 처리할 수 있게 된다.
- 더 낮은 수준에서 하드웨어 엔지니어는 전류, 빛의 파동, 자기장 등의 관점에서 바이트를 표현하는 방법을 알아냈다.

<br>

### 관계형 모델과 문서 모델
- 오늘날 잘 알려진 데이터 모델은 1970년 에드가 코드(Edgar Codd)가 제안한 관계형 모델을 기반으로 한 SQL이다. 데이터는 (SQL에서는 테이블이라 불리는) 관계(relation)로 구성되고 각 관계는 순서 없는 튜플(tuple) (SQL에서 로우(row)) 모음이다.

<br>

### NoSQL의 탄생
- 현재 2010년대의 NoSQL은 관계형 모델의 우위를 뒤집으려는 가장 최신 시도다. "NoSQL"이라는 이름은 실제 어떤 특정 기술을 참고한 것이 이나기에 적절하지 않다. 원래 NoSQL 은 2009년에 오픈소스, 분산환경, 비관계형 데이터베이스 밋업(meetup)용 인기 트위터 해시태그였다. NoSQL은 거슬러 올라가 Not Only SQL로 재해석됐다.
- NoSQL 데이터베이스를 채택한 데는 다음과 같은 원동력이 있다.
  - 대규모 데이터셋이나 매우 높은 쓰기 처리량 달성을 관계형 데이터베이스보다 쉽게 할 수 있는 뛰어난 확장성의 필요
  - 상용 데이터베이스 제품보다 무료 오픈소스 소프트웨어에 대한 선호도 확산
  - 관계형 모델에서 지원하지 않는 특수 질의 동작
  - 관계형 스키마의 제한에 대한 불만과 더욱 동적이고 표현력이 풍부한 데이터 모델에 대한 바람

<br>

### 객체 관계형 불일치
- 오늘날 대부분의 애플리케이션은 객체지향 프로그래밍 언어로 개발한다. 이는 SQL 데이터 모델을 향한 공통된 비판을 불러온다. 데이터를 관계형 테이블에 저장하려면 애플리케이션 코드와 데이터 베이스 모델 객체(테이블, 로우, 칼럼) 사이에 거추장스러운 전환 계층이 필요하다. 이런 모델 사이의 분리를 종종 임피던스 불일치(impedance mismatch)라고 부른다.
  - 임피던스란 전자공학에서 빌려온 용어이다. 모든 저기 회로는 입력과 출력에 일정한 임피던스(교류에 대한 저항)를 갖고 있다. 한 회로의 출력을 또 다른 회로의 입력으로 연결했을 때 두 회로의 출력과 입력 임피던스가 일치하면 연결을 통한 전력 전달은 최대가 된다. 임피던스가 불일치하면 신호 반사 및 여러 문제를 겪을 수 있다.
- 관계형 스키마에서 이력서를 어떻게 표현하는지 예를 들어볼 때, 대부분의 사람들은 경력에 입력할 수 있는 값이 하나 이상일 것이다. 이때 사용자와 이들 항목은 일대다(one-to-many) 관계다. 이 관계를 나타낼 때는
  - 전통적인 SQL 모델(SQL:1999 이전)에서 가장 일반적인 정규화 표현은 직위, 학력, 연락처 정보를 개별 테이블에 넣고 외래 키롤 지원자 테이블을 참조하는 방식이다.
  - SQL 표준의 마지막 버전에서 구조화된 데이터 타입(datatype) 과 XML 데이터에 대한 지원을 추가했다. 이 지원으로 단일 로우에 다중 값을 저장할 수 있고 문서 내 질의와 색인이 가능해졌다. 이런 기능은 오라클, IBM DB2, 마이크로소프트 SQL 서버, 포스트 그레스큐엘(PostgreSQL) 같은 데이터베이스마다 제각각 다양한 형태로 지원한다. 
    - JSON은 XML 보다 훨씬 더 간단해 매력적이다. 몽고DB(MongoDB), 리싱크DB(RethinkDB), 카우치DB(CouchDB)와 에스프레소(Espresso) 같은 문서 지향(document-oriented) 데이터베이스는 JSON 데이터 모델을 지원한다.
  - 세 번째 방법으로 직업, 학력, 연락처 정보를 JSON이나 XML 문서로 부호화해 데이터베이스의 텍스트 칼럼에 저장한 다음 애플리케이션이 구조와 내용을 해석하게 하는 방식이다. 이 방식을 쓰면 일반적으로 부호화된 칼럼의 값을 질의하는 데 데이터베이스를 사용할 수 없다.

<br>

- JSON 표현은 다중 테이블(multi-table) 스키마보다 더 나은 지역성(locality)을 갖는다. 관계형 예제에서 프로필을 가져오려면 다중 질의(각 테이블에 user_id로 질의)를 수행하거나 users 테이블과 그 하위 테이블 간에 난잡한 다중 조인을 수행해야 한다. JSON 표현에서는 모든 관련 정보가 한 곳에 있어 질의 하나로 충분하다.

<br>

### 다대일과 다대다 관계
- 관계형 데이터베이스의 설계에서 중복을 최소화하게 데이터를 구조화하는 프로세스를 정규화(Normalization)라고 한다.
- 중복된 데이터를 정규화하려면 다대일(many-to-one) 관계(많은 사람들은 한 특정 지역에 살거나 한 특정 업계에서 일한다) 가 필요한데 안타깝게도 다대일 관계는 문서 모델에 적합하지 않다. 관계형 데이터베이스에서는 조인이 쉽기 때문에 ID로 다른 테이블의 로우를 참조하는 방식은 일반적이다. 문서 데이터베이스에서는 일대다 트리 구조를 위해 조인이 필요하지 않지만 조인에 대한 지원이 보통 약하다.
- 데이터베이스 자체가 조인을 지원하지 않으면 데이터베이스에 대한 다중 질의를 만들어서 애플리케이션 코드에서 조인을 흉내내야 한다. 
- 아래 그림은 다대다 관계를 어떻게 필요로 하는지 보여준다. 각 점선 내 데이터는 하나의 문서로 묶을 수 있지만 조직, 학교, 기타 사용자는 참조로 표현해야 하고 질의할 때는 조인이 필요하다.
<img src="https://camo.githubusercontent.com/d64f1e7b58faec0e832b72598314c80c131e03cde9b30ffaa8f95a29223ab7fb/68747470733a2f2f73332d65752d776573742d312e616d617a6f6e6177732e636f6d2f6a752e7075626c69632f676974732e6769746875622e636f6d2f4d617274696e2532304b6c6570706d616e6e2532302d25323044657369676e696e67253230446174612d496e74656e736976652532304170706c69636174696f6e732f466967757265253230322d342e706e67" width="40%" height="40%">

<br>

### 문서 데이터베이스는 역사를 반복하고 있나?
- 계층 모델 : 상당힌 간단한 데이터 모델이다. 계층 모델은 문서 데이터베이스에서 사용하는 JSON 모델과 놀랍도록 비슷하다. 모든 데이터를 레코드 내에 중첩된 레코드 트리로 표현한다.
  - 문서 데이터베이스처럼 일대다 관계에서는 잘 동작한다. 하지만 다대다 관계 표현은 어려웠고 조인을 지원하지 않는다.
- 네트워크 모델 : 네트워크 모델에서 레코드 간 연결은 외래 키보다는 프로그래밍 언어의 포인터와 더 비슷하다. 레코드에 접근하는 유일한 방법은 최상위 레코드(root record)에서부터 연속된 연결 경로를 따르는 방법이다. 이를 접근 경로라 한다.
  - 졉근 경로가 연결 목록의 순회와 같을 때 구조가 가장 간단해진다. 하지만 다대다 관계에서는 다양한 다른 경로가 같은 레코드로 이어질 수 있고 네트워크 모델을 사용하는 프로그래머는 경로의 맨 앞에서 이런 다양한 접근 경로를 계속 추적해야 한다.
  - 수동 접근 경로 선택은 1970년대에는 매우 제한된 하드웨어 성능을 가장 효율적으로 사용할 수 있었지만 데이터베이스 질의와 갱신을 위한 코드가 복잡하고 유연하지 못한 문제가 있었다. 계층 모델과 네트워크 모델 모두, 원하는 데이터에 대한 경로가 없다면 어려운 상황에 놓인다.
- 관계형 모델 : 대조적으로 관계형 모델이 하는 일은 알려진 모든 데이터를 배치하는 것이다. 관계(테이블)는 단순히 튜플(로우)의 컬렉션이 전부다. 얽히고 설킨 중첩 구조와 데이터를 보고 싶을 때 다라가야 할 복잡한 접근 경로가 없다. 임의 조건과 일치하는 테이블의 일부 또는 모든 로우를 선택해서 읽을 수 있고 일부 칼럼을 키로 지정해 칼럼과 일치하는 특정 로우를 읽을 수 있다. 다른 테이블과의 외래 키 관계에 대해 신경 쓰지 않고 임의 테이블에 새 로우를 삽입할 수 있다.
  - 관계형 데이터베이스에서 질의 최적화기(query optimizer)는 질의의 어느 부분을 어떤 순서로 실행할지를 결정하고 사용할 색인을 자동으로 결정한다. 이 선택은 실제로 '접근 경로'다. 하지만 큰 차이점은 접근 경로를 애플리케이션 개발자가 아니라 질의 최적화기가 자동으로 만든다는 점이다. 그래서 접근 경로를 따로 생각할 필요가 없다.
  - 새로운 방식으로 데이터에 질의하고 싶은 경우 새로운 색인을 선언하기만 하면 질의는 자동으로 가장 적합한 색인을 사용한다. 새로운 색인을 사용하기 위해 질의를 바꿀 필요가 없다. 따라서 관계형 모델은 애플리케이션에 새로운 기능을 추가하는 작업이 훨씬 쉽다.

### 문서 데이터베이스와의 비교
- 문서 데이터베이스는 한 가지 측면에서 계층 모델로 되돌아갔다. 문서 데이터베이스는 별도 테이블이 아닌 상위 레코드 내에 중첩된 레코드를 저장한다.
- 하지만 다대일과 다대다 관계를 표현할 때 관계형 데이터베이스와 문서 데이터베이스는 근본적으로 다르지 않다. 둘 다 관련 항목은 고유한 식별자로 참조한다. 관계형 모델에서는 외래 키라 부르고 문서 모델에서는 문서 참조(document reference)라 부른다. 이 식별자는 조인이나 후속 질의를 사용해 읽기 시점에 확인한다. 현재까지는 문서 데이터베이스가 코다실(계층 모델)의 전철을 밟지 않고 있다.

### 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 할까?
- 애플리케이션에서 데이터가 문서와 비슷한 구조(일대다 관계 트리로 보통 한 번에 전체 트리를 적재)라면 문서 모델을 사용해서 찢는 것이 좋다. 문서와 비슷한 구조를 여러 테이블로 나누어 찢는(shredding) 관계형 기법은 다루기 힘든 스키마와 불필요하게 복잡한 애플리케이션 코드를 발생시킨다.
- 문서 모델에는 제한이 있다. 예를 들어 문서 내 중첩 항목을 바로 참조할 수는 없어서 "상요자 251의 직위 목록의 두 번째 항목"과 같이 표현해야 한다.(계층 모델에서 접근 경로와 매우 유사) 하지만 문서가 너무 깊게 중첩되지 않으면 일반적으로 문제가 되지 않는다.
- 문서 데이터베이스의 미흡한 조인 지원은 애플리케이션에 따라 문제일 수도 있고 아닐 수도 있다. 예를 들어 어떤 시점에 발생한 이벤트를 기록하는 문서 데이터베이스를 사용하는 분석 애플리케이션에서는 다대다 관계가 결코 필요하지 않다.


### 문서 모델에서의 스키마 유연성
...

### 질의를 위한 데이터 지역성
- 문서는 보통 JSON, XML 로 부호화된 단일 연속 문자열이나 (몽고DB와 BSON 같은) JSON 또는 XML 의 이진 변형으로 저장된다. 웹 페이지 상에 문서를 보여주는 동작처럼 애플리케이션이 자주 전체 문서에 접근해야 할 때 저장소 지역성(storage locality) 을 활용하면 성능 이점이 있다. 
- 지역성의 이점은 한 번에 해당 문서의 많은 부분을 필요로 하는 경우에만 적용된다. 데이터베이스는 대개 문서의 작은 부분에만 접근해도 전체 문서를 적재해야 하기에 큰 문서에서는 낭비일 수 있다. 문서를 갱신할 도 보통 전체 문서를 재작성해야 한다. 이런 이유로 일반적으로 문서를 아주 작게 유지하면서 문서의 크기가 증가하는 쓰기를 피하라고 권장한다. 이 성능 제한 때문에 문서 데이터베이스가 유용한 상황이 많이 줄어든다.


### 문서 데이터베이스와 관계형 데이터베이스의 통합
...


### 데이터를 위한 질의 언어
- 관계형 모델이 등장했을 때 데이터를 질의하는 새로운 방법도 함께 나타났다. SQL은 선언형 질의 언어인 반면 IMS와 코다실은 명령형 코드를 사용해 데이터베이스에 질의한다.
- 명령형 언어는 특정 순서로 특정 연산을 수행하게끔 컴퓨터에게 지시한다. 지시의 예로 코드를 한 줄 씩 실행하고 조건을 평가하고 변수를 갱신하고 루프를 한 번 더 실행할지 여부를 결정하는 것을 들 수 있다.
  - SQL이나 관계 대수 같은 선언형 질의 언어에서는 목표를 달성하기 위한 방법이 아니라 알고자 하는 데이터의 패턴, 즉 결과가 충족해야 하는 조건과 데이터를 어떻게 변환(예를 들어 정렬, 그룹화, 집계)할지를 지정하기만 하면 된다. 어떤 색인과 어떤 조인 함수를 사용할지, 질의의 다양한 부분을 어떤 순서로 실행할지를 결정하는 일은 데이터베이스 시스템의 질의 최적화기가 할 일이다.
- 선언형 언어는 종종 병렬 실행에 적합하다. 오늘날 CPU 는 이전보다 훨씬 더 높은 클록 속도로 실행해 빨라지기보다 더 많은 코어를 추가해 빨라지고 있다. 명령형 코드는 명령어를 특정 순서로 실행하게끔 지정하기 때문에 다중 코어나 다중 장비에서 병렬 처리가 매우 어렵다. 선언형 언어는 결과를 결정하기 윟나 알고리즘을 지정하는 게 아니라 결과의 패턴만 지정하기 때문에 병렬 실행으로 더 빨라질 가능성이 있다.

...
</details>


</details>

## 03장. 저장소와 검색

<details>
<summary>fold/unfold</summary>

### 데이터베이스를 강력하게 만드는 데이터 구조
- 데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요하다. 바로 색인이다. 
- 색인의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다. 이 메타데이터는 이정표 역할을 해서 원하는 데이터의 위치를 찾는 데 도움을 준다. 동일한 데이터를 여러 가지 다양한 방법으로 검색하고자 한다면 데이터의 각 부분에 여러 가지 다양한 색인이 필요하다.
- 색인은 기본 데이터(primary data)에서 파생된 추가적인 구조이다. 많은 데이터베이스는 색인의 추가와 삭제를 허용한다. 이 작업은 데이터베이스의 내용에는 영향을 미치지 않는다. 단지 질의 성능에만 영향을 준다. 추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생한다. 쓰기의 경우 단순히 파일에 추가할 때의 성능을 앞서기 어렵다. 왜냐하면 단순히 파일에 추가하는 작업이 제일 간단한 쓰기 작업이기 때문이다. 어떤 종류의 색인이라도 대개 쓰기 속도를 느리게 만든다. 이는 데이터를 쓸 때마다 매번 색인도 갱신해야 하기 때문이다.

### 해시 색인
- 키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입(dictionary type)과 매우 유사하다. 보통 해시 맵(hash map)(해시 테이블(hash table)) 으로 구현한다. 해시 맵은 많은 알고리즘 교과서에서 설명하고 있어서 여기서 동작 방식을 자세히 설명하지 않는다. 인메모리 데이터 구조를 위한 해시 맵이 이미 있으니 디스크 상의 데이터를 색인하기 위해 인메모리 데이터 구조를 사용하는 것은 어떨까?

<img src="https://brilliun.com/images/designing-data-intensive-applications/3-1.png" width="40%" height="40%">


- 이 방식은 매우 단순해 보이지만 실제로 많이 사용되는 접근법이다. 해시 맵을 전부 메모리에 유지하기 때문에 사용 가능한 랩(RAM)에 모든 키가 저장된다는 조건을 전제로 고성능으로 읽기, 쓰기를 보장한다. 값은 한 번의 디스크 탐색으로 디스크에서 적재할 수 있기 때문에 사용 가능한 메모리보다 더 많은 공간을 사용할 수 있다. 만약 데이터 파일의 일부가 이미 파일 시스템 캐시에 있다면 읽기에 디스크 입출력이 필요하지 않다.
  - 이런 저장소 엔진은 각 키의 값이 자주 갱신되는 상황에 매우 적합하다. 예를 들어 키는 고양이 동영상의 URL 이고 값은 비디오가 재생된 횟수 (재생 버튼을 누를 때마다 증가함) 인 경우다. 이런 유형의 작업 부하에서는 쓰기가 아주 많지만 고유 키는 많지 않다. 즉, 키당 쓰기 수가 많지만 메모리에 모든 키를 보관할 수 있다.
  - 지금까지 설명한 것처럼 파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 이 상황은 어떻게 피할 수 있을까? 특정 크기의 세그먼트(segment) 로 로그를 나누는 방식이 좋은 해결책이다. 특정 크기에 도달하면 세그먼트 파읠을 닫고 새로운 세그먼트를 파일에 이후 쓰기를 수행한다. 세그먼트 파일들에 대해 컴팩션(compaction)을 수행할 수 있다. 컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.


<img src="https://brilliun.com/images/designing-data-intensive-applications/3-2.png" width="40%" height="40%">


<img src="https://brilliun.com/images/designing-data-intensive-applications/3-3.png" width="40%" height="40%">

<br>

이런 간단한 생각을 실제로 구현하려면 세부적으로 많은 사항을 고려해야 한다. 실제 구현에서 중요한 문제 몇 가지만 간략히 들자면 다음과 같다.
- 파일 형식
- 레코드 삭제
- 고장(Crash) 복구
- 부분적으로 레코드 쓰기
- 동시성 제어

<br>

추가 전용 로그는 언뜻 보면 낭비처럼 보인다. 예전 값을 새로운 값으로 덮어써 정해진 자리에 파일을 갱신하는 방법은 어떨까? 하지만 전용 추가 설계은 여러 측면에서 좋은 설계다.
- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 보통 무작위 쓰기보다 훨씬 빠르다. 특히 자기 회전 디스크 하드드라이브에서 그렇다. 일부 확장된 순차 쓰기는 플래시 기반 솔리드 스테이트 드라이브(SSD) 도 선호한다.
- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다. 예를 들어 값을 덮어 쓰는 동안 데이터베이스가 죽는 경우에 대해 걱정할 필요 없다. 이전 값 부분과 새로운 값 부분을 포함한 파일을 나누어 함께 남겨두기 위함이다.
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화된느 데이터 파일 문제를 피할 수 있다.

하지만 해시 테이블 색인 또한 제약 사항이 있다.
- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다. 원칙적으로는 디스크에 해시 맵을 유지할 수 있지만 불행하게도 디스크 상의 해시 맵에 좋은 성능을 기대하기란 어렵다. 이는 무작위 접근 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요하다.
- 해시 테이블은 범위 질의(range query)에 효율적이지 않다. 예를 들어 kitty00000과 kitty99999 사이 모든 키를 쉽게 스캔할 수 없다. 해시 맵에서 모든 개별 키를 조회해야 한다.

### SS테이블과 LSM 트리
위의 그림에서 각 로그 구조화 저장소 세그먼트는 키-값 쌍의 연속이다. 이 쌍은 쓰여진 순서대로 나타나며 로그에서 같은 키를 갖는 값 중 나중의 값이 이전 값보다 우선한다. 이 점만 제외하면 파일에서 키-값 쌍의 순서는 문제가 되지 않는다.
  - 이제 세그먼트 파일의 형식에 간단한 변경 사항 한 가지를 적용해보자. 변경 요구사항은 일련의 키-값 쌍을 키로 정렬하는 것이다. 이처럼 키로 정렬된 형식을 정렬된 문자열 테이블(Sorted String Table) 또는 짧게 SS테이블이라 부른다. 그리고 또한 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다.(컴팩션 과정은 이를 이미 보장한다.) SS테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.
    - 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단한고 효율적이다. 이 접근법은 병합정렬(merge sort) 알고리즘에서 사용하는 방식과 유사하다. 먼저 입력 팡링르 함께 읽고 각 파일의 첫 번째 키를 본다.(정렬된 순서에 따라) 그리고 가장 낮은 키를 출력 파일로 복사한 뒤 이 과정을 반복한다. 이 과정에서 새로운 병합 세그먼트 파일이 생성된다. 새로 만든 세그먼트 파일도 역시 키로 정렬돼 있다.


<img src="https://brilliun.com/images/designing-data-intensive-applications/3-4.png" width="40%" height="40%">

- 여러 입력 세그먼트에 동일한 키가 있으면 어떻게 해야 할까? 각 세그먼트는 일정 기간 동안 데이터베이스에 쓰여진 모든 값이 포함된다는 점에 유의하자. 이것은 입력 세그먼트 하나의 모든 값이 다른 세그먼트의 모든 값보다 최신 값이라는 점을 의미한다.(항상 인접된 세그먼트의 병햡을 가정한다.) 다중 세그먼트가 동일한 키를 포함하는 경우 가장 최근 세그먼트의 값은 유지하고 오래된 세그먼트의 값은 버린다.
- 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다. 특정 키의 색인을 확인할 수 없더라도 주변 키의 색인 값을 활용하여 탐색하는 키 값의 스캔 범위를 최소화할 수 있다.
- 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. 그러면 희소 인메모리 색인의 각 항목은 압축된 블록을 시작을 가리키게 된다. 디스크 공간을 절약한다는 점 외에도 압축은 I/O 대역폭 사용도 줄인다.

### SS 테이블 생성과 유지
디스크 상에 정렬된 구조를 유지하는 일은 가능하지만 메모리에 유지하는 편이 훨씬 쉽다. 레드 블랙 트리(red-black tree)나 AVL 트리와 같이 잘 알려졌고 사용 가능한 트리 데이터 구조는 많이 있다. 이런 데이터 구조를 이용하면 임의 순서로 키를 삽입하고 정렬된 순서로 해당 키를 다시 읽을 수 있다.

<br>

저장소 엔진을 다음과 같이 만들 수 있다.
- 쓰기가 들어오면 인메모리 균형 트리(balanced tree) 데이터 구조(예를 들어 레드 블랙 트리)에 추가한다. 이 인메모리 트리는 멤테이블(memtable)이라고도 한다.
- 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS 테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 새로운 SS 테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그 다음 디스크 상의 가장 최신 세그먼트에서 찾는다. 그 다음으로 두 번째 오래된 세그먼트, 세 번째 오래된 세그먼트 등에서 찾는다.
- 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.

<br>

이 계획은 잘 동작하지만 한 가지 문제가 있는데, 만약 데이터베이스가 고장나면 아직 디스크로 기록되지 않고 멤테이블에 있는 가장 최신 쓰기는 손실된다. 이런 문제를 피하기 위해서는 매번 쓰기를 측시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 한다. 이 로그는 손상 후 멤테이블을 복원할 때만 필요하기 때문에 순서가 정렬되지 않아도 문제되지 않는다. 멤테이블을 SS테이블로 기록하고 나면 해당 로그는 버릴 수 있다.

### SS 테이블에서 LSM 트리 만들기
...

### 성능 최적화
...

### B 트리
가장 널리 사용되는 색인 구조는 B트리(B-tree)로 구조가 로그 구조화 색인과는 상당히 다르다. 거의 대부분의 관계형의 데이터베이스에서 표준 색인 구현으로 B 트리를 사용할 뿐 아니라 많은 비 관계형 데이터베이스에서도 사용한다.
- B 트리는 SS 테이블과 같이 키로 정렬된 키-값 쌍을 유지하기 때문에 키-값 검색과 범위 질의에 효율적이다. 하지만 비슷한 점은 이 정도가 전부다. B 트리는 설계 철학이 매우 다르다.
- 로그 구조화 색인은 데이터베이스를 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다. 반면 B 트리는 전통적으로 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다. 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.
- 각 페이지는 주소나 위치를 이용해 식별할 수 있다. 이 방식으로 하나의 페이지가 다른 페이지를 참조할 수 있다.(포인터와 비슷하지만 메모리 대신 디스크에 있음). 이 페이지 참조는 아래 그림과 같이 페이지 트리를 구성하는 데 사용할 수 있다.

<img src="https://ebrary.net/htm/img/15/554/22.png" width="40%" height="40%">

- 한 페이지는 B 트리의 루트(root)로 지정된다. 색인에서 키를 찾으려면 루트에서 시작한다. 페이지는 여러 키와 하위 페이지의 참조를 포함한다. 각 하위 페이지는 키가 계속 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타낸다.
  - 위의 예시에서는 키 251을 찾고 있었기 때문에 200과 300 경계 사이의 페이지 참조를 따라가야 한다는 사실을 알 수 있다. 그러면 200~300 범위와 비슷하게 생겼지만 좀 더 작은 범위로 더 나눈 페이지로 이동한다.
  - 최종적으로 개별 키(리프 페이지(leaf page)) 를 포함하는 페이지에 도달한다. 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다.
- B 트리의 한 페이지에서 하위 페이지를 참조하는 수를 분기 계수(branching factor)라고 부른다. 예를 들어 위의 그림에서 분기 계수는 6이다.
- B 트리에 존재하는 키의 값을 갱신하려면 키를 포함하고 있는 리프 페이지를 검색하고 페이지의 값을 바꾼 다음 페이지를 디스크에 다시 기록한다.(페이지에 대한 모든 참조는 계속 유효하다.) 새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다. 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다.

<img src="https://ebrary.net/htm/img/15/554/23.png" width="40%" height="40%">

- 이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장한다. n 개의 키를 가진 B 트리는 깊이가 항상 O(log n) 이다. 대부분의 데이터베이스는 B 트리의 깊이가 3이나 4단계 정도면 충분하므로 검색하려는 페이지를 찾기 위해 많은 페이지 참조를 따라가지 않아도 된다.(분기 계수 500의 4KB 페이지의 4단계 트리는 256TB 까지 저장할 수 있다.)

### 신뢰할 수 있는 B 트리 만들기
B 트리의 기본적인 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어쓴다. 이 동작은 덮어쓰기가 페이지 위치를 변경하지 않는다고 가정한다. 즉 페이지를 덮어쓰더라도 페이지를 가리키는 모든 참조는 온전하게 남는다. LSM 트리와 같은 로그 구조화 색인과는 아주 대조적인 점이다. 로그 구조화 색인은 파일에 추가만 할 뿐(결국 더 이상 쓸모 없는 파일은 삭제됨) 같은 위치의 파일은 변경 하지 않는다.
- 디스크의 페이지를 덮어쓰는 일은 실제 하드웨어 동작이라고 생각할 수 있다. 자성의 하드드라이브의 경우 디스크 헤드를 적절한 곳으로 옮기고 회전하는 플래터의 올바른 위치가 돌아올 때까지 기다린 다음 적합한 섹터에 새로운 데이터를 덮어쓴다. SSD의 경우는 SSD 가 저장소  칩의 상당한 블록을 한번에 지우고 다시 쓰기를 해야 하기 때문에 조금 더 복잡하다.

### B 트리 최적화
...
- 페이지 덮어 쓰기와 고장 복구를 위한 WAL 유지 대신(LMDB 같은) 일부 데이터베이스는 쓰기 시 복사 방식(copy-on-write scheme) 을 사용한다. 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 한다. 이 접근 방식은 동시성 제어에도 유용하다.
- 페이지에 전체 키를 저장하는 게 아니라 키를 축약해 쓰면 공간을 절약할 수 있다. 특히 트리 내부 페이지에서 키가 키 범위 사이의 경계 역할을 하는 데 충분한 정보만 제공하면 된다. 페이지 하나에 키를 더 많이 채우면 트리는 더 높은 분기 계수를 얻는다. 그러면 트리 깊이 수준을 낮출 수 있다.
- 일반적으로 페이지는 디스크 상 어디에나 위치할 수 있다. 키 범위가 가까운 페이지들이 디스크 상에 가까이 있어야 할 필요가 없기 때문이다. 질의가 정렬된 순서로 키 범위의 상당 부분을 스캔해야 한다면 몯느 페이지에 대해 디스크 찾기가 필요하기 때문에 페이지 단위 배치는 비효율적이다. 따라서 많은 B 트리 구현에서 리프(leaf) 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리를 배치하려 시도한다. 하지만 트리가 커지면 순서를 유지하기가 어렵다. 반대로 LSM 트리는 변합하는 과정에서 저장소의 큰 세그먼트를 한 번에 다시 쓰기 때문에 디스크에서 연속된 키를 서로 가깝게 유지하기 더 쉽다.
- 트리에 포인터를 추가한다. 예를 들어 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있다.
- 프랙탈 트리(fractal tree) 같은 B 트리 변형은 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다.(프랙탈 트리는 기하학의 프랙탈과는 아무런 관련도 없다).

### B 트리와 LSM 트리 비교
- B 트리가 LSM 트리보다 일반적으로 구현 성숙도가 더 높지만 LSM 트리도 그 성능 특성 때문에 관심을 받고 있다. 경험적으로 LSM 트리는 보통 쓰기에서 더 빠른 반면 B 트리는 읽기에서 더 빠르다고 여긴다. 읽기가 보통 LSM 트리에서 더 느린 이유는 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS 테이블을 확인해야 하기 때문이다.

### LSM 트리의 장점
B 트리 색인은 모든 데이터 조각을 최소한 두 번 기록해야 한다. 쓰기 전 로그 한 번과 트리 페이지에 한 번(페이지가 분리될 때 다시 기록)이다. 해당 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야 하는 오버헤드도 있다. 일부 저장소 엔진은 심지어 전원에 장애가 발생했을 때 일부만 갱신된 페이지로 끝나지 않게 동일한 페이지를 두 번 덮어쓴다.
- 로그 구조화 색인 또한 SS 테이블의 반복된 컴팩션과 병합으로 인해 여러 번 데이터를 다시 쓴다. 데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 디스크에 여러 번의 쓰기를 야기하는 이런 효과를 쓰기 증폭(write amplification)이라 한다. SSD는 수명이 다할 때까지 블록 덮어쓰기 횟수가 제한되기 때문에 쓰기 증폭은 SSD 의 경우 특별한 관심사다.
- 쓰기가 많은 애플리케이션에서 성능 병목은 데이터베이스가 디스크에 쓰는 속도일 수 있다. 이 경우 쓰기 증폭은 바로 성능 비용이다. 저장소 엔진이 디스크에 기록할수록 디스크 대역폭 내 처리할 수 있는 초당 쓰기는 점점 줄어든다.
- 더욱이 LSM 트리는 보통 B 트리보다 쓰기 처리량을 높게 유지할 수 있다.(저장소 엔진 설정과 작업부하에 따라 다르긴 하지만) LSM 트리가 상대적을 쓰기 증폭이 더 낮고 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS 테이블 파일을 쓰기 때문이다. 이런 차이는 자기 하드드라이브에서 특히 중요하다. 자기 하드드라이브는 순차 쓰기가 임시 쓰기보다 훨씬 더 빠르다.
- LSM 트리는 압축률이 더 좋다. 그래서 보통 B 트리보다 디스크에 더 적은 파일을 생성한다. B 트리 저장소 엔진은 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다. 페이지를 나누거나 로우가 기존 페이지에 맞지 않을 때 페이지의 일부 공간은 사용하지 않게 된다. LSM 트리는 페이지 지향적이지 않고 주기적으로 파편화를 없애기 위해 SS 테이블을 다시 기록하기 때문에 저장소 오버헤드가 더 낮다. 레벨 컴팩션(level compaction)을 사용하면 특히 그렇다.
- 대다수의 SSD의 펌웨어는 내장 저장소 칩에서 임의 쓰기를 순차 쓰기로 전환하기 위해 내부적으로 로그 구조화 알고리즘을 사용한다. 그래서 저장소 엔진의 쓰기 패턴이 SSD 에 미치는 영향은 분명하지 않다. 하지만 낮은 쓰기 증폭과 파편화 감소는 SSD의 경우 훨씬 유리하다. 데이터를 더 밀집해 표현하면 가능한 I/O 대역폭 내에서 더 많은 읽기와 쓰기 요청이 가능하다.

### LSM 트리의 단점
로그 구조화 저장소의 단점은 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다는 점이다. 저장소 엔진은 컴팩션을 점진적으로 수행하고 동시 접근의 영향이 없게 수행하려 한다. 하지만 디스크가 가진 자원은 한계가 있다. 그래서 디스크에서 비싼 컴팩션 연산이 끝날 때까지 요청이 대기해야 하는 상황이 발생하기 쉽다. 처리량과 평균 응답 시간이 성능에 미치는 영향은 대개 작다. 하지만 로그 구조화 저장소 엔진의 상위 백분위 질의의 응답 시간은 때때로 꽤 길다. 반면 B 트리의 성능은 로그 구조화 저장소 엔진보다 예측하기 쉽다.
- 또 다른 컴팩션 문제는 높은 쓰기 처리량에서 발생한다. 디스크의 쓰기 대역폭은 유한하다. 초기 쓰기(로깅(logging)과 멤테이블을 디스크로 방출(flushing)) 와 백그라운드에서 수행되는 컴팩션 스레드가 이 대역폭을 공유해야 한다. 빈 데이터베이스에 쓴느 경우 전체 디스크 대역폭은 초기 쓰기만을 위해 사용할 수 있지만 데이터베이스가 점점 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요하다.
- 쓰기 처리량이 높음에도 컴팩션 설정을 주의 깊게 하지 않으면 컴팩션이 유입 쓰기 속도를 따라갈 수 없다. 이 경우 디스크 상에 병햡되지 않은 세그먼트 수는 디스크 공간이 부족할 때까지 증가한다. 그리고 더 많은 세그먼트 파일을 확인해야 하기 때문에 읽기 또한 느려진다. 보통 SS 테이블 기반 저장소 엔진은 컴팩션이 유입 속도를 따라가지 못해도 유입 쓰기의 속도를 조절하지 않으므로 이런 상황을 감지하기 위한 명시적 모니터링이 필요하다.
- B 트리의 장점은 각 키가 색인의 한 곳에만 정확하게 존재한다는 점이다. 반면 로그 구조화 저장소 엔진으 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다. 이런 측면 때문에 강력한 트랜잭션 시맨틱(semantic) 를 제공하는 데이터베이스에는 B 트리가 훨씬 매력적이다. 많은 관계형 데이터베이스에서 트랜잭션 격리(transaction isolation)는 키 범위의 잠금을 사용해 구현한 반면 B트리 색인에서는 트리에 직접 잠금을 포함시킨다.


### 기타 색인 구조

</details>
