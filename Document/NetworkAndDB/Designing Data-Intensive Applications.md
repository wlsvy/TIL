# 데이터 중심 애플리케이션 설계

#### Reference
- [ju-popov/Martin Kleppmann - Designing Data-Intensive Applications.md](https://gist.github.com/ju-popov/6c653d6fea82aa25868260654f06f2e8)


## 01장. 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션

<details>
<summary>fold/unfold</summary>

<img src="https://miro.medium.com/max/875/1*HdNA-aIwWx_5pI0ODo8nZA.png" width="40%" height="40%">

- 오늘날 많은 애플리케이션은 계산 중심(computer-intensive)과는 다르게 데이터 중심(data-intensive)적이다. 이러한 애플리케이션의 경우, CPU 성능은 애플리케이션을 제한하는 요소가 아니며, 더 큰 문제는 보통 데이터의 양, 데이터의 복잡도, 데이터의 변화 속도다.
- 일반적으로 데이터 중심 애플리케이션은 공통으로 필요로 하는 기능을 제공하는 표준 구성 요소(standard building block)로 만든다. 
  - 구동 애플리케이션이나 다른 애플리케이션에서 나중에 다시 데이터를 찾을 수 있게 데이터를 저장(데이터베이스)
  - 읽기 속도 향상을 위해 값비싼 수행 결과를 기억(캐시)
  - 사용자가 키워드로 데이터를 검색하거나 다양한 방법으로 필터링할 수 있게 제공(검색 색인(search index))
  - 비동기 처리를 위해 다른 프로세스로 메세지 보내기(스트림 처리(stream processing))
  - 주기적으로 대량의 누적된 데이터를 분석(일괄 처리(batch processing))

<br>

이 책에서는 대부분의 소프트웨어 시스템에서 중요하게 여기는 세 가지 관심사에 중점을 둔다.
- 신뢰성Reliability : 하드웨어나 소프트웨어 결함, 심지어 인적 오류(human error) 같은 역경에 직면하더라도 시스템은 지속적으로 올바르게 동작(원하는 성능 수준에서 정확한 기능을 수행)해야 한다.
- 확장성Scalability : 시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면서 이를 처리할 수 이쓴 적절한 방법이 있어야 한다.
- 유지보수성Maintainability : 시간이 지남에 따라 여러 다양한 사람들이 시스템 상에서 작업(현재 작업을 유지보수하고 새로운 사용 사례를 시스템에 적용하는 엔지니어링과 운영)할 것이기 때문에 모든 사용자가 시스템 상에서 생산적으로 작업할 수 있게 해야 한다.

<br>

### 신뢰성
- 소프트웨어의 경우 일반적인 기대치는 다음과 같다.
  - 애플리케이션은 사용자가 기대한 기능을 수행한다.
  - 시스템은 사용자가 범한 실수나 예상치 못한 소프트웨어 사용법을 허용할 수 있다.
  - 시스템 성능은 예상된 부하와 데이터 양에서 필수적인 사용 사례를 충분히 만족한다.
  - 시스템은 허가되지 않은 접근과 오남용을 방지한다.

<br>

- 잘못될 수 있는 일을 결함(fault)라 부른다. 그리고 결함을 예측하도 대처할 수 있는 시스템을 내결함성(fault-tolerant) 또는 탄력성(resilient)을 지녔다고 말한다.
- 결함은 장애(failure)와 동일하지 않다. 일반적으로 결함은 사양에서 벗어난 시스템의 한 구성 요소로 정의되지만, 장애는 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈춘 경우다.
  - 하드웨어 결함
  - 소프트웨어 오류
  - 인적 오류

### 확장성
- 시스템이 현재 안정적으로 동작한다고 해서 미래에도 안정적으로 동작한다는 보장은 없다. 성능 저하를 유발하는 흔한 이유 중 하나는 부하 증가다. 어쩌면 시스템의 동시 사용자 수가 1만 명에서 10만 명 또는 100만 명에서, 1,000만 명으로 증가했을 수도 있다. 시스템은 전에 처리했던 양보다 더 많은 데이터를 처리하고 있을지도 모른다.
- 확장성은 증가한 부하에 대처하는 시스템 능력을 설명하는 데 사용하는 용어지만 시스템에 부여하는 일차원적인 표식이 아님을 주의하자. "X는 확장 가능하다" 또는 "Y는 확장성이 없다" 같은 말은 의미가 없다. 오히려 확장성을 논한다는 것은 "시스템이 특정 방식으로 커지면 이에 대처하기 위한 선택은 무엇인가?"와 "추가 부하를 다루기 위해 계산 자원을 어떻게 투입할까?" 같은 질문을 고려한다는 의미다.

<br>

부하 기술하기
- 시스템의 현재 부하를 간결하게 기술할 수 있어야 한다. 그래야 부하 성장 질문(부하가 두 배로 되면 어떻게 될까?)을 논의할 수 있다. 부하는 부하 매개변수(load parameter)라 부르는 몇 개의 숫자로 나타낼 수 있다. 가장 적합한 부하 매개변수 선택은 시스템 설계에 따라 달라진다. 부하 매개변수로 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자(active user), 캐시 적중률 등이 될 수 있다. 평균적인 경우가 중요할 수도 있고 소수의 극단적인 경우가 병목 현상의 원인일 수도 있다.
- ex) 트위터

<br>

성능 기술하기
- 일단 시스템 부하를 기술하면 부하가 증가할 때 어떤 일이 일어나는지 조사할 수 있다. 다음 두 가지 방법으로 살펴볼 수 있다.
  - 부하 매개변수를 증가시키고 시스템 자원(CPU, 메모리, 네트워크 대역폭 등)은 변경하지 않고 유지하면 시스템 성능은 어떻게 영향을 받을까?
  - 부하 매개변수를 증가시켰을 대 성능이 변하지 않고 유지되길 원한다면 자원을 얼마나 많이 늘려야 할까?

<br>

- 하둡(Hadoop)과 같은 일괄 처리 시스테은 보통 처리량(throughput)(초당 처리할 수 있는 레코드 수나 일정 크기의 데이터 집합으로 작업을 수행할 때 걸리는 전체 시간)에 관심을 가진다. 온라인 시스템에서 더 중요한 사항은 서비스 응답 시간(response time), 즉 클라이언트가 요청을 보내고 응답을 받는 사이의 시간이다.
- 지연 시간(latency)과 응답 시간(response time) : 지연 시간과 응답 시간을 종종 같은 뜻으로 사용하지만 동일하지는 않다. 응답 시간은 클라이언트 관점에서 본 시간으로, 요청을 처리하는 실제 시간(서비스 시간) 외에도 네트워크 지연과 큐 지연도 포함한다. 지연 시간은 요청이 처리되길 기다리는 시간으로, 서비스를 기다리며 휴지(latent) 상태인 시간을 말한다.

<br>

실전 백분위
- 상위 백분위는 단일 최종 사용자 요청의 일부로서 여러 번 호출되는 백엔드 서비스에서 특히 중요하다. 병렬로 호출해도 최종 사용자 요청은 여전히 병렬 호출 중 가장 느린 호출이 완료되길 기다려야 한다. 작은 비율의 백엔드 호출만 느려도 최종 사용자 요청이 여러 번 백엔드를 호출하면 느린 호출이 발생할 가능성이 증가한다. 그래서 최종 사용자 요청 중 많은 비율의 응답 시간이 결국 느려진다. 이 효과를 꼬리 지연 증폭(tail latency amplification) 이라 한다.
- 서비스의 모니터링 대시보드에 응답 시간 백분위를 추가하려면 지속적으로 백분위를 효율적으로 계산할 필요가 있다. 예를 들어, 지난 10분간 요청의 응답 시간을 롤링 윈도(rolling window)로 유지하고 싶다면 1분마다 구간 내 중앙값과 다양한 백분위를 계산해 각 지표를 그래프에 그리면 된다.
- 단순한 구현으로 시간 구간 내 모든 요청의 응답 시간 목록을 유지하고 1분마다 목록을 정렬하는 방법이 있다. 이 구현이 너무 비효율적이라면 상황에 따라 포워드 디케이(forward decay), T 다이제스트(t-digest), Hdr히스토그램(HdrHistogram) 같은 CPU와 메모리 비용을 최소로 하면서 좋은 백분위 근사치를 계산할 수 있는 알고리즘이 있다. 백분위 평균(예를 들어, 시간 해상도를 줄이거나 여러 장비의 데이터를 결합하기)은 수학적으로 의미가 없으니 주의하자. 응답 시간 데이털르 집계하는 올바른 방법은 히스토그램을 추가하는 것이다.


<br>

부하 대응 접근 방식
- 사람들은 확장성과 관련해 용량 확장(scaling up)(수직 확장(vertical scaling), 좀 더 강력한 장비로 이동)과 규모 확장(scaling out)(수평 확장(horizontal scaling), 다수의 낮은 사양 장비에 부하를 분산)으로 구분해서 말하곤한다. 다수의 장비에 부하를 분산하는 아키텍처를 비공유(shared-nothing) 아키텍처라 부른다.
- 대개 대규모로 동작하는 시스템의 아키텍처는 해당 시스템을 사용하는 애플리케이션에 특화돼 있다. 범용적이고 모든 상황에 맞는(one-size-fits-all) 확장 아키텍처(비공식적으로 마법의 확장 소스(magic scaling source)라 부른다)는 없다. 아키텍처를 결정하는 요소는 읽기의 양, 쓰기의 양, 저장할 데이터의 양, 데이터의 복잡도, 응답 시간 요구사항, 접근 패턴 등이 있다. 혹은 (대개) 이 요소 중 일부 조합에 더 많은 문제가 추가된 경우도 있다.
- 예를 들어 각 크기가 1KB 인 chekd 100,000 건의 요청을 처리하도록 설계한 시스템과 각 크기가 2GB인 분당 3건의 요청을 처리하기 위해 설계한 시스템은 서로 같은 데이터 처리량이라 해도 매우 다르다.

<br>

유지보수성
- 소프트웨어 비용의 대부분은 초기 개발이 아니라 지속해서 이어지는 유지보수에 들어간다는 사실은 잘 알려져 있다.
- 이런 유지보수에는 버그 수정, 시스템 운영 유지, 장애 조사, 새로운 플랫폼 적응, 새 사용 사례를 위한 변경, 기술 채무(technical debt) 상환, 새로운 기능 추가 등이 있다.

<br>

- 레거시 시스템 유지보수를 피하기 위한 소프트웨어 설계 원칙은 다음 세 가지가 있다.
  - 운용성(operability) : 운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만들어라.
  - 단순성(simplicity) : 시스템에서 복잡도를 최대한 제거해 새로운 엔지니어가 시스템을 이해하기 쉽게 만들어라(사용자 인터페이스의 단순성과는 다르다는 점에 유의하라)
  - 발전성(evolvability) : 엔지니어가 이후에 시스템을 쉽게 변경할 수 있게 하라. 그래야 요구사항 변경 같은 예기치 않은 사용 사례를 적용하기가 쉽다. 이 속성은 유연성(extensibility), 수정 가능성(modifiability), 적응성(plasticity)으로 알려져 있다.

<br>

운용성 : 운영의 편리함 만들기
- 시스템이 지속해서 원활하게 작동하려면 운영팀이 필수다. 좋은 운영팀은 일반적으로 다음과 같은 작업 등을 책임진다.
  - 시스템 상태를 모니터링하고 상태가 좋지 않다면 빠르게 서비스를 복원
  - 시스템 장애, 성능 저하 등의 문제의 원인을 추적
  - 보안 패치를 포함해 소프트웨어와 플랫폼을 최신 상태로 유지
  - 다른 시스템이 서로 어떻게 영향을 주는지 확인해 문제가 생길 수 있는 변경 사항을 손상을 입히기 전에 차단
  - 미래에 발생 가능한 문제를 예측해 문제가 발생하기 전에 해결(예를 들어 용량 계획)
  - 배포, 설정 관리 등을 위한 모범 사례와 도구를 마련
  - 애플리케이션을 특정 플랫폼에서 다른 플랫폼으로 이동하는 등 복잡한 유지보수 태스클르 수행
  - 설정 변경으로 생기는 시스템 보안 유지보수
  - 예측 가능한 운영과 안정적인 서비스 환경을 유지하기 위한 절차 정의
  - 개인 인사 이동에도 시스템에 대한 조직의 지식을 보존함
- 좋은 운영성이란 동일하게 반복된느 태스크를 쉽게 수행하게끔 만들어 운영팀이 고부가가치 활동에 노력을 집중한다는 의미다. 데이터 시스템은 동일 반복 태스크를 쉽게 하기 위해 아래 항목 등을 포함해 다양한 일을 할 수 있다.
  - 좋은 모니터링으로 런타임(runtime) 동작과 시스템의 내부에 대한 가시성 제공
  - 표준 도구를 이요해 자동화와 통합을 위한 우수한 자원을 제공
  - 개별 장비 의존성을 회피, 유지보수를 위해 장비를 내리더라도 시스템 전체에 영향을 주지 않고, 계속해서 운영 가능해야 함
  - 좋은 문서와 이해하기 쉬운 운영 모델(예를 들어 "X를 하면 Y가 발생한다") 제공
  - 만족할 만한 기본 동작을 제공하고, 필요할 때 기본값을 다시 정의할 수 있는 자유를 관리자에게 부여
  - 적절하게 자기 회복(self-healing)이 가능할 뿐 아니라 필요에 따라 관리자가 시스템 상태를 수동으로 제어할 수 있게 함
  - 예측 가능하게 동작하고 예기치 않은 상황을 최소화함

<br>

단순성 : 복잡도 관리
- 복잡도는 같은 시스템에서 작업해야 하는 모든 사람의 진행을 느리게 하고 나아가 유지보수 비용이 증가한다. 복잡도는 다양한 증상으로 나타난다. 상태 공간의 급증, 모듈 간 강한 커플링(tight coupling), 복잡한 의존성, 일관성 없는 명명(naming)과 용어, 성능 문제 해결을 목표로 한 해킹, 임시방편으로 문제를 해결한 특수 사례(special-casing) 등이 이런 증상이다.
- 우발적 복잡도를 제거하기 위한 최상의 도구는 추상화다. 좋은 추상화는 깔끔하고 직관적인 외관 아래로 많은 세부 구현을 숨길 수 있다. 예를 들어, 고수준 프로그래밍 언어는 기계 언어, CPU 레지스터, 시스템 호출을 숨긴 추상화다. 

<br>

발전성 : 변화를 쉽게 만들기
- 조직 프로세스 측면에서 애자일(agile) 작업 패턴은 변화에 적응하기 위한 프레임워크를 제공한다. 또하 애자일 커뮤니티는 테스트 주도 개발(test-driven development(TDD)) 과 리팩토링(refactoring) 같이 자주 변화하는 환경에서 소프트웨어를 개발할 때 도움이 되는 기술 도구와 패턴을 개발하고 있다.

</details>

## 02장. 데이터 모델과 질의 언어

<details>
<summary>fold/unfold</summary>

대부분의 애플리케이션은 하나의 데이터 모델을 다른 데이터 모델 위의 계층을 둬서 만든다. 각 계층의 핵심적인 문제는 다음 하위 계층 관점에서 데이터 모델을 표현하는 방법이다.
- 애플리케이션 개발자는 현실(사람, 조직, 상품, 행동, 자금 흐름, 센서 등)을 보고 객체나 데이터 구조, 그리고 이러한 데이터 구조를 다루는 API를 모델링한다. 이런 구조는 보통 애플리케이션에 특화돼 있다.
- 데이터 구조를 저장할 때는 JSON 이나 XML 문서, 관계형 데이터베이스 테이블이나 그래프 모델 같은 범용 데이터 모델로 표현한다.
- 데이터베이스 소프트웨어를 개발하는 엔지니어는 JSON/XML/관계형/그래프 데이터를 메모리나 디스크 또는 네트워크 상의 바이트 단위로 표현하는 방법을 결정한다. 이 표현은 다양한 방법으로 데이터의 질의, 탐색, 조작, 처리할 수 있게 된다.
- 더 낮은 수준에서 하드웨어 엔지니어는 전류, 빛의 파동, 자기장 등의 관점에서 바이트를 표현하는 방법을 알아냈다.

<br>

### 관계형 모델과 문서 모델
- 오늘날 잘 알려진 데이터 모델은 1970년 에드가 코드(Edgar Codd)가 제안한 관계형 모델을 기반으로 한 SQL이다. 데이터는 (SQL에서는 테이블이라 불리는) 관계(relation)로 구성되고 각 관계는 순서 없는 튜플(tuple) (SQL에서 로우(row)) 모음이다.

<br>

### NoSQL의 탄생
- 현재 2010년대의 NoSQL은 관계형 모델의 우위를 뒤집으려는 가장 최신 시도다. "NoSQL"이라는 이름은 실제 어떤 특정 기술을 참고한 것이 이나기에 적절하지 않다. 원래 NoSQL 은 2009년에 오픈소스, 분산환경, 비관계형 데이터베이스 밋업(meetup)용 인기 트위터 해시태그였다. NoSQL은 거슬러 올라가 Not Only SQL로 재해석됐다.
- NoSQL 데이터베이스를 채택한 데는 다음과 같은 원동력이 있다.
  - 대규모 데이터셋이나 매우 높은 쓰기 처리량 달성을 관계형 데이터베이스보다 쉽게 할 수 있는 뛰어난 확장성의 필요
  - 상용 데이터베이스 제품보다 무료 오픈소스 소프트웨어에 대한 선호도 확산
  - 관계형 모델에서 지원하지 않는 특수 질의 동작
  - 관계형 스키마의 제한에 대한 불만과 더욱 동적이고 표현력이 풍부한 데이터 모델에 대한 바람

<br>

### 객체 관계형 불일치
- 오늘날 대부분의 애플리케이션은 객체지향 프로그래밍 언어로 개발한다. 이는 SQL 데이터 모델을 향한 공통된 비판을 불러온다. 데이터를 관계형 테이블에 저장하려면 애플리케이션 코드와 데이터 베이스 모델 객체(테이블, 로우, 칼럼) 사이에 거추장스러운 전환 계층이 필요하다. 이런 모델 사이의 분리를 종종 임피던스 불일치(impedance mismatch)라고 부른다.
  - 임피던스란 전자공학에서 빌려온 용어이다. 모든 저기 회로는 입력과 출력에 일정한 임피던스(교류에 대한 저항)를 갖고 있다. 한 회로의 출력을 또 다른 회로의 입력으로 연결했을 때 두 회로의 출력과 입력 임피던스가 일치하면 연결을 통한 전력 전달은 최대가 된다. 임피던스가 불일치하면 신호 반사 및 여러 문제를 겪을 수 있다.
- 관계형 스키마에서 이력서를 어떻게 표현하는지 예를 들어볼 때, 대부분의 사람들은 경력에 입력할 수 있는 값이 하나 이상일 것이다. 이때 사용자와 이들 항목은 일대다(one-to-many) 관계다. 이 관계를 나타낼 때는
  - 전통적인 SQL 모델(SQL:1999 이전)에서 가장 일반적인 정규화 표현은 직위, 학력, 연락처 정보를 개별 테이블에 넣고 외래 키롤 지원자 테이블을 참조하는 방식이다.
  - SQL 표준의 마지막 버전에서 구조화된 데이터 타입(datatype) 과 XML 데이터에 대한 지원을 추가했다. 이 지원으로 단일 로우에 다중 값을 저장할 수 있고 문서 내 질의와 색인이 가능해졌다. 이런 기능은 오라클, IBM DB2, 마이크로소프트 SQL 서버, 포스트 그레스큐엘(PostgreSQL) 같은 데이터베이스마다 제각각 다양한 형태로 지원한다. 
    - JSON은 XML 보다 훨씬 더 간단해 매력적이다. 몽고DB(MongoDB), 리싱크DB(RethinkDB), 카우치DB(CouchDB)와 에스프레소(Espresso) 같은 문서 지향(document-oriented) 데이터베이스는 JSON 데이터 모델을 지원한다.
  - 세 번째 방법으로 직업, 학력, 연락처 정보를 JSON이나 XML 문서로 부호화해 데이터베이스의 텍스트 칼럼에 저장한 다음 애플리케이션이 구조와 내용을 해석하게 하는 방식이다. 이 방식을 쓰면 일반적으로 부호화된 칼럼의 값을 질의하는 데 데이터베이스를 사용할 수 없다.

<br>

- JSON 표현은 다중 테이블(multi-table) 스키마보다 더 나은 지역성(locality)을 갖는다. 관계형 예제에서 프로필을 가져오려면 다중 질의(각 테이블에 user_id로 질의)를 수행하거나 users 테이블과 그 하위 테이블 간에 난잡한 다중 조인을 수행해야 한다. JSON 표현에서는 모든 관련 정보가 한 곳에 있어 질의 하나로 충분하다.

<br>

### 다대일과 다대다 관계
- 관계형 데이터베이스의 설계에서 중복을 최소화하게 데이터를 구조화하는 프로세스를 정규화(Normalization)라고 한다.
- 중복된 데이터를 정규화하려면 다대일(many-to-one) 관계(많은 사람들은 한 특정 지역에 살거나 한 특정 업계에서 일한다) 가 필요한데 안타깝게도 다대일 관계는 문서 모델에 적합하지 않다. 관계형 데이터베이스에서는 조인이 쉽기 때문에 ID로 다른 테이블의 로우를 참조하는 방식은 일반적이다. 문서 데이터베이스에서는 일대다 트리 구조를 위해 조인이 필요하지 않지만 조인에 대한 지원이 보통 약하다.
- 데이터베이스 자체가 조인을 지원하지 않으면 데이터베이스에 대한 다중 질의를 만들어서 애플리케이션 코드에서 조인을 흉내내야 한다. 
- 아래 그림은 다대다 관계를 어떻게 필요로 하는지 보여준다. 각 점선 내 데이터는 하나의 문서로 묶을 수 있지만 조직, 학교, 기타 사용자는 참조로 표현해야 하고 질의할 때는 조인이 필요하다.
<img src="https://camo.githubusercontent.com/d64f1e7b58faec0e832b72598314c80c131e03cde9b30ffaa8f95a29223ab7fb/68747470733a2f2f73332d65752d776573742d312e616d617a6f6e6177732e636f6d2f6a752e7075626c69632f676974732e6769746875622e636f6d2f4d617274696e2532304b6c6570706d616e6e2532302d25323044657369676e696e67253230446174612d496e74656e736976652532304170706c69636174696f6e732f466967757265253230322d342e706e67" width="40%" height="40%">

<br>

### 문서 데이터베이스는 역사를 반복하고 있나?
- 계층 모델 : 상당힌 간단한 데이터 모델이다. 계층 모델은 문서 데이터베이스에서 사용하는 JSON 모델과 놀랍도록 비슷하다. 모든 데이터를 레코드 내에 중첩된 레코드 트리로 표현한다.
  - 문서 데이터베이스처럼 일대다 관계에서는 잘 동작한다. 하지만 다대다 관계 표현은 어려웠고 조인을 지원하지 않는다.
- 네트워크 모델 : 네트워크 모델에서 레코드 간 연결은 외래 키보다는 프로그래밍 언어의 포인터와 더 비슷하다. 레코드에 접근하는 유일한 방법은 최상위 레코드(root record)에서부터 연속된 연결 경로를 따르는 방법이다. 이를 접근 경로라 한다.
  - 졉근 경로가 연결 목록의 순회와 같을 때 구조가 가장 간단해진다. 하지만 다대다 관계에서는 다양한 다른 경로가 같은 레코드로 이어질 수 있고 네트워크 모델을 사용하는 프로그래머는 경로의 맨 앞에서 이런 다양한 접근 경로를 계속 추적해야 한다.
  - 수동 접근 경로 선택은 1970년대에는 매우 제한된 하드웨어 성능을 가장 효율적으로 사용할 수 있었지만 데이터베이스 질의와 갱신을 위한 코드가 복잡하고 유연하지 못한 문제가 있었다. 계층 모델과 네트워크 모델 모두, 원하는 데이터에 대한 경로가 없다면 어려운 상황에 놓인다.
- 관계형 모델 : 대조적으로 관계형 모델이 하는 일은 알려진 모든 데이터를 배치하는 것이다. 관계(테이블)는 단순히 튜플(로우)의 컬렉션이 전부다. 얽히고 설킨 중첩 구조와 데이터를 보고 싶을 때 다라가야 할 복잡한 접근 경로가 없다. 임의 조건과 일치하는 테이블의 일부 또는 모든 로우를 선택해서 읽을 수 있고 일부 칼럼을 키로 지정해 칼럼과 일치하는 특정 로우를 읽을 수 있다. 다른 테이블과의 외래 키 관계에 대해 신경 쓰지 않고 임의 테이블에 새 로우를 삽입할 수 있다.
  - 관계형 데이터베이스에서 질의 최적화기(query optimizer)는 질의의 어느 부분을 어떤 순서로 실행할지를 결정하고 사용할 색인을 자동으로 결정한다. 이 선택은 실제로 '접근 경로'다. 하지만 큰 차이점은 접근 경로를 애플리케이션 개발자가 아니라 질의 최적화기가 자동으로 만든다는 점이다. 그래서 접근 경로를 따로 생각할 필요가 없다.
  - 새로운 방식으로 데이터에 질의하고 싶은 경우 새로운 색인을 선언하기만 하면 질의는 자동으로 가장 적합한 색인을 사용한다. 새로운 색인을 사용하기 위해 질의를 바꿀 필요가 없다. 따라서 관계형 모델은 애플리케이션에 새로운 기능을 추가하는 작업이 훨씬 쉽다.

### 문서 데이터베이스와의 비교
- 문서 데이터베이스는 한 가지 측면에서 계층 모델로 되돌아갔다. 문서 데이터베이스는 별도 테이블이 아닌 상위 레코드 내에 중첩된 레코드를 저장한다.
- 하지만 다대일과 다대다 관계를 표현할 때 관계형 데이터베이스와 문서 데이터베이스는 근본적으로 다르지 않다. 둘 다 관련 항목은 고유한 식별자로 참조한다. 관계형 모델에서는 외래 키라 부르고 문서 모델에서는 문서 참조(document reference)라 부른다. 이 식별자는 조인이나 후속 질의를 사용해 읽기 시점에 확인한다. 현재까지는 문서 데이터베이스가 코다실(계층 모델)의 전철을 밟지 않고 있다.

### 어떤 데이터 모델이 애플리케이션 코드를 더 간단하게 할까?
- 애플리케이션에서 데이터가 문서와 비슷한 구조(일대다 관계 트리로 보통 한 번에 전체 트리를 적재)라면 문서 모델을 사용해서 찢는 것이 좋다. 문서와 비슷한 구조를 여러 테이블로 나누어 찢는(shredding) 관계형 기법은 다루기 힘든 스키마와 불필요하게 복잡한 애플리케이션 코드를 발생시킨다.
- 문서 모델에는 제한이 있다. 예를 들어 문서 내 중첩 항목을 바로 참조할 수는 없어서 "상요자 251의 직위 목록의 두 번째 항목"과 같이 표현해야 한다.(계층 모델에서 접근 경로와 매우 유사) 하지만 문서가 너무 깊게 중첩되지 않으면 일반적으로 문제가 되지 않는다.
- 문서 데이터베이스의 미흡한 조인 지원은 애플리케이션에 따라 문제일 수도 있고 아닐 수도 있다. 예를 들어 어떤 시점에 발생한 이벤트를 기록하는 문서 데이터베이스를 사용하는 분석 애플리케이션에서는 다대다 관계가 결코 필요하지 않다.


### 문서 모델에서의 스키마 유연성
...

### 질의를 위한 데이터 지역성
- 문서는 보통 JSON, XML 로 부호화된 단일 연속 문자열이나 (몽고DB와 BSON 같은) JSON 또는 XML 의 이진 변형으로 저장된다. 웹 페이지 상에 문서를 보여주는 동작처럼 애플리케이션이 자주 전체 문서에 접근해야 할 때 저장소 지역성(storage locality) 을 활용하면 성능 이점이 있다. 
- 지역성의 이점은 한 번에 해당 문서의 많은 부분을 필요로 하는 경우에만 적용된다. 데이터베이스는 대개 문서의 작은 부분에만 접근해도 전체 문서를 적재해야 하기에 큰 문서에서는 낭비일 수 있다. 문서를 갱신할 도 보통 전체 문서를 재작성해야 한다. 이런 이유로 일반적으로 문서를 아주 작게 유지하면서 문서의 크기가 증가하는 쓰기를 피하라고 권장한다. 이 성능 제한 때문에 문서 데이터베이스가 유용한 상황이 많이 줄어든다.


### 문서 데이터베이스와 관계형 데이터베이스의 통합
...


### 데이터를 위한 질의 언어
- 관계형 모델이 등장했을 때 데이터를 질의하는 새로운 방법도 함께 나타났다. SQL은 선언형 질의 언어인 반면 IMS와 코다실은 명령형 코드를 사용해 데이터베이스에 질의한다.
- 명령형 언어는 특정 순서로 특정 연산을 수행하게끔 컴퓨터에게 지시한다. 지시의 예로 코드를 한 줄 씩 실행하고 조건을 평가하고 변수를 갱신하고 루프를 한 번 더 실행할지 여부를 결정하는 것을 들 수 있다.
  - SQL이나 관계 대수 같은 선언형 질의 언어에서는 목표를 달성하기 위한 방법이 아니라 알고자 하는 데이터의 패턴, 즉 결과가 충족해야 하는 조건과 데이터를 어떻게 변환(예를 들어 정렬, 그룹화, 집계)할지를 지정하기만 하면 된다. 어떤 색인과 어떤 조인 함수를 사용할지, 질의의 다양한 부분을 어떤 순서로 실행할지를 결정하는 일은 데이터베이스 시스템의 질의 최적화기가 할 일이다.
- 선언형 언어는 종종 병렬 실행에 적합하다. 오늘날 CPU 는 이전보다 훨씬 더 높은 클록 속도로 실행해 빨라지기보다 더 많은 코어를 추가해 빨라지고 있다. 명령형 코드는 명령어를 특정 순서로 실행하게끔 지정하기 때문에 다중 코어나 다중 장비에서 병렬 처리가 매우 어렵다. 선언형 언어는 결과를 결정하기 윟나 알고리즘을 지정하는 게 아니라 결과의 패턴만 지정하기 때문에 병렬 실행으로 더 빨라질 가능성이 있다.

...
</details>


</details>

## 03장. 저장소와 검색

<details>
<summary>fold/unfold</summary>

### 데이터베이스를 강력하게 만드는 데이터 구조
- 데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 다른 데이터 구조가 필요하다. 바로 색인이다. 
- 색인의 일반적인 개념은 어떤 부가적인 메타데이터를 유지하는 것이다. 이 메타데이터는 이정표 역할을 해서 원하는 데이터의 위치를 찾는 데 도움을 준다. 동일한 데이터를 여러 가지 다양한 방법으로 검색하고자 한다면 데이터의 각 부분에 여러 가지 다양한 색인이 필요하다.
- 색인은 기본 데이터(primary data)에서 파생된 추가적인 구조이다. 많은 데이터베이스는 색인의 추가와 삭제를 허용한다. 이 작업은 데이터베이스의 내용에는 영향을 미치지 않는다. 단지 질의 성능에만 영향을 준다. 추가적인 구조의 유지보수는 특히 쓰기 과정에서 오버헤드가 발생한다. 쓰기의 경우 단순히 파일에 추가할 때의 성능을 앞서기 어렵다. 왜냐하면 단순히 파일에 추가하는 작업이 제일 간단한 쓰기 작업이기 때문이다. 어떤 종류의 색인이라도 대개 쓰기 속도를 느리게 만든다. 이는 데이터를 쓸 때마다 매번 색인도 갱신해야 하기 때문이다.

### 해시 색인
- 키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입(dictionary type)과 매우 유사하다. 보통 해시 맵(hash map)(해시 테이블(hash table)) 으로 구현한다. 해시 맵은 많은 알고리즘 교과서에서 설명하고 있어서 여기서 동작 방식을 자세히 설명하지 않는다. 인메모리 데이터 구조를 위한 해시 맵이 이미 있으니 디스크 상의 데이터를 색인하기 위해 인메모리 데이터 구조를 사용하는 것은 어떨까?

<img src="https://brilliun.com/images/designing-data-intensive-applications/3-1.png" width="40%" height="40%">


- 이 방식은 매우 단순해 보이지만 실제로 많이 사용되는 접근법이다. 해시 맵을 전부 메모리에 유지하기 때문에 사용 가능한 랩(RAM)에 모든 키가 저장된다는 조건을 전제로 고성능으로 읽기, 쓰기를 보장한다. 값은 한 번의 디스크 탐색으로 디스크에서 적재할 수 있기 때문에 사용 가능한 메모리보다 더 많은 공간을 사용할 수 있다. 만약 데이터 파일의 일부가 이미 파일 시스템 캐시에 있다면 읽기에 디스크 입출력이 필요하지 않다.
  - 이런 저장소 엔진은 각 키의 값이 자주 갱신되는 상황에 매우 적합하다. 예를 들어 키는 고양이 동영상의 URL 이고 값은 비디오가 재생된 횟수 (재생 버튼을 누를 때마다 증가함) 인 경우다. 이런 유형의 작업 부하에서는 쓰기가 아주 많지만 고유 키는 많지 않다. 즉, 키당 쓰기 수가 많지만 메모리에 모든 키를 보관할 수 있다.
  - 지금까지 설명한 것처럼 파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 이 상황은 어떻게 피할 수 있을까? 특정 크기의 세그먼트(segment) 로 로그를 나누는 방식이 좋은 해결책이다. 특정 크기에 도달하면 세그먼트 파읠을 닫고 새로운 세그먼트를 파일에 이후 쓰기를 수행한다. 세그먼트 파일들에 대해 컴팩션(compaction)을 수행할 수 있다. 컴팩션은 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것을 의미한다.


<img src="https://brilliun.com/images/designing-data-intensive-applications/3-2.png" width="40%" height="40%">


<img src="https://brilliun.com/images/designing-data-intensive-applications/3-3.png" width="40%" height="40%">

<br>

이런 간단한 생각을 실제로 구현하려면 세부적으로 많은 사항을 고려해야 한다. 실제 구현에서 중요한 문제 몇 가지만 간략히 들자면 다음과 같다.
- 파일 형식
- 레코드 삭제
- 고장(Crash) 복구
- 부분적으로 레코드 쓰기
- 동시성 제어

<br>

추가 전용 로그는 언뜻 보면 낭비처럼 보인다. 예전 값을 새로운 값으로 덮어써 정해진 자리에 파일을 갱신하는 방법은 어떨까? 하지만 전용 추가 설계은 여러 측면에서 좋은 설계다.
- 추가와 세그먼트 병합은 순차적인 쓰기 작업이기 때문에 보통 무작위 쓰기보다 훨씬 빠르다. 특히 자기 회전 디스크 하드드라이브에서 그렇다. 일부 확장된 순차 쓰기는 플래시 기반 솔리드 스테이트 드라이브(SSD) 도 선호한다.
- 세그먼트 파일이 추가 전용이나 불변이면 동시성과 고장 복구는 훨씬 간단하다. 예를 들어 값을 덮어 쓰는 동안 데이터베이스가 죽는 경우에 대해 걱정할 필요 없다. 이전 값 부분과 새로운 값 부분을 포함한 파일을 나누어 함께 남겨두기 위함이다.
- 오래된 세그먼트 병합은 시간이 지남에 따라 조각화된느 데이터 파일 문제를 피할 수 있다.

하지만 해시 테이블 색인 또한 제약 사항이 있다.
- 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 된다. 원칙적으로는 디스크에 해시 맵을 유지할 수 있지만 불행하게도 디스크 상의 해시 맵에 좋은 성능을 기대하기란 어렵다. 이는 무작위 접근 I/O가 많이 필요하고 디스크가 가득 찼을 때 확장하는 비용이 비싸며 해시 충돌 해소를 위해 성가신 로직이 필요하다.
- 해시 테이블은 범위 질의(range query)에 효율적이지 않다. 예를 들어 kitty00000과 kitty99999 사이 모든 키를 쉽게 스캔할 수 없다. 해시 맵에서 모든 개별 키를 조회해야 한다.

### SS테이블과 LSM 트리
위의 그림에서 각 로그 구조화 저장소 세그먼트는 키-값 쌍의 연속이다. 이 쌍은 쓰여진 순서대로 나타나며 로그에서 같은 키를 갖는 값 중 나중의 값이 이전 값보다 우선한다. 이 점만 제외하면 파일에서 키-값 쌍의 순서는 문제가 되지 않는다.
  - 이제 세그먼트 파일의 형식에 간단한 변경 사항 한 가지를 적용해보자. 변경 요구사항은 일련의 키-값 쌍을 키로 정렬하는 것이다. 이처럼 키로 정렬된 형식을 정렬된 문자열 테이블(Sorted String Table) 또는 짧게 SS테이블이라 부른다. 그리고 또한 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다.(컴팩션 과정은 이를 이미 보장한다.) SS테이블은 해시 색인을 가진 로그 세그먼트보다 몇 가지 큰 장점이 있다.
    - 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단한고 효율적이다. 이 접근법은 병합정렬(merge sort) 알고리즘에서 사용하는 방식과 유사하다. 먼저 입력 팡링르 함께 읽고 각 파일의 첫 번째 키를 본다.(정렬된 순서에 따라) 그리고 가장 낮은 키를 출력 파일로 복사한 뒤 이 과정을 반복한다. 이 과정에서 새로운 병합 세그먼트 파일이 생성된다. 새로 만든 세그먼트 파일도 역시 키로 정렬돼 있다.


<img src="https://brilliun.com/images/designing-data-intensive-applications/3-4.png" width="40%" height="40%">

- 여러 입력 세그먼트에 동일한 키가 있으면 어떻게 해야 할까? 각 세그먼트는 일정 기간 동안 데이터베이스에 쓰여진 모든 값이 포함된다는 점에 유의하자. 이것은 입력 세그먼트 하나의 모든 값이 다른 세그먼트의 모든 값보다 최신 값이라는 점을 의미한다.(항상 인접된 세그먼트의 병햡을 가정한다.) 다중 세그먼트가 동일한 키를 포함하는 경우 가장 최근 세그먼트의 값은 유지하고 오래된 세그먼트의 값은 버린다.
- 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요가 없다. 특정 키의 색인을 확인할 수 없더라도 주변 키의 색인 값을 활용하여 탐색하는 키 값의 스캔 범위를 최소화할 수 있다.
- 읽기 요청은 요청 범위 내에서 여러 키-값 쌍을 스캔해야 하기 때문에 해당 레코드들을 블록으로 그룹화하고 디스크에 쓰기 전에 압축한다. 그러면 희소 인메모리 색인의 각 항목은 압축된 블록을 시작을 가리키게 된다. 디스크 공간을 절약한다는 점 외에도 압축은 I/O 대역폭 사용도 줄인다.

### SS 테이블 생성과 유지
디스크 상에 정렬된 구조를 유지하는 일은 가능하지만 메모리에 유지하는 편이 훨씬 쉽다. 레드 블랙 트리(red-black tree)나 AVL 트리와 같이 잘 알려졌고 사용 가능한 트리 데이터 구조는 많이 있다. 이런 데이터 구조를 이용하면 임의 순서로 키를 삽입하고 정렬된 순서로 해당 키를 다시 읽을 수 있다.

<br>

저장소 엔진을 다음과 같이 만들 수 있다.
- 쓰기가 들어오면 인메모리 균형 트리(balanced tree) 데이터 구조(예를 들어 레드 블랙 트리)에 추가한다. 이 인메모리 트리는 멤테이블(memtable)이라고도 한다.
- 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS 테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 새로운 SS 테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. SS테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다.
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그 다음 디스크 상의 가장 최신 세그먼트에서 찾는다. 그 다음으로 두 번째 오래된 세그먼트, 세 번째 오래된 세그먼트 등에서 찾는다.
- 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합과 컴팩션 과정을 수행한다. 이 과정은 백그라운드에서 수행된다.

<br>

이 계획은 잘 동작하지만 한 가지 문제가 있는데, 만약 데이터베이스가 고장나면 아직 디스크로 기록되지 않고 멤테이블에 있는 가장 최신 쓰기는 손실된다. 이런 문제를 피하기 위해서는 매번 쓰기를 측시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 한다. 이 로그는 손상 후 멤테이블을 복원할 때만 필요하기 때문에 순서가 정렬되지 않아도 문제되지 않는다. 멤테이블을 SS테이블로 기록하고 나면 해당 로그는 버릴 수 있다.

### SS 테이블에서 LSM 트리 만들기
- 여기에 기술된 알고리즘은 기본적으로 레벨DB(LevelDB)와 록스DB(RocksDB) 그리고 다른 애플리케이션에 내장하기 위해 설계된 키-값 저장소 엔진 라이브러리에서 사용한다. 이 중에서 리악에서는 비트캐스크의 대안으로 레벨DB를 사용할 수 있고 구글의 빅테이블(Bigtable) 논문(SS테이블과 멤테이블 이라는 용어가 소개됐다.)에서 영감을 얻은 카산드라와 HBase에서도 유사한 저장소 엔진을 사용한다.
- 원래 이 색인 구조는 로그 구조화 병합 트리(Log-structured Merge-Tree)(또는 LSM 트리)란 이름으로 패트릭 오닐(Oatrick O'Neil) 등이 발표했다. 이 색인 구조는 로그 구조화 파일 시스템의 초기 작업의 기반이 됐다. 저렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진을 LSM 저장소 엔진이라 부른다.

### 성능 최적화
...

### B 트리
가장 널리 사용되는 색인 구조는 B트리(B-tree)로 구조가 로그 구조화 색인과는 상당히 다르다. 거의 대부분의 관계형의 데이터베이스에서 표준 색인 구현으로 B 트리를 사용할 뿐 아니라 많은 비 관계형 데이터베이스에서도 사용한다.
- B 트리는 SS 테이블과 같이 키로 정렬된 키-값 쌍을 유지하기 때문에 키-값 검색과 범위 질의에 효율적이다. 하지만 비슷한 점은 이 정도가 전부다. B 트리는 설계 철학이 매우 다르다.
- 로그 구조화 색인은 데이터베이스를 일반적으로 수 메가바이트 이상의 가변 크기를 가진 세그먼트로 나누고 항상 순차적으로 세그먼트를 기록한다. 반면 B 트리는 전통적으로 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다. 디스크가 고정 크기 블록으로 배열되기 때문에 이런 설계는 근본적으로 하드웨어와 조금 더 밀접한 관련이 있다.
- 각 페이지는 주소나 위치를 이용해 식별할 수 있다. 이 방식으로 하나의 페이지가 다른 페이지를 참조할 수 있다.(포인터와 비슷하지만 메모리 대신 디스크에 있음). 이 페이지 참조는 아래 그림과 같이 페이지 트리를 구성하는 데 사용할 수 있다.

<img src="https://ebrary.net/htm/img/15/554/22.png" width="40%" height="40%">

- 한 페이지는 B 트리의 루트(root)로 지정된다. 색인에서 키를 찾으려면 루트에서 시작한다. 페이지는 여러 키와 하위 페이지의 참조를 포함한다. 각 하위 페이지는 키가 계속 이어지는 범위를 담당하고 참조 사이의 키는 해당 범위 경계가 어디인지 나타낸다.
  - 위의 예시에서는 키 251을 찾고 있었기 때문에 200과 300 경계 사이의 페이지 참조를 따라가야 한다는 사실을 알 수 있다. 그러면 200~300 범위와 비슷하게 생겼지만 좀 더 작은 범위로 더 나눈 페이지로 이동한다.
  - 최종적으로 개별 키(리프 페이지(leaf page)) 를 포함하는 페이지에 도달한다. 이 페이지는 각 키의 값을 포함하거나 값을 찾을 수 있는 페이지의 참조를 포함한다.
- B 트리의 한 페이지에서 하위 페이지를 참조하는 수를 분기 계수(branching factor)라고 부른다. 예를 들어 위의 그림에서 분기 계수는 6이다.
- B 트리에 존재하는 키의 값을 갱신하려면 키를 포함하고 있는 리프 페이지를 검색하고 페이지의 값을 바꾼 다음 페이지를 디스크에 다시 기록한다.(페이지에 대한 모든 참조는 계속 유효하다.) 새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다. 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다.

<img src="https://ebrary.net/htm/img/15/554/23.png" width="40%" height="40%">

- 이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장한다. n 개의 키를 가진 B 트리는 깊이가 항상 O(log n) 이다. 대부분의 데이터베이스는 B 트리의 깊이가 3이나 4단계 정도면 충분하므로 검색하려는 페이지를 찾기 위해 많은 페이지 참조를 따라가지 않아도 된다.(분기 계수 500의 4KB 페이지의 4단계 트리는 256TB 까지 저장할 수 있다.)

### 신뢰할 수 있는 B 트리 만들기
B 트리의 기본적인 쓰기 동작은 새로운 데이터를 디스크 상의 페이지에 덮어쓴다. 이 동작은 덮어쓰기가 페이지 위치를 변경하지 않는다고 가정한다. 즉 페이지를 덮어쓰더라도 페이지를 가리키는 모든 참조는 온전하게 남는다. LSM 트리와 같은 로그 구조화 색인과는 아주 대조적인 점이다. 로그 구조화 색인은 파일에 추가만 할 뿐(결국 더 이상 쓸모 없는 파일은 삭제됨) 같은 위치의 파일은 변경 하지 않는다.
- 디스크의 페이지를 덮어쓰는 일은 실제 하드웨어 동작이라고 생각할 수 있다. 자성의 하드드라이브의 경우 디스크 헤드를 적절한 곳으로 옮기고 회전하는 플래터의 올바른 위치가 돌아올 때까지 기다린 다음 적합한 섹터에 새로운 데이터를 덮어쓴다. SSD의 경우는 SSD 가 저장소  칩의 상당한 블록을 한번에 지우고 다시 쓰기를 해야 하기 때문에 조금 더 복잡하다.

### B 트리 최적화
...
- 페이지 덮어 쓰기와 고장 복구를 위한 WAL 유지 대신(LMDB 같은) 일부 데이터베이스는 쓰기 시 복사 방식(copy-on-write scheme) 을 사용한다. 변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 한다. 이 접근 방식은 동시성 제어에도 유용하다.
- 페이지에 전체 키를 저장하는 게 아니라 키를 축약해 쓰면 공간을 절약할 수 있다. 특히 트리 내부 페이지에서 키가 키 범위 사이의 경계 역할을 하는 데 충분한 정보만 제공하면 된다. 페이지 하나에 키를 더 많이 채우면 트리는 더 높은 분기 계수를 얻는다. 그러면 트리 깊이 수준을 낮출 수 있다.
- 일반적으로 페이지는 디스크 상 어디에나 위치할 수 있다. 키 범위가 가까운 페이지들이 디스크 상에 가까이 있어야 할 필요가 없기 때문이다. 질의가 정렬된 순서로 키 범위의 상당 부분을 스캔해야 한다면 몯느 페이지에 대해 디스크 찾기가 필요하기 때문에 페이지 단위 배치는 비효율적이다. 따라서 많은 B 트리 구현에서 리프(leaf) 페이지를 디스크 상에 연속된 순서로 나타나게끔 트리를 배치하려 시도한다. 하지만 트리가 커지면 순서를 유지하기가 어렵다. 반대로 LSM 트리는 변합하는 과정에서 저장소의 큰 세그먼트를 한 번에 다시 쓰기 때문에 디스크에서 연속된 키를 서로 가깝게 유지하기 더 쉽다.
- 트리에 포인터를 추가한다. 예를 들어 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있다.
- 프랙탈 트리(fractal tree) 같은 B 트리 변형은 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다.(프랙탈 트리는 기하학의 프랙탈과는 아무런 관련도 없다).

### B 트리와 LSM 트리 비교
- B 트리가 LSM 트리보다 일반적으로 구현 성숙도가 더 높지만 LSM 트리도 그 성능 특성 때문에 관심을 받고 있다. 경험적으로 LSM 트리는 보통 쓰기에서 더 빠른 반면 B 트리는 읽기에서 더 빠르다고 여긴다. 읽기가 보통 LSM 트리에서 더 느린 이유는 각 컴팩션 단계에 있는 여러 가지 데이터 구조와 SS 테이블을 확인해야 하기 때문이다.

### LSM 트리의 장점
B 트리 색인은 모든 데이터 조각을 최소한 두 번 기록해야 한다. 쓰기 전 로그 한 번과 트리 페이지에 한 번(페이지가 분리될 때 다시 기록)이다. 해당 페이지 내 몇 바이트만 바뀌어도 한 번에 전체 페이지를 기록해야 하는 오버헤드도 있다. 일부 저장소 엔진은 심지어 전원에 장애가 발생했을 때 일부만 갱신된 페이지로 끝나지 않게 동일한 페이지를 두 번 덮어쓴다.
- 로그 구조화 색인 또한 SS 테이블의 반복된 컴팩션과 병합으로 인해 여러 번 데이터를 다시 쓴다. 데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 디스크에 여러 번의 쓰기를 야기하는 이런 효과를 쓰기 증폭(write amplification)이라 한다. SSD는 수명이 다할 때까지 블록 덮어쓰기 횟수가 제한되기 때문에 쓰기 증폭은 SSD 의 경우 특별한 관심사다.
- 쓰기가 많은 애플리케이션에서 성능 병목은 데이터베이스가 디스크에 쓰는 속도일 수 있다. 이 경우 쓰기 증폭은 바로 성능 비용이다. 저장소 엔진이 디스크에 기록할수록 디스크 대역폭 내 처리할 수 있는 초당 쓰기는 점점 줄어든다.
- 더욱이 LSM 트리는 보통 B 트리보다 쓰기 처리량을 높게 유지할 수 있다.(저장소 엔진 설정과 작업부하에 따라 다르긴 하지만) LSM 트리가 상대적을 쓰기 증폭이 더 낮고 트리에서 여러 페이지를 덮어쓰는 것이 아니라 순차적으로 컴팩션된 SS 테이블 파일을 쓰기 때문이다. 이런 차이는 자기 하드드라이브에서 특히 중요하다. 자기 하드드라이브는 순차 쓰기가 임시 쓰기보다 훨씬 더 빠르다.
- LSM 트리는 압축률이 더 좋다. 그래서 보통 B 트리보다 디스크에 더 적은 파일을 생성한다. B 트리 저장소 엔진은 파편화로 인해 사용하지 않는 디스크 공간 일부가 남는다. 페이지를 나누거나 로우가 기존 페이지에 맞지 않을 때 페이지의 일부 공간은 사용하지 않게 된다. LSM 트리는 페이지 지향적이지 않고 주기적으로 파편화를 없애기 위해 SS 테이블을 다시 기록하기 때문에 저장소 오버헤드가 더 낮다. 레벨 컴팩션(level compaction)을 사용하면 특히 그렇다.
- 대다수의 SSD의 펌웨어는 내장 저장소 칩에서 임의 쓰기를 순차 쓰기로 전환하기 위해 내부적으로 로그 구조화 알고리즘을 사용한다. 그래서 저장소 엔진의 쓰기 패턴이 SSD 에 미치는 영향은 분명하지 않다. 하지만 낮은 쓰기 증폭과 파편화 감소는 SSD의 경우 훨씬 유리하다. 데이터를 더 밀집해 표현하면 가능한 I/O 대역폭 내에서 더 많은 읽기와 쓰기 요청이 가능하다.

### LSM 트리의 단점
로그 구조화 저장소의 단점은 컴팩션 과정이 때로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다는 점이다. 저장소 엔진은 컴팩션을 점진적으로 수행하고 동시 접근의 영향이 없게 수행하려 한다. 하지만 디스크가 가진 자원은 한계가 있다. 그래서 디스크에서 비싼 컴팩션 연산이 끝날 때까지 요청이 대기해야 하는 상황이 발생하기 쉽다. 처리량과 평균 응답 시간이 성능에 미치는 영향은 대개 작다. 하지만 로그 구조화 저장소 엔진의 상위 백분위 질의의 응답 시간은 때때로 꽤 길다. 반면 B 트리의 성능은 로그 구조화 저장소 엔진보다 예측하기 쉽다.
- 또 다른 컴팩션 문제는 높은 쓰기 처리량에서 발생한다. 디스크의 쓰기 대역폭은 유한하다. 초기 쓰기(로깅(logging)과 멤테이블을 디스크로 방출(flushing)) 와 백그라운드에서 수행되는 컴팩션 스레드가 이 대역폭을 공유해야 한다. 빈 데이터베이스에 쓴느 경우 전체 디스크 대역폭은 초기 쓰기만을 위해 사용할 수 있지만 데이터베이스가 점점 커질수록 컴팩션을 위해 더 많은 디스크 대역폭이 필요하다.
- 쓰기 처리량이 높음에도 컴팩션 설정을 주의 깊게 하지 않으면 컴팩션이 유입 쓰기 속도를 따라갈 수 없다. 이 경우 디스크 상에 병햡되지 않은 세그먼트 수는 디스크 공간이 부족할 때까지 증가한다. 그리고 더 많은 세그먼트 파일을 확인해야 하기 때문에 읽기 또한 느려진다. 보통 SS 테이블 기반 저장소 엔진은 컴팩션이 유입 속도를 따라가지 못해도 유입 쓰기의 속도를 조절하지 않으므로 이런 상황을 감지하기 위한 명시적 모니터링이 필요하다.
- B 트리의 장점은 각 키가 색인의 한 곳에만 정확하게 존재한다는 점이다. 반면 로그 구조화 저장소 엔진으 다른 세그먼트에 같은 키의 다중 복사본이 존재할 수 있다. 이런 측면 때문에 강력한 트랜잭션 시맨틱(semantic) 를 제공하는 데이터베이스에는 B 트리가 훨씬 매력적이다. 많은 관계형 데이터베이스에서 트랜잭션 격리(transaction isolation)는 키 범위의 잠금을 사용해 구현한 반면 B트리 색인에서는 트리에 직접 잠금을 포함시킨다.


### 기타 색인 구조
...

### 색인 안에 값 저장하기
...

### 다중 칼럼 색인
...

### 전문 검색과 퍼지 색인
...

### 모든 것을 메모리에 보관
디스크는 메인 메모리와 비교해 다루기 어렵다. 자기 디스크와 SSD 를 사용할 때 읽기와 쓰기에서 좋은 성능을 원한다면 주의해서 데이터를 디스크에 배치해야 한다. 이런 이상함을 참을 수 있는 이유는 디스크에는 주요한 두 가지 장점이 있기 때문이다. 디스크는 지속성(디스크 내용은 전원이 꺼져도 손실되지 않는다)이 있고 램보다 기가바이트당 가격이 더 저렴한다.
- 램이 점점 저렴해져서 기가바이트당 가격 논쟁은 약해졌다. 데이터셋 대부분은 그다지 크지 않기 때문에 메모리에 전체를 보관하는 방식도 꽤 현실적이다. 혹은 여러 장비 간 분산해서 보관할 수도 있다. 이런 이유로 인메모리 데이터베이스가 개발됐다.
- 맴캐시드 같은 일부 인메모리 키-값 저장소는 장비가 재시작되면 데이터 손실을 허용하는 캐시 용도로만 사용된다. 하지만 다른 인메모리 데이터베이스는 지속성을 목표로 한다. 이 목표를 달성하는 방법은 (배터리 전원 공급 RAM과 같은) 특수 하드웨어를 사용하거나 디스크에 변경 사항의 로그를 기록하거나 디스크에 주기적인 스냅숏을 기록하거나 다른 장비에 인메모리 상태를 복제하는 방법이 있다.
- 인메모리 데이터베이스가 재시작되는 경우 특수 하드웨어를 사용하지 않는다면 디스크나 네트워크를 통해 복제본에서 상태를 다시 적재해야 한다. 디스크에 기록하더라도 여전히 인메모리 데이터베이스다. 왜냐하면 디스크는 전적으로 지속성을 위한 추가 전용 로그로 사용되고 읽기는 전적으로 메모리에서 제공되기 때문이다. 디스크에 기록하는 방식은 운영상의 장점도 있다. 디스크 상의 파일은 쉽게 백업이 가능하고 외부 유틸리티를 이용해 검사와 분석을 할 수 있다.
- 직관에 어긋나지만 인메모리 데이터베이스의 성능 장점은 디스크에서 읽지 않아도 된다는 사실 때문은 아니다. 심지어 디스크 기반 저장소 엔진도 운영체제가 최근에 사용한 디스크 블록을 메모리에 캐시하기 때문에 충분한 메모리를 가진 경우에는 디스크에서 읽을 필요가 없다. 오히려 인메모리 데이터 구조를 디스크에 기록하기 위한 형태로 부호화하는 오버헤드를 피할 수 있어 더 빠를 수도 있다.
- 최근 연구에 따르면 인메모리 데이터베이스 아키텍처가 디스크 중심 아키텍처에서 발생하는 오버헤드 없이 가용한 메모리보다 더 큰 데이터셋을 지원하게끔 확장할 수 있다. 소위 안티 캐싱(anti-caching) 접근 방식은 메모리가 충분하지 않을 때 가장 최근에 사용하지 않은 데이터를 메모리에서 디스크로 내보내고 나중에 다시 접근할 때 메모리에 적재하는 방식으로 동작한다. 이것은 운영체제가 가상 메모리와 스왑 파일에서 수행하는 방식과 유사하지만 데이터베이슨느 전체 메모리 페이지보다 개별 레코드 단위로 작업할 수 있기 때문에 OS보다 더 효율적으로 메모리를 관리할 수 있다. 하지만 이 접근 방식은 여전히 전체 색인이 메모리에 있어야 한다.

### 트랜잭션 처리나 분석
...

### 칼럼 지향 저장소
...

### 메모리 대역폭과 벡터화 처리
- 수백만 로우를 스캔해야 하는 데이터 웨어하우스 질의는 디스크로부터 메모리로 데이터를 가져오는 대역폭이 가장 큰 병목이다. 하지만 이 병목이 유일한 것은 아니다. 분석용 데이터베이스 개발자는 메인 메모리에서 CPU 캐시로 가는 대역폭을 효율적으로 사용하고 CPU 명령 처리 파이프라인에서 분기 예측 실패(branch misprediction)와 버블(bubble) 을 피하며 최시 CPU에서 다닝ㄹ 명령 다중 데이터(single-instruction-multi-data, SIMD) 명령을 사용하게끔 신경 써야 한다.
- 디스크로부터 적재할 데이터 양 줄이기 외에도 칼럼 저장소 배치는 CPU 주기를 효율적으로 사용하기에 적합하다. 예를 들어 질의 엔진은 압축된 칼럼 데이터를 CPU의 L1 캐시에 딱 맞게 덩어리로 나누어 가져오고 이 작업을 (함수 호출이 없는) 타이트 루프(tight loop) 에서 반복한다. CPU는 함수 호출이 많이 필요한 코드나 각 레코드 처리를 위해 분기가 필요한 코드보다 타이트 루프를 훨씬 빨리 실행할 수 있다. 칼럼 압축을 사용하면 같은 양의 L1 캐시에 칼럼의 더 많은 로우를 저장할 수 있다. 앞에서 설명한 비트 AND와 OR 같은 연산자는 압축된 칼럼 데이터 덩어리를 바로 연산할 수 있게 설계할 수 있다. 이런 기법을 벡터화 처리(vectorized processing) 라고 한다.

### 칼럼 저장소의 순서 정렬
...

### 다양한 순서 정렬
...

### 칼럼 지향 저장소에 쓰기
...

### 집계: 데이터 큐브와 구체화 뷰
...


</details>

## 04장. 부호화와 발전

<details>
<summary>fold/unfold</summary>

### 데이터 부호화 형식
- 프로그램은 보통(최소화) 두 가지 형태로 데이터를 사용해 동작한다.
- 메모리에 객체(object), 구조체(struct), 목록(list), 배열(array), 해시 테이블(hash table), 트리(tree) 등으로 데이터가 유지된다. 이런 데이터 구조는 CPU에서 효율적으로 접근하고 조작할 수 있게 (보통은 포인터를 이용해) 최적화된다.
- 데이터를 파일에 쓰거나 네트워크를 통해 전송하려면 스스로를 포함한 일련의 바이트열 (예를 들어 JSON 문서) 의 형태로 부호화해야 한다. 포인터는 다른 프로세스가 이해할 수 없으므로 이 일련의 바이트열은 보통 메모리에서 사용하는 데이터 구조와는 상당히 다르다.
- 따라서 두 가지 표현 사이에 일종의 전환이 필요하다. 인메모리 표현에서 바이트열로의 전환을 부호화(직렬화나 마샬링이라고도 함)라고 하며, 그 반대를 복호화(파싱, 역직렬화, 언마샬링이라고도 함)라고 한다.
  - 직렬화는 유감스럽게도 트랜잭션의 맥락에서도 사용되는데 완전히 다른 의미다. 직렬화가 조금 더 일반적인 용어일지라도 단어의 중복 사용을 피하기 위해 이 책에서는 부호화를 사용한다.

#### 언어별 형식
- 많은 프로그래밍 언어는 인메모리 객체를 바이트열로 부호화하는 기능을 내장한다. 예를 들어 자바는 java.io.Serializable, 루비는 Marshal, 파이썬은 pickle 등이 있다. 자바 전용인 크리오(Kryo) 같은 서드파티 라이브러리도 많다.
- 프로그래밍 언어에 내장된 부호화 라이브러리는 최소한의 추가 코드로 인메모리 객체를 저장하고 복원할 수 있기 때문에 매우 편리하지만 심각한 문제점 또한 많다.
  - 부호화는 보통 특정 프로그래밍 언어와 묶여 있어 다른 언어에서 데이터를 읽기는 매우 어렵다. 이런 부호화로 데이터를 저장하고 전송하는 경우 매우 오랜 시간이 될지도 모를 기간 동안 현재 프로그래밍 언어로만 코드를 작성해야 할 뿐 아니라 다른 시스템(다른 언어로 사용할 수도 있음) 과 통합하는 데 방해가 된다.
  - 동일한 객체 유형의 데이터를 복원하려면 복호화 과정이 임의의 클래스를 인스턴스화할 수 있어야 한다. 이것은 종종 보안 문제의 원인이 된다. 공격자가 임의의 복호화할 수 있는 애플리케이션을 얻을 수 있으면 공격자가 원격으로 임의 코드를 실행하는 것과 같은 끔찍한 일이 발생할 수 있다.
  - 데이터 버전 관리는 보통 부호화 라이브러리에서는 나중에 생각하게 된다. 데이터를 빠르고 쉽게 부호화하기 위해 상위, 하위 호환성의 불편한 문제가 등한시되곤 한다.
  - 효율성(부호화나 복호화에 소요되는 CPU 시간과 부호화된 구조체의 크기) 도 종종 나중에 생각하게 된다. 예를 들어 자바의 내장 직렬화는 성능이 좋지 않고 비대해지는 부호화로 유명하다.
이런 이유로 매우 일시적인 목적 외에 언어에 내장된 부호화를 사용하는 방식은 일반적으로 좋지 않다.

### JSON과 XML, 이진 변형
- 많은 프로그래밍 언어에서 읽고 쓸 수 있는 표준화된 부호화로서 JSON과 XML은 확실한 경쟁자다. JSON과 XML은 널리 알려지고 많은 곳에서 지원하지만 그만큼 싫어하기도 한다. XML은 종종 너무 장황하고 불필요하게 복잡하다고 비판받는다. JSON 의 인기는 주로 웹 브라우저에 내장된 지원 (자바스크립트의 일부이기 때문에)과 XML 대비 단순하기 때문이다. 강력하진 않지만 CSV 도 인기 있는, 언어 독립적 형식이다.
- JSON, XML, CSV 는 텍스트 형식이라서 (비록 이 문법은 인기 있는 토론 주제지만) 어느 정도 사람이 읽을 수 있다. 피상적인 문법적 문제 외에도 일부 미묘한 문제가 있다.
  - 수(number)의 부호화에는 많은 애매함이 있다. XML 과 CSV에서는 수와 숫자(digit)로 구성된 문자열을 구분할 수 없다. (외부 스키마 참조는 제외), JSON은 문자열과 수를 구분하지만 정수와 부동소수점 수를 구별하지 않고 정밀도를 지정하지 않는다.
  - 이 애매함은 큰 수를 다룰 때 문제가 된다. 예를 들어 2^53 보다 큰 정소는 IEEE 754 배정도 부동소수점 수에서는 정확하게 표현할 수 없으므로 이런 수는 부동소수점 수를 사용하는(자바스크립트 같은) 언어에서는 파싱할 때 부정확해질 수 있다. 2^53 보다 큰 숫자의 예는 각 트윗의 식별을 위해 64 비트 숫자를 사용한느 트위터에서 볼 수 있다. 트위터의 API에서 반환된 JSON은 JSON 수로 한번, 10진 문자열로 한번, 이렇게 트윗 ID 가 두 번 포함되는데 자바스크립트 애플리케이션에서 정확하게 숫자를 파싱하지 않는 문제를 해결한다.
  - JSON과 XML은 유니코드 문자열(즉, 사람이 읽을 수 있는 텍스트)을 잘 지원한다. 그러나 이진 문자열(문자 부호화가 없는 바이트열) 을 지원하지 않는다. 이진 문자열은 매우 유용한 기능이기 때문에 사람들은 이진 데이터를 Base64를 사용해 텍스트로 부호화해 이런 제한을 피한다. 그런 다음 값이 Base64로 부호화됐기 때문에 해석해야 한다는 사실을 스키마를 사용해 표시한다. 이 방법은 실제로 사용되는 방법이지만 정공법과는 거리가 있다. 또한 데이터 크기가 33%가 증가한다.
  - 필수는 아니지만 XML과 JSON 모두 스키마를 지원한다. XML과 JSON을 정의하는 스키마 언어는 상당히 강력하지만 익히고 구현하기가 상당히 난해하다. XML 스키마는 꽤 널리 사용하지만 많은 JSON 기반 도구는 스키마 사용을 강제하지 않는다. (수와 이진 문자열 같은) 데이터의 올바른 해석은 스키마의 정보에 따라 다르기 때문에 XML/JSON 스키마를 사용하지 않는 애플리케이션은 필요한 부호화/복호화 로직을 하드코딩해야 할 가능성이 있다.
  - CSV는 스키마가 없으므로 각 로우의 칼럼의 의미를 정의하는 작업은 애플리케이션이 해야 한다. 애플리케이션이 새로운 로우나 칼럼 추가를 변경하려면 수동으로 변경을 처리해야 한다. 또한 CSV는 매우 모호한 형식이다.(값이 쉼표나 개행 문자를 포함하면 어떻게 될까?). 이스케이핑 규칙을 공식적으로 규정했지만, 모든 파서가 규칙을 정확하게 구현하지는 않는다.

  이런 결점에도 JSON, XML, CSV는 다양한 용도에 사용하기에 충분하다. 이 부호화 형식들은 앞으로도 인기를 유지할 것이다. 특히 데이터 교환 형식(즉, 한 조직에서 다른 조직으로 데이터를 전송) 으로 사용하기가 매우 좋다. 이런 상황에서 사람들이 동의만 한다면 얼마나 읽기 쉽고 효율적인 형식인지는 대개 중요하지 않다. 무엇이든 다른 조직의 동의를 얻는 어려움은 대부분의 다른 문제보다 더 크다.


### 이진 부호화
- JSON 은 XML 보다 덜 장황하지만 이진 형식과 비교하면 둘 다 훨씬 많은 공간을 사용한다. 이런 관찰이 JSON(메세지팩(MessagePack), BSON, BJSON, UBJSON, BISON, 스마일(Smile))과 XML(WBXML, 패스트 인포셋(Fast Infoset)) 용으로 사용 가능한 다양한 이진 부호화의 개발로 이어졌다. 이런 형식은 다양한 틈새 시장에서 채택됐지만 JSON과 XML의 텍스트 버전처럼 널리 채택 되지 않았다.

### 스리프트와 프로토콜 버퍼
...

### 필드 태그와 스키마 발전
...

### 데이터타입과 스키마 발전
...

### 아브로
...

### 스키마의 장점
- 프로토콜 버퍼와 스리프트, 아브로는 스키마를 사용해 이진 부호화 형식을 기술한다. 이 스키마 언어는 XML 스키마나 JSON 스키마보다 훨씬 간단하며 더 자세한 유효성 검사 규칙을 지원한다. (예를 들어 "이 필드의 문자열 값은 이 정규 표현식에 일치해야 한다"거나 이 필드의 정수 값은 0 과 100 사이여야 한다."). 프로토콜 버퍼, 스리프트, 아브론느 구현과 사용이 더 간단하므로 상당히 광범위한 프로그래밍 언어를 지원하는 방향으로 성장 중이다.
- JSON, XML, CSV 같은 텍스트 데이터 타입이 널리 사용되지만 스키말르 기반으로 한 이진 부호화 또한 가능한 선택임을 알 수 있다. 이진 부호화에는 좋은 속성이 많이 있다.
  - 부호화된 데이터에서 필드 이름을 생략할 수 있기 때문에 다양한 "이진 JSON" 변형보다 크기가 훨씬 작을 수 있다.
  - 스키마는 유용한 문서화 형식이다. 복호화를 할 때 스키마가 필요하기 때문에 스키마가 최신 상태인지를 확신할 수 있다(반면 수동으로 관리하는 문서는 실제와 달라지기 쉽다)
  - 스키마 데이터베이스를 유지하면 스키마 변경이 적용되기 전에 상위 호환성과 하위 호환성을 확인할 수 있다.
  - 정적 타입 프로그래밍 언어 사용자에게 스키마로부터 코드를 생성하는 기능은 유용하다. 컴파일 시점에 타입 체크를 할 수 있기 때문이다.
- 요약하면 스키마 발전은 스키마리스(schemaless)또는 읽기 스키마 (schema-on-read) JSON 데이터베이스가 제공하는 것과 동일한 종류의 유연성을 제공하머 데어터나 도구 지원도 더 잘 보장한다.

### 데이터플로 모드
- 

</details>


## 05장. 복제

<details>
<summary>fold/unfold</summary>

- 복제란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지한다는 의미다. 데이터 복제가 필요한 여러 이유가 있다.
  - 지리적으로 사용자와 가깝게 데이터를 유지해 지연 시간을 줄인다.
  - 시스템의 일부에 장애가 발생해도 지속적으로 동작할 수 있게 해 가용성을 높인다.
  - 읽기 질의를 제공하는 장비의 수를 확장해 읽기 처리량을 늘린다.

### 리더와 팔로워
- 데이터베이스의 복사본을 저장하는 각 노드를 복제 서버(replica)라고 한다.
  - 모든 복제 서버에 모든 데이터가 있다는 사실을 어떻게 보장할 수 있을까?

- 데이터 베이스의 모든 쓰기는 복제 서버에서 처리되어야 한다. 그렇지 않으면 복제 서버는 더 이상 동일한 데이터를 유지할 수 없다. 이 문제를 위한 가장 일반적인 해결책은 리더 기반 복제(leader-based replication)(또는 능동(active)/수동(passive), 마스터(master) 슬레이브(slave) 복제라고도 함)이다.
- 복제 서버 중 하나를 리더(leader)(마스터나 프라이머리(primary)라고도 함)로 지정한다. 클라이어언트가 데이터베이스에 쓰기를 할 때 클라이언트는 요청을 리더에게 보내야 한다. 리더는 먼저 로컬 저장소에 새로운 데이터를 기록한다. 다른 복제 서버는 팔로워(follower)(읽기 복제 서버(read replica), 슬레이브 2차(secondary), 핫 대기(hot standby)) 라고 한다. 리더가 로컬 저장소에 새로운 데이터를 기록할 때마다 변경을 복제로그(replication log)나 변경 스트림(change stream)의 일부를 팔로워에게 전송한다. 각 팔로워가 리더로부터 로그를 받으면 리더가 처리한 것과 동일한 순서로 모든 쓰기를 적용해 그에 맞게 데이터베이스의 로컬 복사본에 갱신한다.
  - 클라이언트가 데이터베이스로부터 읽기를 할 때는 리더 또는 임의 팔로워에게 질의할 수 있다. 하지만 쓰기는 리더에게만 허용된다. (팔로워는 클라이언트 관점에서는 읽기 전용이다)


<img src="https://1.bp.blogspot.com/-9zSd0FnakOk/XxSJTbHCzgI/AAAAAAAAARw/Bf3bhrD5SAoao5EiFjGmyeoXUCiYUHIeQCLcBGAsYHQ/w625-h244/Screen%2BShot%2B2020-07-19%2Bat%2B10.37.16%2BAM.png" width="40%" height="40%">

### 동기식 대 비동기식 복제
- 아래 그림은 클라이언트, 리더, 두 팔로워 간 통신을 보여준다.
  - 팔로워 1의 복제는 동기식이다. 리더는 팔로워 1이 쓰기를 수신했는지 확인해 줄 때까지 기다린다. 확인이 끝나면 사용자에게 성공을 보고하고 다른 클라이언트에게 해당 쓰기를 보여준다.
  - 팔로워 2의 복제는 비동기식이다. 리더는 메시지를 전송하지만 팔로워의 응답을 기다리지 않는다.

<img src="https://1.bp.blogspot.com/-Kw9L2tDH83Y/XxSNmxI3OBI/AAAAAAAAASI/Szyj8Azs9xQBRiTZo5aBykXgwcv1yRV4QCLcBGAsYHQ/w625-h313/Screen%2BShot%2B2020-07-19%2Bat%2B11.14.38%2BAM.png" width="40%" height="40%">

- 동기식 복제의 장점은 팔로워가 리더와 일관성 있게 최신 데이터 복사본을 가지는 것을 보장한다. 갑자기 리더가 작동하지 않아도 데이터는 팔로워에서 계속 사용할 수 있음을 확신할 수 있다. 
- 단점은 (팔로워가 죽거나 네트워크 문제나 다른 어떤 이유로 인해) 동기 팔로워가 응답하지 않는다면 쓰기가 처리될 수 없다는 것이다. 리더는 모든 쓰기를 차단(block)하고 동기 복제 서버가 다시 사용할 수 있을 때까지 기다려야 한다.


- 이런 이유로 모든 팔로워가 동기식인 상황은 비현실적이다. 임의 한 노드의 장애는 전체 시스템을 멈추게 한다. 보통 팔로워 하나는 동기식으로 하고 그 밖에는 비동기식으로 하는 것을 의미한다. 동기식 팔로워가 사용할 수 없게 되거나 느려지면 비동기식 팔로워 중 하나가 동기식이 된다. 이것은 적어도 두 노드(리더와 하나의 동기 팔로워)에 데이터의 최식 복사본이 있다는 것을 보장한다. 이런 설정을 반동기식(semi-synchronous)라고 한다.
- 보통 리더 기반 복제는 완전히 비동기식으로 구성한다. 이런 경우 리더가 잘못되고 복구할 수 없으면 팔로워에 아직 복제되지 않은 모든 쓰기는 유실된다. 하지만 완전 비동기식 설정은 모든 팔로워가 잘못되더라도 리더가 쓰기 처리를 계속 할 수 있는 장점이 있다.

### 새로운 팔로워 설정
새로운 팔로워가 리더의 데이터 복제본을 정확히 가지고 있는지 어떻게 보장할까?
- 가능하다면 전체 데이터베이스를 잠그지 않고 리더의 데이터베이스 스냅숏을 일정 시점에 가져온다. 대부분의 데이터베이스는 백업이 필요하기 때문에 이 기능을 갖췄다.
- 스냅숏을 새로운 팔로워 노드에 복사한다.
- 팔로워는 리더에 연결해 스냅숏 이후 발생한 모든 데이터 변경을 요청한다. 이것은 스냅숏이 리더의 복제 로그의 정확한 위치와 연관돼야 한다.
- 팔로워가 스냅숏 이후 데이터 변경의 미처리분(backlog)을 모두 처리했을 때 따라잡았다고 말한다. 이제부터 리더에 발생하는 데이터 변화를 이어 처리할 수 있다.

### 노드 중단 처리
시스템의 모든 노든느 장애로 인해 예기치 않게 중단될 수 있지만 계획된 유지보수(예를 들어 커널의 보안 패치 설치를 위한 장비 리부팅)로 인해 중단될 수 있다. 중단시간 없이 개별 노드를 재부팅할 수 있다는 점은 운영과 유지보수의 큰 장점이다.
- 리더 기반 복제에서 고가용성은 어떻게 달성할 수 있을까?

#### 팔로워 장애 : 따라잡기 복구
- 각 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관한다. 팔로워가 죽어 재시작하거나 리더와 팔로워 사이의 네트워크가 일시적으로 중단된다면 팔로워는 매우 쉽게 복구할 수 있다. 먼저 보관된 로그에서 결함이 발생하기 전에 처리한 마지막 트랜잭션을 알아낸다. 그러면 팔로워는 리더에 연결해 팔로워 연결이 끊어진 동안 발생한 데이터 변경을 모두 요청할 수 있다. 이 변경이 다 적용되면 리더를 다 따라잡게 되고 이전과 같이 데이터 변경의 스트림을 계속 받을 수 있다.

#### 리더 장애 : 장애 복구
- 팔로워 하나를 새로운 리더로 승격해야 하고 클라이언트는 새로운 리더로부터 데이터 변경을 소비하기 시작해야 한다. 이 과정을 장애 복구(fail over)라고 한다.
- 장애 복구는 수동 혹은 자동으로 진행될 수 있다. 자동 복구는 아래의 단계로 구성된다.
  1. 리더가 장애인지 판단한다. 대부분의 시스템은 단순히 타임아웃을 사용한다. 노드들은 자주 서로 메시지를 주고 받으며 일정 시간 동안 노드가 응답하지 않으면 죽은 것으로 간주한다.
  2. 새로운 리더를 선택한다. 
  3. 새로운 리더 사용을 위해 시스템을 재설정한다.

- 장애 복구 과정은 잘못될 수 있는 것 투성이다.
  - 비동기식 복제의 경우, 새로운 리더는 이전 리더가 실패하기 이전의 쓰기 내용을 수신하지 못할 수 있다.
  - 쓰기를 폐지하는 방법은 데이터베이스 외부의 다른 저장소 시스템이 데이터베이스 내용에 맞춰 조정돼야 한다면 특히 위험하다.
  - 특정 결함 시나리오에서 두 노드가 모두 자신이 리더라고 믿을 수 있다. (스플릿 브레인(split brain))


### 복제 로그 구현
#### 구문 기반 복제
- 리더는 모든 쓰기 요청(구문(statement))을 기록하고 쓰기를 실행한 다음 구문 로그를 팔로워에게 전송한다. 관계형 데이터베이스는 모든 INSERT, UPDATE, DELETE 구문을 팔로워에게 전달하고 각 팔로워는 클라이언트에서 직접 받은 것처럼 SQL 구문을 파싱하고 실행한다.
- 이 접근법은 합리적인 것 같지만 복제가 깨질 수 있는 다양한 사례가 있다.

#### 쓰기 전 로그 배송
- 일반적으로 모든 쓰기는 로그에 기록한다는 사실을 확인했다.
  - 로그 구조화 저장소 엔진의 경우 로그 자체가 저장소의 주요 부분이다. 로그 세그먼트는 작게 유지되고 백그라운드로 가비지 컬렉션을 한다.
  - 개별 디스크 블록에 덮어쓰는 B 트리의 경우 모든 변경은 쓰기 전 로그(Write-ahead log. WAL)에 쓰기 때문에 고장 이후 일관성 있는 상태로 색인을 복원할 수 있다.

- 두 경우 모두 로그는 데이터베이스의 모든 쓰기를 포함하는 추가 전용(append-only) 바이트 열이다. 완전히 동일한 로그를 사용해 다른 노드에서 복제 서버를 구축할 수 있다. 리더는 디스크에 로그를 기록하는 일 외에도 팔로워에게 네트워크로 로그를 전송하기도 한다.


#### 논리적 (로우 기반) 로그 복제
- 복제 로그를 저장소 엔진 내부와 분리하기 위한 대안 하나는 복제와 저장소 엔진을 위해 다른 로그 형식을 사용하는 것이다. 이 같은 종류의 복제 로그를 저장소 엔진의 (물리적) 데이터 표현과 구별하기 위해 논리적 로그(logical log) 라고 부른다.
- 논리적 로그를 저장소 엔진 내부와 분리했기 때문에 하위 호환성을 더 쉽게 유지할 수 있고 리더와 팔로워에서 다른 버전의 데이터베이스 소프트웨어나 심지어 다른 저장소 엔진을 실행할 수 있다.
- 또한 논리적 로그 형식은 외부 애플리케이션이 파싱하기 더 쉽다. 이런 측면은 오프라인 분석이나 사용자 정의 색인과 캐시 구축을 위해 데이터 웨어하우스 같은 외부 시스템에 데이터베이스의 내용을 전송하고자 할 때 유용하다. 이 기술을 변경 데이터 캡쳐(change data capture)라 부른다.

#### 트리거 기반 복제
...

### 복제 지연 문제
노드 내결함성을 갖추려는 단 한 가지 이유는 복제가 필요하기 때문이다. 확장성(단일 장비에서 감당하지 못하는 요청을 처리)과 지연 시간(사용자에게 지리적으로 더 가까운 복제 서버를 위치시킴)이 또 다른 이유다.
- 읽기 확장(read-scaling) 아키텍처에서는 간단히 팔로워를 더 추가함으로써 읽기 전용 요청을 처리하기 위한 용량을 늘릴 수 있다.(쓰기는 많지 않고 팔로워에서 읽는 동작이 많으므로) 하지만 이 접근 방식은 실제로는 비동기식 복제에서만 동작한다. 동기식으로 모든 팔로워에 복제를 시도한다면 단일노드 장애나 네트워크 중단으로 전체 시스템의 쓰기가 불가능해진다. 그리고 노드가 많아지면 다운될 가능성이 커져 완전한 동기식 설정은 매우 불안정하다.
- 애플리케이션이 비동기 팔로워에서 데이터를 읽을 때 팔로워가 뒤쳐진다면 지난 정보를 볼 수 있다. 이와 동시에 리더와 팔로워에 동일한 질의를 수행한다면 모든 쓰기가 팔로워에 반영되지 않았기 때문에 서로 다른 결과를 얻을 수 있다. 하지만 이런 불일치는 일시적인 상태에 불과하다. 데이터베이스에 쓰기를 멈추고 잠시 동안 기다리면 팔로워는 결국 따라잡게 되고 리더와 일치하게 된다. 이런 효과를 최종적 일관성이라 한다.

### 자신이 쓴 내용 읽기
- 사용자가 자신이 새로 작성한 내용을 바로 확인하는 순간이 있다. 새로운 데이터가 제출되면 리더에게 전송해야 하지만 사용자가 데이터를 볼 때는 팔로워에서 읽을 수 있다. 비동기식 복제에서는 이런 경우, 사용자가 쓰기를 수행한 직후 데이터를 본다면 새로운 데이터는 아직 복제 서버에 반영되지 않았을 수 있다. 
- 이런 상황에서는 쓰기 후 읽기 일관성(자신의 쓰기 일관성으로도 알려져 있음)이 필요하다. 이것은 사용자가 페이지를 재로딩했을 때 항상 자신이 제출한 모든 갱신을 볼 수 있음을 보장하며 다른 사용자에 대해서는 보장하지 않는다.


- 리더 기반 복제 시스템에서 쓰기 후 읽기 일관성을 구현할까?
  - 사용자가 수정한 내용을 읽을 때는 리더에서 읽는다. 그 밖에는 팔로워에서 읽는다. 이를 위해서는 실제로 질의하지 않고 무엇이 수정됐는지 알 수 있는 방법이 필요하다. (프로필의 경우, 자신의 프로필만 편집 가능하므로 소유자의 프로필은 리더에서, 다른 사용자의 프로필은 팔로워에서 읽는 등의 규칙)
  - 애플리케이션 내 대부분의 내용을 사용자가 편집할 가능성이 있다면 이 접근 방식은 대부분 리더에서 읽기 때문에 효율적이지 않다.(읽기 확장의 이점을 무효화) 이런 경우에는 리더에서 읽을지 말지를 결정하기 위해 다른 기준을 사용해야 하는데 예를 들어 마지막 갱신 시간을 찾아서 마지막 갱신 후 1분 동안은 리더에서 모든 읽기를 수행한다. 또한 팔로워에서 복제 지연을 모니터링해 리더보다 1분 이상 늦은 모든 팔로워에 대한 질의를 금지할 수 있다.
  - 클라이언트는 가장 최근 쓰기의 타임스탬프를 기억할 수 있다. 그러면 시스템은 사용자 읽기를 위한 복제 서버가 최소한 해당 타임스탬프까지 갱신을 반영하게 할 수 있다. 복제 서버가 아직 최신 내용이 아닌 경우에는 다른 복제 서버가 읽기를 처리하거나 복제 서버가 따라잡을 때까지 질의를 대기시킬 수 있다.
  - 복제 서버가 여러 데이터센터에 분산(사용자에게 지리적인 근접성이나 가용성을 위해)됐다면 복잡도가 증가한다. 리더가 제공해야 하는 모든 요청은 리더가 포함된 데이터센터로 라우팅돼야 한다.


동일한 사용자가 여러 디바이스로 서비스를 접근할 때 또 다른 문제가 발생할 수 있다. 디바이스 간(cross-device) 쓰기 후 읽기 일관성이 제공 돼야 한다.


### 단조 읽기
비동기식 팔로워에서 읽을 때 발생할 수 있는 두 번째 이상 현상은 사용자가 시간이 거꾸로 흐르는 현상을 목격할 수 있다는 것이다. 이 사례는 사용자가 각기 다른 복제 서버에서 여러 읽기를 수행할 때 발생할 수 있다.
- 사용자가 최신 복제 서버에서 데이터를 먼저 읽고, 그 후 예전 복제 서버에서 데이터를 먼저 읽는다. 쓰기의 내용이 아직 예전 복제 서버에 반영되지 않았다면 시간 역전 현상이 발생한다.


단조 읽기(monotonic read)은 이런 종류의 이상 현상이 발생하지 않음을 보장한다. 단조 읽기는 강한 일관성보다는 덜한 보장이지만 최종적 일관성보다는 더 강한 보장이다.
- 단조 읽기를 달성하는 한 방법은 각 사용자의 읽기가 항상 동일한 복제 서버에서 수행되게끔 하는 것이다. 예를 들어 임의 선택보다는 사용자 ID의 해시를 기반으로 복제 서버를 선택한다.

#### 일관된 순서로 읽기
- 일관된 순서로 읽기(Consistent Prefix Read) 같은 또 다른 유형의 보장이 필요하다. 일관된 순서로 읽기는 일련의 쓰기가 특정 순서로 발생한다면 이 쓰기를 읽는 모든 사용자는 같은 순서로 쓰여진 내용을 보게 됨을 보장한다.

#### 복제 지연을 위한 해결책
- "올바른 작업 수행"을 위해 항상 데이터베이스를 신뢰할 수 있다면 훨씬 좋다. 이것이 트랜잭션이 있는 이유다. 트랜잭션은 애플리케이션이 더 단순해지기 위해 데이터베이스가 더 강력한 보장을 제공하는 방법이다.

### 다중 리더 복제
- 리더 기반 복제에는 주요한 단점 하나가 있다. 리더가 하나만 존재하고 모든 쓰기는 해당 리더를 거쳐야 한다. 어떤 이유로 리더에 연결할 수 없다면 (예를 들어 클라이언트와 리더 간 네트워크 중단) 데이터베이스에 쓰기를 할 수 없다.

### 쓰기 충돌 다루기
...

### 리더 없는 복제
일부 데이터 저장소 시스템은 리더의 개념을 버리고 모든 복제 서버가 클라이언트로부터 쓰기를 직접 받을 수 있게 허용하는 접근 방식을 사용하기도 한다.

#### 노드가 다운됐을 때 데이터베이스에 쓰기
- 리더 없는 설정에서는 장애 복구가 필요하지 않다. 클라이언트가 쓰기를 세 개의 모든 복제 서버에 병렬로 전송한다. 사용 불가능한 복제 서버가 쓰기 신호를 받지 못했다 하더라도 아래 예시처럼 세 개의 복제 서버 중 두 곳으로부터 ok 응답을 받는다면 쓰기가 성공한 것으로 간주한다. 클라이언트는 복제 서버 중 하나가 쓰기를 놓친 사실을 단순히 무시한다.
- 다시 클라이언트가 데이터베이스에서 읽을 때 하나의 복제 서버로 보내지 않고 읽기 요청을 병렬로 여러 노드에 전송한다. 그러면 클라이언트는 여러 노드에서 다른 응답을 받을 수 있다. 즉 한 노드에서는 최신 값을 받고 다른 노드에서는 오래된 값을 받는다. 이때는 버전 숫자를 사용해 어떤 값이 최신 내용인지 결정한다.
<img src="https://1.bp.blogspot.com/-dEpAswYxjYc/XxSXK-hO-PI/AAAAAAAAAT8/eGiMldpGjrs4KSTv0pBAqyfQXlYMkh6GwCLcBGAsYHQ/w625-h375/Screen%2BShot%2B2020-07-19%2Bat%2B11.55.29%2BAM.png" width="40%" height="40%">



</details>


## 06장. 파티셔닝

<details>
<summary>fold/unfold</summary>

- 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하고 데이터를 파티션으로 쪼갤 필요가 있다. 이 작업을 샤딩이라고 한다.
  - 여기서 말하는 파티션은 몽고 DB, 엘라스틱 서치, 솔라클라우드의 샤드(shard)에 해당된다. HBase에서는 리전(region), 빅테이블에서는 태블릿(tablet), 카산드라와 리악에서는 브이노드(vnode), 카우치베이스에서는 브이버켓(vBucket)이라고 부른다. 그러나 파티셔닝이 가장 널리 쓰이는 용어이므로 이 책에서는 계속 파티션을 사용한다.

- 파티션을 나눌 때는 보통 각 데이터 단위(레코드, 로우, 문서)가 하나의 파티션에 속하게 한다. 데이터베이스가 여러 파티션을 동시에 건드리는 연산을 지원할 수도 있지만 결과적으로 각 파티션은 그 자체로 작은 데이터베이스가 된다.
- 데이터 파티셔닝을 원하는 주된 이유는 확장성이다. 비공유 클러스터(shared-nothing cluster)에서 다른 파티션은 다른 노드에 저장될 수 있다. 따라서 대용량 데이터셋이 여러 디스크에 분산될 수 있고 질의 부하는 여러 프로세서에 분산될 수 있다.
  - 단일 파티션에 실행되는 질의를 생각해보면 각 노드에서 자신의 파티션에 해당하는 질의를 독립적으로 실행할 수 있으므로 노드를 추가함으로써 질의량을 늘릴 수 있다. 크고 복잡한 질의는 훨씬 더 어렵기는 하지만 여러 노드에서 병렬 실행이 가능하다.

#### 파티셔닝과 복제
- 보통 복제와 파티셔닝을 함께 적용해 각 파티션의 복사본을 여러 노드에 저장한다. 각 레코드는 정확히 한 파티션에 속하더라도 이를 여러 다른 노드에 저장해서 내결함성을 보장할 수 있다는 의미다. 모든 부하가 한 파티션에 몰려 10개 중 9개는 유휴 상태에 있고 요청을 받는 노드 하나가 병목이 될 수 있다. 불균형하게 부하가 높은 파티션을 핫스팟이라고 한다.

#### 키-값 데이터 파티셔닝
- 파티셔닝의 목적은 데이터와 질의 부하를 노드 사이에 고르게 분산시키는 것이다. 모든 노드가 동일한 분량을 담당한다고 가정할 때 10대의 노드를 사용하면 한 대를 사용할 때보다 이론상으로 10배의 데이터를 저장하고 10배의 읽기, 쓰기 요청을 처리할 수 있다.
- 파티셔닝이 고르게 이뤄지지 않아 다른 파티션보다 데이터가 많거나 질의를 많이 받는 파티션이 있다면 쏠렸다(Skewed) 고 말한다. 쏠림이 있으면 파티셔닝의 효과가 매우 떨어진다. 

#### 키 범위 기준 파티셔닝
- 파티셔닝하는 방법 중 하나는 백과사전처럼 각 파티션에 연속된 범위(어떤 최솟값에서 최댓값까지)의 키를 할당하는 것이다. 각 범위들 사이의 경계를 알면 어떤 키가 어느 파티션에 속하는지 쉽게 찾을 수 있다.
- 각 파티션 내에서는 키를 정렬된 순서로 저장할 수 있다. 이렇게 하면 범위 스캔이 쉬워지는 이점이 있고, 키를 연쇄된 색인으로 간주해서 질의 하나로 관련 레코드 여러 개를 읽어오는 데 사용할 수 있다.
- 그러나 키 범위 기준 파티셔닝은 특정한 접근 패턴이 핫스팟을 유발하는 단점이 있다. (시간에 따라 데이터를 기록하는 경우, 연속적인 시간의 데이터를 쓰기한다면 해당 파티션만 과부하가 걸린다)

#### 키의 해시값 기준 파티셔닝
- 쏠림과 핫스팟의 위험 때문에 많은 분산 데이터스토어는 거의 파티션을 정하는 데 해시 함수를 사용한다.

<br>

- 일관성 해싱
  - 일관성 해싱은 카저(karger)가 정의한 대로 CDN(content delivery network) 같은 인터넷 규모의 캐시 시스템에서 부하를 균등하게 분산시키는 방법이다. 중앙 제어나 분산 합의(distributed consensus)가 필요하지 않도록 파티션 경계를 무작위로 선택한다. 여기서 말하는 일관성은 복제 일관성이나 ACID 일관성과는 관련이 없으며 특별한 재균형화 방법을 의미한다. 
  - 이 특별한 방법은 데이터베이스에서 실제로는 잘 동작하지 않아서 거의 사용되지 않는다. 매우 혼동하기 쉬우므로 일관성 해싱이라는 단어 대신 그냥 해시 파티셔닝을 쓰는 게 좋다.


#### 쏠린 작업부하와 핫스팟 완화
- 키를 해싱해서 파티션을 정하면 핫스팟을 줄이는 데 도움이 된다. 그렇지만 핫스팟을 완벽히 제거할 수는 없다. 항상 동일한 키를 읽고 쓰는 극단적 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.
- 현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정하지 못하므로 애플리케이션에서 쏠림을 완화해야 한다. 예를 들어 요청이 매우 많이 쏠리는 키를 발견했을 때 간단한 해결책은 각 키의 시작이나 끝에 임의의 숫자를 붙이는 것이다. 한 키에 대한 쓰기 작업이 100개의 다른 키로 균등하게 분산되고, 그 키들은 다른 파티션으로 분산될 수 있다.

### 파티셔닝과 보조 색인
- 보조 색인이 연관되면 상황은 복잡해진다. 보조 색인은 보통 레코드를 유일하게 식별하는 용도가 아니라 특정한 값이 발생한 항목을 검색하는 수단이다.
- 보조 색인은 관계형 데이터베이스의 핵심 요소이며 문서 데이터베이스에서도 흔하다. 많은 키-값 저장소에서는 구현 복잡도가 추가되는 것을 피하려고 보조 색인을 지원하지 않지만 보조 색인은 데이터 모델링에 매우 유용하므로 일부 저장소에서는 이를 추가하기 시작했다.

#### 문서 기준 보조 색인 파티셔닝
- 각 파티션이 완전히 독립적으로 동작한다. 각 파티션은 자신의 보조 색인을 유지하며 그 파티션에 속하는 문서만 담당한다.

#### 용어 기준 보조 색인 파티셔닝
- 각 파티션이 자신만의 보조 색인(지역 색인)을 갖게 하는 대신, 모든 파티션의 데이터를 담당하는 전역 색인을 만들 수도 있다. 찾고자 하는 용어에 따라 색인의 파티션이 결정되므로 이런 식의 색인을 용어 기준으로 파티셔닝됐다(term-partitioned)고 한다.

### 파티션 재균형화
시간이 지나면 데이터베이스에 변화가 생긴다.
- 질의 처리량이 증가해서 늘어난 부하를 처리하기 위해 CPU를 더 추가하고 싶다.
- 데이터셋 크기가 증가해서 데이터셋 저장에 사용할 디스크와 램을 추가하고 싶다.
- 장비에 장애가 발생해서 그 장비가 담당하던 역할을 다른 장비가 넘겨받아야 한다.

이런 변화가 생기면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다. 클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정을 재균형화(rebalancing)라고 한다.
- 어떤 파티셔닝 방식을 쓰는지에 무관하게 재균형화가 실행될 때 보통 만족시킬 것으로 기대되는 최소 요구사항이 있다.
  - 재균형화 후, 부하(데이터 저장소, 읽기 쓰기 요청)가 클러스터 내에 있는 노드들 사이에 균등하게 분배돼야 한다.
  - 재균형화 도중에도 데이터베이스는 읽기 요쳥을 받아들여야 한다.
  - 재균형화가 빨리 실행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에 데이터가 필요 이상으로 옮겨져서는 안 된다.

### 재균형화 전략

#### 쓰면 안 되는 방법 : 해시값에 모드 N 연산을 실행
- 모드(mod) 연산을 사용한다면 각 키를 노드에 할당하는 것은 쉬운 일로 보인다.(노드가 10개일 때, 10 mod 연산을 통해 0 ~ 9 숫자를 배정)
- 모드 N 방식의 문제는 노드 개수 N이 바뀌면 대부분의 키가 노드 사이에 옮겨져야 한다는 점이다. 예를 들어 hash(key) = 123456 이라고 하자. 처음에 노드가 10대라면 이 키는 노드 6에 할당된다. (123456 mod 10 = 6 이므로). 노드가 11대로 늘어나면 이 크는 노드 3으로 옮겨져야 하고, 노드가 12대로 늘어나면 노드 0으로 옮겨져야 한다. 이렇게 키가 자주 이동하면 재균형화 비용이 지나치게 커진다.

#### 파티션 개수 고정
- 파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당하는 방법이 있다. 파티션은 노드 사이에서 통째로 이동하기만 한다. 파티션 개수는 바뀌지 않고 파티션에 할당된 키도 변경되지 않는다. 유일한 변화는 노드에 어떤 파티션이 할당되는가 뿐이다.
- 이 방식을 사용할 때는 보통 데이터베이스가 처음 구축될 때 파티션 개수가 고정되고 이후에 변하지 않는다. 이론적으로는 파티션을 쪼개거나 합치는 게 가능하지만 파티션 개수가 고정되면 운영이 단순해지므로 고정 파티션을 사용하는 데이터베이스는 파티션 분할을 지원하지 않는 경우가 많다.
- 전체 데이터셋의 크기 변동이 심하다면 적절한 파티션 개수를 정하기 어렵다.(예를 들어 처음에는 데이터셋이 작지만 시간이 지나면서 훨씬 더 커질 수도 있다) 각 파티션에는 전체 데이터의 고정된 비율이 포함되므로 개별 파티션 크기는 클러스터의 전체 데이터 크기에 비례해서 증가한다.

#### 동적 파티셔닝
- 키 범위 파티셔닝을 사용하는 데이터베이스에서는 파티션 경계와 개수가 고정돼 있는 게 매우 불편하다. 파티션 경계를 잘못 지정하면 모든 데이터가 한 파티션에 저장되고 나머지 파티션은 텅 빌 수 있다. 파티션 경계를 수동으로 재설정하는 것은 매우 성가시다.
- 이런 이유로 HBase 처럼 키 범위 파티셔닝을 사용하는 데이터베이스에서는 파티션을 동적으로 만든다. 파티션 크기가 설정된 값을 넘어서면 파티션을 두 개로 쪼개 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다. 반대로 데이터가 많이 삭제되어 파티션 크기가 임곗값 아래로 떨어지면 인접한 파티션과 합쳐질 수 있다. (B 트리와 유사)
- 동적 파티셔닝은 파티션 개수가 전체 데이터 용량에 맞춰 조정된다는 이점이 있다. 데이터 양이 작으면 파티션 개수가 적어도 되므로 오버헤드도 적다. 데이터 양이 거대하다면 개별 파티션의 크기는 설정된 최대치로 제한된다.

#### 노드 비례 파티셔닝
- 동적 파티셔닝에서는 파티션 분할과 병합을 통해 개별 파티션 크기가 어떤 고정된 최솟값과 최댓값 사이에 유지되게 하므로 파티션 개수가 데이터셋 크기에 비례한다. 반면 파티션 개수를 고정하면 개별 파티션의 크기가 데이터셋 크기에 비례한다. 두 경우 모두 파티션 개수는 노드 대수와 독립적이다.
- 카산드라와 케타마(Ketama)에서 사용되는 세 번째 방법은 파티션 개수가 노드 대수에 비례하게 하는 것이다. 다시 말해 노드당 할당되는 파티션 개수를 고정한다. 이 경우 노드 대수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례해서 증가하지만 노드 대수를 늘리면 파티션 크기는 다시 작아진다. 일반적으로 데이터 용량이 클수록 데이터를 저장할 노드도 많이 필요하므로 이 방법을 쓰면 개별 파티션 크기도 상당히 안정적으로 유지된다.

#### 운영: 자동 재균형화와 수동 재균형화
...

### 요청 라우팅
- 클라이언트에서 요청을 보내려고 할 때 어느 노드로 접속해야 하는지 어떻게 알 수 있을까? 파티션이 재균형화되면서 노드에 할당되는 파티션이 바뀐다. 이 문제는 데이터베이스에 국한되지 않은 더욱 일반적인 문제인 서비스 찾기(service discovery) 의 일종이다.
  - 클라이언트가 아무 노드에나 접속하게 한다.(예를 들어 라운드로빈 로드 밸런서를 통해). 만약 해당 노드에 마침 요청을 적용할 파티션이 있다면 거기서 요청을 직접 처리할 수 있다. 그렇지 않으면 요청을 올바른 노드로 전달해서 응답을 받고 클라이언트에게 응답을 전달한다
  - 클라이언트의 모든 요청을 라우팅 계층으로 먼저 보낸다. 라우팅 계층에서는 각 요청을 처리할 노드를 알아내고 그에 따라 해당 노드로 요청을 전달한다. 라우팅 계층 자체에서는 아무 요청도 처리하지 않는다. 파티션 인자(partition-aware)로드 밸런서로 동작할 뿐이다.
  - 클라이언트가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지를 알고 있게 한다. 이 경우 클라이언트는 중개자 없이 올바른 노드로 직접 접속할 수 있다.

> 주키퍼, 카산드라 - 가십 프로토콜(gossip protocol)

#### 병렬 질의 실행
...


</details>

## 07장. 트랜잭션

<details>
<summary>fold/unfold</summary>

데이터 시스템은 여러 가지 문제가 생길 수 있다.
- 데이터베이스 소프트웨어나 하드웨어는 (쓰기 연산이 실행 중일 때를 포함해서) 언제라도 실패할 수 있다.
- 애플리케이션은 (연속된 연산이 실행되는 도중도 포함해서) 언제라도 죽을 수 있다.
- 네트워크가 끊기면 애플리케이션과 데이터베이스의 연결이 갑자기 끊기거나 데이터베이스 노드 사이의 통신이 안 될 수 있다.
- 여러 클라이언트가 동시에 데이터베이스에 쓰기를 실행해서 다른 클라이언트가 쓴 내용을 덮어쓸 수 있다.
- 클라이언트가 부분적으로만 갱신돼서 비상적적인 데이터를 읽을 수 있다.
- 클라이언트 사이의 경쟁 조건은 예측하지 못한 버그를 유발할 수 있다.

<br>

수십년 동안 트랜잭션은 이런 문제를 단순화하는 매커니즘으로 채택해 왔다. 트랜잭션은 애플리케이션에서 몇 개의 읽기와 쓰기를 하나의 논리적 단위로 묶는 방법이다. 개념적으로 한 트랜잭션 내의 모든 읽기와 쓰기는 한 연산으로 실행된다. 트랜잭션은 전체가 성공(커밋)하거나 실패(어보트(abort), 롤백)한다. 트랜잭션이 실패하면 애플리케이션에서 안전하게 재시도할 수 있다. 트랜잭션을 쓰면 애플리케이션에서 오류 처리를 하기가 훨씬 단순해진다. 어떤 연산은 성공하고 어떤 연산은 실패하는 경우처럼 부분적인 실패를 걱정할 필요가 없기 때문이다.
- 트랜잭션은 데이터베이스에 접속하는 애플리케이션에서 프로그래밍 모델을 단순화하려는 목적으로 만든 것이다. 트랜잭션을 사용함으로써 애플리케이션에서 어느 정도의 잠재적인 오류 시나리오와 동시성 문제를 무시할 수 있다. 데이터베이스에서 대신 이런 일을 도맡아 주기 때문이다.(이를 안전성 보장(safety guarantee)이라고 한다)

### 애매모호한 트랜잭션의 개념

#### ACID의 개념
- 트랜잭션이 제공하는 안전성 보장은 흔히 원자성(Atomicity), 일관성(Consistency), 격리성(Isolation), 지속성(Durability)을 의미하는 약자인 ACID로 잘 알려져 있다.

#### 원자성
- 일반적으로 원자적이란 더 작은 부분으로 쪼갤 수 없는 뭔가를 가리킨다. ACID의 원자성은 클라이언트가 쓰기 작업 몇 개를 실행하려고 하는데 그중 일부만 처리된 후 결함이 생기면(예를 들어 프로세스가 죽거나 네트워크 연결이 끊기면 혹은 디스크가 가득 차거나 어떤 정합성 제약 조건을 위반하면) 무슨 일이 생기는지 설명한다. 여러 쓰기 작업이 하나의 원자적인 트랜잭션으로 묶여 있는데 결함 때문에 완료(커밋)될 수 없다면 어보트 되고 데이터베이스는 이 트랜잭션에서 지금까지 실행한 쓰기를 무시하거나 취소해야 한다.
- 원자성 없이는 여러 변경을 적용하는 도중 오류가 발생하면 어떤 변경은 효과가 있고 어떤 것은 그렇지 않은지 알기 어렵다. 애플리케이션에서 재시도할 수 있지만 동일한 변경이 두 번 실행돼서 중복되거나 잘못된 데이터가 만들어지기 쉽다. 원자성은 이 문제를 단순하게 만들어준다. 트랜잭션이 어보트됐다면 애플리케이션에서 이 트랜잭션이 어떤 것도 반영하지 않았음을 알 수 있으므로 안전하게 재시도할 수 있다.

#### 일관성
일관성이란 단어는 여러 의미로 쓰인다.
- 5장에서는 복제 일관성(replica consistency)과 비동기식으로 복제되는 시스템에서 발생하는 최종적 일관성(eventual consistency) 문제에 대해 설명했다.
- 일관성 해싱은 어떤 시스템들에서 재균형화를 위해 사용하는 파티셔닝 방법이다.
- CAP 정리에서 일관성이란 단어는 선형성(linearizability)을 의미한다.
- ACID의 맥락에서 일관성은 데이터베이스가 "좋은 상태" 에 있어야 한다는 것의 애플리케이션에 특화된 개념을 가리킨다.

<br>

ACID 일관성의 아이디어는 항상 진실이어야 하는, 데이터에 관한 어떤 선언(불변식(invariant)) 이 있다는 것이다. 예를 들어 회계 시스템에서 모든 계좌에 걸친 대변과 차변은 항상 맞아떨어져야 한다. 트랜잭션이 이런 불변식이 유효한 데이터베이스에서 시작하고 트랜잭션에서 실행된 모든 쓰기가 유효성을 보존한다면 불변식이 한상 만족된다고 확신할 수 있다.
- 그러나 일관성의 아이디어는 애플리케이션의 불변식 개념에 의존하고, 일관성을 유지하도록 트랜잭션을 올바르게 정의하는 것은 애플리케이션의 책임이다. 이는 데이터베이스가 보장할 수 있는 게 아니다. 데이터베이스는 불변식을 위반하는 잘못된 데이터를 쓰지 못하도록 막을 수 없다.(데이터베이스에서 확인할 수 있는 특정한 종류의 불변식이 있기는 하다. 예를 들어 외래 키 제약 조건이나 유일성 제약 조건을 쓸 수 있다. 그러나 일반적으로 애플리케이션에서 데이터가 유효한지 아닌지를 정의하고 데이터베이스는 데이터를 저장할 뿐이다)
- 원자성, 격리성, 지속성은 데이터베이스의 속성인 반면(ACID에서의) 일관성은 애플리케이션의 속성이다. 애플리케이션의 일관성을 달성하기 위해 데이터베이스의 원자성과 격리성 속성에 기댈 수는 있지만 데이터베이스만으로 되는 것이 아니다. 따라서 C는 실제로는 ACID에 속하지 않는다.

#### 격리성 
- 대부분 동시에 여러 클라이언트에서 데이터베이스에 접속한다. 클라이언트들이 데이터베이스의 다른 부분을 읽고 쓰면 아무 문제가 없지만 동일한 데이터베이스 레코드에 접근하면 동시성 문제(경쟁 조건)에 맞닥뜨리게 된다.
- ACID에서 격리성은 동시에 실행되는 트랜잭션은 서로 격리된다는 것을 의미한다. 트랜잭션은 다른 트랜잭션을 방해할 수 없다. 고전적인 데이터베이스 교과서에서는 격리성을 직렬성이라는 용어로 공식화한다. 직렬성은 각 트랜잭션이 전체 데이터베이스에서 실행되는 유일한 트랜잭션인 것처럼 동작할 수 있다는 것을 의미한다. 데이터베이스는 실제로는 여러 트랜잭션이 동시에 실행됐더라도 트랜잭션이 커밋됐을 때의 결과가 트랜잭션이 순차적으로(하나씩 차례로) 실행됐을 때의 결과와 동일하도록 보장한다.

#### 지속성
- 데이터베이스 시스템의 목적은 데이터를 잃어버릴 염려가 없는 안전한 저장소를 제공하는 것이다. 지속성(durability)은 트랜잭션이 성공적으로 커밋됐다면 하드웨어 결함이 발생하거나 데이터베이스가 죽더라도 트랜잭션에서 기록한 모든 데이터는 손실되지 않는다는 보장이다.
- 완벽한 지속성은 존재하지 않는다. 모든 하드디스크와 백업이 동시에 파괴돼 버리면 당연히 데이터베이스가 해줄 수 있는 것은 아무것도 없다.

#### 단일 객체 연산과 다중 객체 연산
...

#### 단일 객체 쓰기
...

#### 다중 객체 트랜잭션의 필요성
...

#### 오류와 어보트 처리
- 트랜잭션의 핵심 기능은 오류가 생기면 어보트되고 안전하게 재시도할 수 있다는 것이다. ACID 데이터베이스는 이 철학을 바탕으로 한다. 데이터베이스가 원자성, 격리성, 또는 지속성 보장을 위반할 위험이 있다면 트랜잭션이 절반 정도 완료된 상태에 머물게 하는 대신 트랜잭션을 완전히 폐기한다.
- 하지만 모든 시스템이 이 철학을 따르지는 않는데 '리더 없는 복제' 를 사용하는 데이터스토어는 "최선을 다하는(best effort)" 원칙을 기반으로 훨씬 더 많은 일을 한다. 데이터베이스는 가능한 모든 것을 할 것이며 그 때문에 오류가 발생하면 이미 한 일을 취소하지 않는다. 따라서 오류 복구는 애플리케이션에 책임이 있다.

### 완화된 격리 수준
- 두 트랜잭션이 동일한 데이터에 접근하지 않으면 서로 의존하지 않으므로 안전하게 병렬 실행될 수 있다. 동시성 문제(경쟁 조건)는 트랜잭션이 다른 트랜잭션에서 동시에 변경한 데이터를 읽거나 두 트랜잭션이 동시에 같은 데이터를 변경하려고 할 때만 나타난다.

#### 커밋 후 읽기
- 가장 기본적인 수준의 트랜잭션 격리는 커밋 후 읽기(read committed)다. 이 수준에서는 두 가지를 보장해준다.
  - 데이터베이스에서 읽을 때 커밋된 데이터만 보게 된다.(더티 읽기가 없음).
  - 데이터베이스에 쓸 때 커밋된 데이터만 덮어쓰게 된다.(더티 쓰기가 없음).

#### 더티 읽기 방지
- 트랜잭션이 데이터베이스에 데이터를 썼지만 아직 커밋되거나 어보트되지 않았다고 하자. 다른 트랜잭션에서 커밋되지 않은 데이터를 볼 수 있을까? 만약 그렇다면 이를 더티 읽기 라고 한다.
- 커밋 후 읽기 격리 수준에서 실행되는 트랜잭션은 더티 읽기를 막아야 한다. 트랜잭션이 쓴 내용은 커밋된 후에야 다른 트랜잭션에게 보인다는 뜻이다.

<br>

더티 읽기를 막는 게 유용한 이유가 몇 가지 있다.
- 트랜잭션이 여러 객체를 갱신하는데 더티 읽기가 생기면 다른 트랜잭션이 일부는 갱신된 값을, 일부는 갱신되지 않은 값을 볼 수 있다.
- 트랜잭션이 어보트되면 그때까지 쓴 내용은 모두 롤백돼야 한다. 데이터베이스가 더티 읽기를 허용하면 트랜잭션이 나중에 롤백될 데이터, 즉 실제로는 데이터베이스에 결코 커밋되지 않을 데이터를 볼 수 있다. 그 결과를 따져보려 하면 곧 머리가 혼란스러워질 것이다.

#### 더티 쓰기 방지
- 두 트랜잭션이 데이터베이스에 있는 동일한 객체를 동시에 갱신하려고 하면 무슨 일이 생길까? 쓰기 순서가 어떻게 될지는 모르지만 일반적으로 나중에 쓴 내용이 먼저 쓴 내용을 덮어쓴다고 가정한다.
- 그러나 먼저 쓴 내용이 아직 커밋되지 않은 트랜잭션에서 쓴 것이고 나중에 실행된 쓰기 작업이 커밋되지 않은 값을 덮어써버리면 어떻게 될까? 이를 더티 쓰기(Dirty write) 라고 부른다. 커밋 후 읽기 격리 수준에서 실행된는 트랜잭션은 더티 쓰기를 방지해야 한다. 보통 먼저 쓴 트랜잭션이 커밋되거나 어보트될 때까지 두 번째 쓰기를 지연시키는 방법을 사용한다.

#### 커밋 후 읽기 구현
- 커밋 후 읽기는 매울 널리 쓰이는 격리 수준이다.
- 가장 흔한 방법으로 데이터베이스는 로우 수준 잠금을 사용해 더티 쓰기를 방지한다. 트랜잭션에서 특정 객체(로우나 문서)를 변경하고 싶다면 먼저 해당 객체에 대한 잠금을 획득해야 한다. 그리고 트랜잭션이 커밋되거나 어보트될 때까지 잠금을 보유하고 있어야 한다. 오직 한 틀내잭션만 어떤 주어진 객체에 대한 잠금을 보유할 수 있다. 다른 트랜잭션에서 동일한 객체에 쓰기를 원한다면 첫 번째 트랜잭션이 커밋되거나 어보트된 후에야 잠금을 얻어 진행할 수 있다. 이런 잠금은 커밋 후 읽기모드(또는 더 강력한 격리 수준)에서 데이터베이스에 의해 자동으로 실행된다.



</details>
